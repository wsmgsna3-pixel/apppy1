# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.22 ç»ˆæä¿®æ­£ç‰ˆ (MACDå½’ä¸€åŒ– + èµ„é‡‘å…±æŒ¯)
æ ¸å¿ƒé€»è¾‘ä¼˜åŒ–ï¼š
1. [è¯„åˆ†ä¿®æ­£] ä½¿ç”¨ MACD/Price å½’ä¸€åŒ–è¯„åˆ†ï¼Œæ¶ˆé™¤é«˜ä»·è‚¡åå·®ã€‚
2. [å®æˆ˜è¿‡æ»¤] å‰”é™¤ä¸€å­—æ¶¨åœæ— æ³•ä¹°å…¥çš„æƒ…å†µã€‚
3. [é»„é‡‘å½¢æ€] å¼•å…¥é‡æ¯”(>1.5)å’Œæ¢æ‰‹ç‡(5-15%)ä½œä¸ºæ ¸å¿ƒåŠ åˆ†é¡¹ã€‚
4. [èŒƒå›´æ”¾å®½] ä¸å†å¼ºåˆ¶é”å®š 40-80 å…ƒï¼Œå…¨å¸‚åœºæ‰«æã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V30.22 ç»ˆæä¿®æ­£ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V30.22 ç»ˆæä¿®æ­£ç‰ˆï¼ˆâš–ï¸ è¯„åˆ†ä¿®æ­£ + ğŸ’° èµ„é‡‘å…±æŒ¯ï¼‰")
st.markdown("""
**ğŸ› ï¸ ç­–ç•¥é€»è¾‘å‡çº§ï¼š**
1. **å…¬å¹³è¯„åˆ†ï¼š** ä½¿ç”¨ **MACD / è‚¡ä»·** è¿›è¡Œè¯„åˆ†ï¼Œä½ä»·å¦–è‚¡ä¹Ÿèƒ½ä¸Šæ¦œã€‚
2. **ä¹°å…¥é£æ§ï¼š** è‡ªåŠ¨å‰”é™¤ **ä¸€å­—æ¶¨åœ** (ä¹°ä¸è¿›) çš„æ ‡çš„ã€‚
3. **èµ„é‡‘å…±æŒ¯ (åˆ©ç”¨10000ç§¯åˆ†æ•°æ®)ï¼š**
    * âœ… **é‡æ¯” > 1.5** (ä¸»åŠ›å¼‚åŠ¨)
    * âœ… **æ¢æ‰‹ 5%~15%** (é»„é‡‘æ´»è·ƒåŒº)
    * âœ… **æ¶¨åœç¡®è®¤** (æ¶¨å¹…>9.5%)
""")

# ---------------------------
# è¾…åŠ©å‡½æ•° 
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        # å¢åŠ é‡è¯•æœºåˆ¶ï¼Œé˜²æ­¢ç½‘ç»œæŠ–åŠ¨
        for _ in range(3):
            try:
                if kwargs.get('is_index'): df = pro.index_daily(**kwargs)
                else: df = func(**kwargs)
                if df is not None and not df.empty:
                    return df
            except:
                continue
        return pd.DataFrame(columns=['ts_code'])
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    # å¤šå–ä¸€äº›å¤©æ•°ä»¥é˜²å‡æœŸ
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3 + 30)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ Token æˆ–ç½‘ç»œã€‚")
        return []
    return cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# æ•°æ®æ‹‰å–
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    # æ‹‰å–è¡Œæƒ…
    daily_df = safe_get('daily', trade_date=date)
    # æ‹‰å–å¤æƒå› å­
    adj_df = safe_get('adj_factor', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    # é¢„ç•™è¶³å¤Ÿçš„å‰ç½®æ•°æ®ç”¨äºè®¡ç®—MACD (è‡³å°‘120å¤©)
    start_date = (datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
    end_date = (datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=25)).strftime("%Y%m%d") 
    
    all_dates = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')['cal_date'].tolist()
    st.info(f"â³ æ­£åœ¨æ‹‰å–å…¨å¸‚åœºæ•°æ® ({start_date} ~ {end_date})ï¼Œè¯·è€å¿ƒç­‰å¾…...")

    adj_list, daily_list = [], []
    download_progress = st.progress(0, text="æ•°æ®ä¸‹è½½è¿›åº¦...")
    
    # æ‰¹é‡æˆ–å¾ªç¯æ‹‰å–
    total_dates = len(all_dates)
    for i, date in enumerate(all_dates):
        try:
            cached_data = fetch_and_cache_daily_data(date)
            if not cached_data['adj'].empty: adj_list.append(cached_data['adj'])
            if not cached_data['daily'].empty: daily_list.append(cached_data['daily'])
            
            # æ›´æ–°è¿›åº¦æ¡
            if i % 5 == 0:
                download_progress.progress((i + 1) / total_dates)
        except: continue 
    download_progress.empty()

    if not adj_list or not daily_list:
        st.error("âŒ æ— æ³•è·å–å†å²æ•°æ®ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ Token æƒé™ã€‚")
        return False
        
    # åˆå¹¶æ•°æ®
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    # å»é‡å¹¶å»ºç«‹ç´¢å¼•
    GLOBAL_ADJ_FACTOR = adj_data.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    cols_to_keep = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'vol']
    daily_raw = pd.concat(daily_list)
    valid_cols = [c for c in cols_to_keep if c in daily_raw.columns]
    daily_raw = daily_raw[valid_cols]
    
    for col in ['open', 'high', 'low', 'close', 'pre_close', 'vol']:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

    # ç¼“å­˜æœ€æ–°çš„å¤æƒåŸºå‡†
    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_global_date:
        try:
            latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
        except: GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True

# ----------------------------------------------------------------------
# æ•°æ®å¤„ç† (å‰å¤æƒ)
# ----------------------------------------------------------------------
def get_qfq_data_v4_optimized_final(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty: return pd.DataFrame()
        
    base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(base_adj) or base_adj < 1e-9: return pd.DataFrame() 

    try:
        # åˆ©ç”¨ç´¢å¼•åˆ‡ç‰‡åŠ é€Ÿ
        daily = GLOBAL_DAILY_RAW.loc[(ts_code, slice(start_date, end_date)), :]
        adj = GLOBAL_ADJ_FACTOR.loc[(ts_code, slice(start_date, end_date)), 'adj_factor']
    except KeyError: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    
    # å¯¹é½ç´¢å¼•
    df = daily.merge(adj.rename('adj_factor'), left_index=True, right_index=True, how='left').dropna(subset=['adj_factor'])
    
    factor = df['adj_factor'] / base_adj
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns: df[col] = df[col] * factor
    
    df = df.reset_index() # æ¢å¤ ts_code, trade_date ä¸ºåˆ—
    df['trade_date_str'] = df['trade_date']
    df['trade_date'] = pd.to_datetime(df['trade_date_str'], format='%Y%m%d')
    return df.sort_values('trade_date').set_index('trade_date_str')[['open', 'high', 'low', 'close', 'pre_close', 'vol']]

# ----------------------------------------------------------------------
# æ ¸å¿ƒä¹°å…¥è®¡ç®— (å®ç›˜ä¸¥é€‰)
# ----------------------------------------------------------------------
def get_future_prices_real_combat(ts_code, selection_date, days_ahead=[1, 3, 5], buy_threshold_pct=1.5):
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_future = (d0 + timedelta(days=25)).strftime("%Y%m%d")
    
    hist = get_qfq_data_v4_optimized_final(ts_code, start_date=start_future, end_date=end_future)
    results = {}
    for n in days_ahead: results[f'Return_D{n}'] = np.nan

    if hist.empty: return results
    d1_data = hist.iloc[0]
    
    # 1. æ‹’ç»ä½å¼€
    if d1_data['open'] <= d1_data['pre_close']: return results 
    
    # 2. [æ–°å¢] æ‹’ç»ä¸€å­—æ¶¨åœ (ä¹°ä¸è¿›)
    # åˆ¤å®šæ ‡å‡†ï¼šå¼€ç›˜ä»· >= æ˜¨æ”¶ * 1.095 (ç§‘åˆ›æ¿éœ€æ›´å®½ï¼Œæ­¤å¤„é€šç”¨ä¿å®ˆå¤„ç†) ä¸” æœ€ä½ä»· == å¼€ç›˜ä»·
    limit_up_price = d1_data['pre_close'] * 1.095
    if d1_data['open'] >= limit_up_price and d1_data['low'] >= d1_data['open']:
        return results # ä¸€å­—æ¿ï¼Œæ”¾å¼ƒ

    # 3. ç¡®è®¤çªç ´é˜ˆå€¼ (å¦‚ +1.5%)
    buy_price_threshold = d1_data['open'] * (1 + buy_threshold_pct / 100.0)
    
    # å¦‚æœæœ€é«˜ä»·éƒ½æ²¡æ‘¸åˆ°é˜ˆå€¼ï¼Œæ²¡æˆäº¤
    if d1_data['high'] < buy_price_threshold: return results 

    # è®¡ç®—æ”¶ç›Š
    for n in days_ahead:
        idx = n - 1
        if len(hist) > idx:
            # æ”¶ç›Šç‡ = (Næ—¥æ”¶ç›˜ä»· / ä¹°å…¥ä»· - 1) * 100
            results[f'Return_D{n}'] = (hist.iloc[idx]['close'] / buy_price_threshold - 1) * 100
            
    return results

# ----------------------------------------------------------------------
# æŒ‡æ ‡è®¡ç®— 
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date, end_date=end_date)
    res = {}
    if df.empty or len(df) < 26: return res
         
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    vol = df['vol']
    
    # 1. æ”¹è¿›ç‰ˆ MACD (8, 17, 5)
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=5, adjust=False).mean()
    macd_val = (diff - dea) * 2
    res['macd_val'] = macd_val.iloc[-1]
    
    # 2. å‡çº¿/é‡èƒ½/å…¶ä»–ç‰¹å¾
    ma20 = close.rolling(window=20).mean()
    ma5_vol = vol.rolling(window=5).mean()
    
    res['close_current'] = close.iloc[-1]
    res['ma20_current'] = ma20.iloc[-1] if not pd.isna(ma20.iloc[-1]) else 0
    res['vol_current'] = vol.iloc[-1]
    res['ma5_vol_current'] = ma5_vol.iloc[-1] if not pd.isna(ma5_vol.iloc[-1]) else 0
    res['pct_chg_current'] = df['pct_chg'].iloc[-1]
    
    return res

@st.cache_data(ttl=3600*12)
def get_market_state(trade_date):
    # ç®€å•çš„å¤§ç›˜çŠ¶æ€åˆ¤æ–­ï¼Œè‹¥å¤§ç›˜è·Œç ´20æ—¥çº¿åˆ™ä¸ºå¼±åŠ¿
    start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=40)).strftime("%Y%m%d")
    index_data = safe_get('daily', ts_code='000300.SH', start_date=start_date, end_date=trade_date, is_index=True)
    if index_data.empty or len(index_data) < 20: return 'Weak'
    index_data = index_data.sort_values('trade_date')
    return 'Strong' if index_data.iloc[-1]['close'] > index_data['close'].tail(20).mean() else 'Weak'
    
# ----------------------------------------------------
# ä¾§è¾¹æ 
# ----------------------------------------------------
with st.sidebar:
    st.header("1. å›æµ‹è®¾ç½®")
    backtest_date_end = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = int(st.number_input("**å›æµ‹å¤©æ•° (N)**", value=30, step=1))
    
    st.markdown("---")
    st.header("2. å®æˆ˜å‚æ•° (V30.22)")
    BUY_THRESHOLD_PCT = st.number_input("ä¹°å…¥ç¡®è®¤é˜ˆå€¼ (%)", value=1.5, step=0.1)
    
    st.markdown("---")
    st.header("3. åŸºç¡€è¿‡æ»¤")
    FINAL_POOL = int(st.number_input("å…¥å›´æ•°é‡", value=100)) 
    TOP_BACKTEST = int(st.number_input("Top K", value=5))
    # [ä¿®æ”¹] æ”¾å®½ä»·æ ¼é™åˆ¶ï¼Œé¿å…ä»·æ ¼æ­§è§†
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»·", value=4.0, step=0.5) 
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»·", value=600.0, step=10.0)
    MIN_TURNOVER = st.number_input("æœ€ä½æ¢æ‰‹ (%)", value=3.0) 
    MIN_CIRC_MV_BILLIONS = st.number_input("æœ€ä½æµé€šå¸‚å€¼ (äº¿)", value=20.0)
    MIN_AMOUNT = st.number_input("æœ€ä½æˆäº¤é¢ (äº¿)", value=1.0) * 100000000 

TS_TOKEN = st.text_input("Tushare Token (éœ€10000ç§¯åˆ†)", type="password")
if not TS_TOKEN: st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ----------------------------------------------------------------------
# æ ¸å¿ƒé€»è¾‘ (V30.22 ç»ˆæå½¢æ€)
# ----------------------------------------------------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, buy_threshold):
    # 1. å¼±å¸‚ç†”æ–­
    market_state = get_market_state(last_trade)
    if market_state == 'Weak': return pd.DataFrame(), f"å¼±å¸‚é¿é™©"

    # 2. æ‹‰å–æ•°æ®
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤±"
    pool = daily_all.reset_index(drop=True)
    
    basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date') 
    if not basic.empty: pool = pool.merge(basic, on='ts_code', how='left')
    
    # [å…³é”®] è·å–æ¯æ—¥æŒ‡æ ‡ï¼šæ¢æ‰‹ç‡ã€é‡æ¯” (Volume Ratio)
    # volume_ratio éœ€è¦ 10000 ç§¯åˆ†æˆ–è¶³å¤Ÿæƒé™
    d_basic = safe_get('daily_basic', trade_date=last_trade, fields='ts_code,turnover_rate,circ_mv,total_mv,volume_ratio')
    if not d_basic.empty: pool = pool.merge(d_basic, on='ts_code', how='left')
    
    # èµ„é‡‘æµ (å¯é€‰ï¼Œè¾…åŠ©)
    mf = safe_get('moneyflow', trade_date=last_trade)
    if not mf.empty and 'net_mf' in mf.columns:
        mf = mf[['ts_code', 'net_mf']].fillna(0)
        pool = pool.merge(mf, on='ts_code', how='left')
    
    # å¡«å……ç¼ºå¤±å€¼
    for c in ['turnover_rate','circ_mv','net_mf', 'volume_ratio']: 
        if c not in pool.columns: pool[c] = 0.0
    
    # 3. åŸºç¡€è¿‡æ»¤
    df = pool.copy()
    df['close'] = pd.to_numeric(df['close'], errors='coerce') 
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000 
    
    # è¿‡æ»¤ STã€é€€å¸‚ã€åŒ—äº¤æ‰€(92å¼€å¤´)
    df = df[~df['name'].str.contains('ST|é€€', case=False, na=False)]
    df = df[~df['ts_code'].str.startswith('92')] # è¿‡æ»¤åŒ—äº¤æ‰€
    df = df[~df['ts_code'].str.startswith('688')] if False else df # ç§‘åˆ›æ¿å¯é€‰ä¿ç•™
    
    if 'list_date' in df.columns:
        df['days_listed'] = (datetime.strptime(last_trade, "%Y%m%d") - pd.to_datetime(df['list_date'], format='%Y%m%d', errors='coerce')).dt.days
        df = df[df['days_listed'] >= 120]
        
    df = df[(df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE) & 
        (df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS) &
        (df['turnover_rate'] >= MIN_TURNOVER) & (df['turnover_rate'] <= 25.0) &
        (df['amount'] * 1000 >= MIN_AMOUNT)]
        
    if len(df) == 0: return pd.DataFrame(), f"è¿‡æ»¤åæ— è‚¡ç¥¨"

    # åˆé€‰æ± é€»è¾‘ï¼šä¸€åŠé€‰èµ„é‡‘æµå¼ºï¼Œä¸€åŠé€‰æ¶¨å¹…å¼º
    limit_mf = int(FINAL_POOL * 0.5)
    df_mf = df.sort_values('net_mf', ascending=False).head(limit_mf)
    df_pct = df[~df['ts_code'].isin(df_mf['ts_code'])].sort_values('pct_chg', ascending=False).head(FINAL_POOL - len(df_mf))
    candidates = pd.concat([df_mf, df_pct]).reset_index(drop=True)
    
    # ç¡®ä¿æœ‰å†å²æ•°æ®
    if not GLOBAL_DAILY_RAW.empty:
        try:
            available = GLOBAL_DAILY_RAW.loc[(slice(None), last_trade), :].index.get_level_values('ts_code').unique()
            candidates = candidates[candidates['ts_code'].isin(available)]
        except: return pd.DataFrame(), "ç¼“å­˜ç¼ºå¤±"

    # 4. æ·±åº¦è®¡ç®— (ç¡¬é—¨æ§›)
    records = []
    for row in candidates.itertuples():
        ind = compute_indicators(row.ts_code, last_trade) 
        
        # [ç¡¬é—¨æ§›]
        # å¿…é¡»æ˜¯ä¸Šå‡è¶‹åŠ¿ (æ”¶ç›˜ä»· > 20æ—¥çº¿)
        if ind.get('close_current', 0) <= ind.get('ma20_current', 0): continue
        # å¿…é¡»æ”¾é‡ (å½“å‰é‡ > 5æ—¥å‡é‡ * 1.2)
        if ind.get('vol_current', 0) <= ind.get('ma5_vol_current', 0) * 1.2: continue
        # MACD å¿…é¡»ä¸ºæ­£
        if pd.isna(ind.get('macd_val')) or ind.get('macd_val') <= 0: continue
        
        # è®¡ç®—å®æˆ˜ä¹°å…¥ç»“æœ
        future = get_future_prices_real_combat(row.ts_code, last_trade, buy_threshold_pct=buy_threshold)
        
        records.append({
            'ts_code': row.ts_code, 
            'name': getattr(row, 'name', row.ts_code),
            'Close': row.close, 
            'Pct_Chg (%)': getattr(row, 'pct_chg', 0),
            'macd': ind['macd_val'], 
            'volume_ratio': getattr(row, 'volume_ratio', 0),
            'turnover_rate': getattr(row, 'turnover_rate', 0),
            'Return_D1 (%)': future.get('Return_D1'), 
            'Return_D3 (%)': future.get('Return_D3'),
            'Return_D5 (%)': future.get('Return_D5')
        })
    
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), "æ— ä¼˜è´¨æ”¾é‡è‚¡ç¥¨"

    # 5. [ç»ˆæè¯„åˆ†ç³»ç»Ÿ]
    
    # A. åŸºç¡€åˆ†ä¿®æ­£ï¼š(MACD / Close) * 1000000
    # è§£å†³äº†é«˜ä»·è‚¡ MACD ç»å¯¹å€¼è¿‡å¤§çš„é—®é¢˜
    fdf['macd_ratio'] = fdf['macd'] / fdf['Close']
    base_score = fdf['macd_ratio'] * 1000000 
    
    # B. åŠ¨æ€åŠ åˆ† (èµ„é‡‘å…±æŒ¯)
    def calculate_smart_bonus(row):
        bonus = 1.0
        tags = []
        
        # [åŠ åˆ† 1] é‡èƒ½ç¡®è®¤ï¼šé‡æ¯” > 1.5 (è¯´æ˜ä¸»åŠ›èµ„é‡‘ä»‹å…¥æ˜æ˜¾)
        if row['volume_ratio'] > 1.5:
            bonus += 0.1
            tags.append('é‡æ¯”ä½³')
            
        # [åŠ åˆ† 2] æ¢æ‰‹ç‡é»„é‡‘åŒºé—´ï¼š5% ~ 15% (æ´»è·ƒä½†ä¸è¿‡çƒ­)
        # æ›¿ä»£äº†åŸå…ˆéš¾ç”¨çš„â€œæ³¢åŠ¨ç‡â€æŒ‡æ ‡
        if 5.0 <= row['turnover_rate'] <= 15.0:
            bonus += 0.1
            tags.append('æ¢æ‰‹ä½³')
            
        # [åŠ åˆ† 3] æ¶¨åœæ¿ç¡®è®¤ (>9.5%) -> +10%
        if row['Pct_Chg (%)'] >= 9.5:
            bonus += 0.1
            tags.append('æ¿ç¡®è®¤')
            
        return bonus, "+".join(tags)

    fdf[['bonus', 'åŠ åˆ†é¡¹']] = fdf.apply(lambda x: pd.Series(calculate_smart_bonus(x)), axis=1)
    fdf['ç»¼åˆè¯„åˆ†'] = base_score * fdf['bonus']
    
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(TOP_BACKTEST)
    return fdf.reset_index(drop=True), None

# ---------------------------
# ä¸»ç¨‹åº
# ---------------------------
if st.button(f"ğŸš€ å¼€å§‹ {BACKTEST_DAYS} æ—¥ V30.22 ç»ˆæå›æµ‹"):
    trade_days = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
    if not trade_days: st.stop()
    if not get_all_historical_data(trade_days): st.stop()
    
    st.success("âœ… V30.22 (ç»ˆæä¿®æ­£ç‰ˆ) å¯åŠ¨... æ­£åœ¨å…¨å¸‚åœºæ‰«æ")
    results = []
    bar = st.progress(0)
    
    for i, date in enumerate(trade_days):
        try:
            df, msg = run_backtest_for_a_day(date, TOP_BACKTEST, FINAL_POOL, BUY_THRESHOLD_PCT)
            if not df.empty:
                df['Trade_Date'] = date
                results.append(df)
        except Exception: pass
        bar.progress((i + 1) / len(trade_days))
    bar.empty()
    
    if not results:
        st.error("æ— ç»“æœã€‚")
        st.stop()
        
    all_res = pd.concat(results)
    if all_res['Trade_Date'].dtype != 'object': all_res['Trade_Date'] = all_res['Trade_Date'].astype(str)
    
    # ---------------------------
    # ç»“æœå±•ç¤º
    # ---------------------------
    st.header(f"ğŸ“Š V30.22 å›æµ‹æŠ¥å‘Š (MACDä¿®æ­£ + èµ„é‡‘å…±æŒ¯)")
    st.markdown(f"**æœ‰æ•ˆäº¤æ˜“å¤©æ•°ï¼š** {all_res['Trade_Date'].nunique()} å¤©")

    cols = st.columns(3)
    for idx, n in enumerate([1, 3, 5]):
        col = f'Return_D{n} (%)' 
        valid = all_res.dropna(subset=[col])
        if not valid.empty:
            avg_ret = valid[col].mean()
            hit_rate = (valid[col] > 0).sum() / len(valid) * 100
            count = len(valid)
        else: avg_ret, hit_rate, count = 0, 0, 0
        with cols[idx]:
            st.metric(f"D+{n} æ”¶ç›Š / èƒœç‡", f"{avg_ret:.2f}% / {hit_rate:.1f}%", help=f"æˆäº¤ï¼š{count} ç¬”")
            
    # ä¸‹è½½æŒ‰é’®
    csv = all_res.to_csv(index=False).encode('utf-8-sig')
    st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´å›æµ‹æ•°æ® (CSV)", csv, "v30_22_export.csv", "text/csv")

    st.header("ğŸ“‹ æ¯æ—¥æˆäº¤æ˜ç»†")
    st.dataframe(all_res.sort_values('Trade_Date', ascending=False), use_container_width=True)
