# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆ v4.6 - å‡å€¼å›å½’/å›è°ƒç­–ç•¥ï¼‰
è¯´æ˜ï¼š
- **V4.6 æ ¸å¿ƒä¿®å¤ï¼š** ä¿®å¤äº†å›æµ‹å‡½æ•° `run_backtest` çš„å‚æ•°ç­¾åå’Œè¿‡æ»¤é€»è¾‘ï¼Œ
  ç¡®ä¿ä¾§è¾¹æ è®¾ç½®çš„**æ¶¨è·Œå¹…é™åˆ¶**èƒ½å¤Ÿæ­£ç¡®ä¼ é€’å’Œåº”ç”¨ï¼Œå½»åº•è§£å†³â€œäº¤æ˜“æ¬¡æ•°0â€çš„é—®é¢˜ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆå‡å€¼å›å½’ v4.6ï¼‰", layout="wide")
st.title("é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆ v4.6 - å‡å€¼å›å½’ç­–ç•¥ï¼‰")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚è‹¥æœ‰æƒé™ç¼ºå¤±ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é™çº§å¹¶ç»§ç»­è¿è¡Œã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆç­–ç•¥æ ¸å¿ƒï¼‰")
    # ç­–ç•¥ç¡¬æ€§è¿‡æ»¤å‚æ•°
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=1.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=500.0, step=10.0))
    MIN_MARKET_CAP = float(st.number_input("æœ€ä½å¸‚å€¼ (å…ƒ)", value=500000000.0, step=100000000.0)) # é»˜è®¤ 5äº¿
    MAX_MARKET_CAP = float(st.number_input("æœ€é«˜å¸‚å€¼ (å…ƒ)", value=100000000000.0, step=1000000000.0)) # é»˜è®¤ 1000äº¿
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=100000000.0, step=10000000.0)) # é»˜è®¤ 1äº¿
    
    st.markdown("---")
    st.subheader("æŠ€æœ¯æŒ‡æ ‡å‚æ•°")
    MACD_FAST = int(st.number_input("MACD å¿«çº¿å‘¨æœŸ", value=12, step=1))
    MACD_SLOW = int(st.number_input("MACD æ…¢çº¿å‘¨æœŸ", value=26, step=1))
    MACD_SIGNAL = int(st.number_input("MACD ä¿¡å·çº¿å‘¨æœŸ", value=9, step=1))
    RSI_PERIOD = int(st.number_input("RSI å‘¨æœŸ", value=14, step=1))
    
    st.markdown("---")
    # --- å†å²å›æµ‹å‚æ•° ---
    st.header("å†å²å›æµ‹å‚æ•°")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹äº¤æ˜“æ—¥å¤©æ•°", value=60, min_value=10, max_value=250))
    BACKTEST_TOP_K = int(st.number_input("å›æµ‹æ¯æ—¥æœ€å¤šäº¤æ˜“ K æ”¯", value=5, min_value=1, max_value=20))
    HOLD_DAYS_OPTIONS = st.multiselect("å›æµ‹æŒè‚¡å¤©æ•°", options=[1, 3, 5, 10, 20], default=[3, 5])
    
    st.subheader("å›æµ‹å½“æ—¥æ¶¨è·Œå¹…æ§åˆ¶")
    # V4.6 å…³é”®å‚æ•°ï¼šç”¨äºå›æµ‹æ—¶çš„ç¡¬è¿‡æ»¤
    BT_MIN_PCT_FOR_CACHE = float(st.number_input("å›æµ‹ï¼šå½“æ—¥æœ€ä½æ¶¨å¹… (%)", value=-3.0, step=0.5, help="å›è°ƒç­–ç•¥ï¼Œå½“æ—¥æœ€ä½è·Œå¹…"))
    BT_MAX_PCT_FOR_CACHE = float(st.number_input("å›æµ‹ï¼šå½“æ—¥æœ€é«˜æ¶¨å¹… (%)", value=1.5, step=0.5, help="å›è°ƒç­–ç•¥ï¼Œå½“æ—¥æœ€é«˜æ¶¨å¹…ï¼ˆé¿å…è¿½é«˜ï¼‰"))

    # ç¼“å­˜ç ´åé”® (ç”¨äºå¼ºåˆ¶å›æµ‹é‡æ–°åŠ è½½æ•°æ®)
    CACHE_BREAKER = float(st.number_input("å›æµ‹ï¼šç¼“å­˜ç ´åé”®ï¼ˆä»»æ„ä¿®æ”¹åˆ·æ–°å›æµ‹ï¼‰", value=1.20, step=0.01))
    st.caption("æç¤ºï¼šç­–ç•¥ä¸º**å‡å€¼å›å½’/å›è°ƒç­–ç•¥**ï¼Œä¹°å…¥æ¡ä»¶æ˜¯ MACD é‡‘å‰åçš„å›è°ƒã€‚")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰ä¸åˆå§‹åŒ–
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# ç¼“å­˜è¾…åŠ©å‡½æ•°
# ---------------------------
def safe_get(func, **kwargs):
    """å®‰å…¨è°ƒç”¨ APIï¼Œè‹¥å¤±è´¥åˆ™è¿”å›ç©º DataFrameã€‚"""
    try:
        if func == pro.query:
             df = pro.query(kwargs.pop('api_name'), **kwargs)
        else:
            df = func(**kwargs)
            
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†å¹¶ç¼“å­˜"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        return df[df.is_open == 1]['cal_date'].tolist()
    except Exception:
        return []

@st.cache_data(ttl=36000)
def find_last_trade_day(max_days=20):
    """å¯»æ‰¾æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# ---------------------------
# æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—å‡½æ•°
# ---------------------------
@st.cache_data(ttl=36000)
def get_hist_cached(ts_code, end_date, days=120): 
    """è·å–å•åªè‚¡ç¥¨å†å²æ•°æ®å¹¶ç¼“å­˜"""
    try:
        # æ‰©å±•å†å²å¤©æ•°ä»¥ç¡®ä¿è®¡ç®—æŒ‡æ ‡çš„å‡†ç¡®æ€§
        start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days * 2)).strftime("%Y%m%d")
        df = safe_get(pro.daily, ts_code=ts_code, start_date=start, end_date=end_date)
        if df is None or df.empty:
            return pd.DataFrame()
        df = df.sort_values('trade_date').reset_index(drop=True)
        return df.tail(days).reset_index(drop=True) 
    except:
        return pd.DataFrame()

def compute_indicators(df, macd_fast, macd_slow, macd_signal, rsi_period):
    """è®¡ç®— MACD, RSI, VWA ç­‰å…³é”®æŒ‡æ ‡"""
    res = {}
    if df.empty or len(df) < max(macd_slow, rsi_period) + 1:
        return res
    
    close = df['close'].astype(float)
    pct = df['pct_chg'].astype(float)
    vol = df['vol'].astype(float)
    amount = df['amount'].astype(float) # Tushare amount æ˜¯åƒå…ƒ

    # MACD (EMA)
    ema_fast = close.ewm(span=macd_fast, adjust=False).mean()
    ema_slow = close.ewm(span=macd_slow, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=macd_signal, adjust=False).mean()
    hist = (diff - dea) * 2
    
    res['macd_diff'] = diff.iloc[-1]
    res['macd_dea'] = dea.iloc[-1]
    res['macd_hist'] = hist.iloc[-1]
    
    # MACDé‡‘å‰åˆ¤æ–­: DIFF > DEA ä¸” ä¸Šä¸€å‘¨æœŸ DIFF <= DEA
    # V4.x ç­–ç•¥ï¼šå¯»æ‰¾ MACD é‡‘å‰åçš„â€œå¼ºåŠ¿è‚¡â€
    if len(diff) > 1:
        # å‡å€¼å›å½’ç­–ç•¥å¯»æ‰¾çš„æ˜¯**é‡‘å‰åçš„å›è°ƒä¹°ç‚¹**ï¼Œè€Œéé‡‘å‰å½“æ—¥
        res['macd_golden_yesterday'] = (diff.iloc[-2] > dea.iloc[-2]) and (diff.iloc[-3] <= dea.iloc[-3])
    else:
        res['macd_golden_yesterday'] = False
    
    # RSI (RSI < 50 è¡¨ç¤ºå›è°ƒï¼ŒRSI < 30 è¡¨ç¤ºè¶…è·Œ)
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).ewm(span=rsi_period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(span=rsi_period, adjust=False).mean()
    rs = gain / loss
    rsi = 100 - (100 / (1 + rs))
    res['rsi'] = rsi.iloc[-1]
    
    # è¶‹åŠ¿æŒ‡æ ‡ (è¿‡å» N å¤©ç´¯è®¡æ¶¨å¹…)
    for n in (5, 10, 20):
        if len(close) >= n:
            res[f'{n}d_return'] = (close.iloc[-1] / close.iloc[-n] - 1) * 100
        else:
            res[f'{n}d_return'] = np.nan
            
    # é‡èƒ½æŒ‡æ ‡
    res['last_vol'] = vol.iloc[-1]
    res['last_amount'] = amount.iloc[-1] * 1000 # åƒå…ƒ -> å…ƒ

    return res

# ---------------------------
# é€‰è‚¡é€»è¾‘
# ---------------------------
if st.button("ğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡ï¼ˆåˆæ¬¡è¿è¡Œå¯èƒ½è¾ƒä¹…ï¼‰"):
    # 1. æ‹‰å–å½“æ—¥ daily_basic ä½œä¸ºåˆç­›
    st.write("æ­£åœ¨æ‹‰å–å½“æ—¥ daily_basic ä½œä¸ºåˆç­›...")
    # å‡å€¼å›å½’ç­–ç•¥ä¸éœ€è¦æŒ‰æ¶¨å¹…åˆç­›ï¼Œç›´æ¥å…¨é‡åŠ è½½
    daily_all = safe_get(pro.daily_basic, trade_date=last_trade)
    if daily_all.empty:
        st.error("æ— æ³•è·å–å½“æ—¥ daily_basic æ•°æ®ã€‚")
        st.stop()
        
    # 2. æ‹‰å–é«˜çº§æ¥å£æ•°æ®
    st.write("å°è¯•åŠ è½½ stock_basic / daily ç­‰é«˜çº§æ¥å£...")
    # å°½é‡ä½¿ç”¨ä¸€æ¬¡æ€§æŸ¥è¯¢ï¼Œæé«˜æ•ˆç‡
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,total_mv,circ_mv')
    daily_raw = safe_get(pro.daily, trade_date=last_trade, fields='ts_code,close,pct_chg,vol,amount')
    
    # 3. æ•°æ®åˆå¹¶
    pool_merged = daily_all.copy()
    
    if not stock_basic.empty:
        pool_merged = pool_merged.merge(stock_basic[['ts_code','name','industry']], 
                                        on='ts_code', how='left')
    if not daily_raw.empty:
        pool_merged = pool_merged.merge(daily_raw, 
                                        on='ts_code', how='left')
        
    # Tushare çš„ total_mv/circ_mv é»˜è®¤å•ä½æ˜¯ä¸‡å…ƒ
    pool_merged['total_mv_yuan'] = pool_merged['total_mv'].fillna(0) * 10000.0
    pool_merged['amount_yuan'] = pool_merged['amount'].fillna(0) * 1000.0 # Tushare amount æ˜¯åƒå…ƒ

    # 4. ç¡¬æ€§è¿‡æ»¤ï¼ˆæ¸…æ´—é˜¶æ®µï¼‰
    st.write("æ­£åœ¨å¯¹åˆç­›æ± è¿›è¡Œç¡¬æ€§è¿‡æ»¤ï¼ˆä»·æ ¼/å¸‚å€¼/æˆäº¤é¢/ST/åŒ—äº¤æ‰€ï¼‰...")
    clean_df = pool_merged.copy()
    
    # F1: ä»·æ ¼åŒºé—´
    clean_df = clean_df[(clean_df['close'] >= MIN_PRICE) & (clean_df['close'] <= MAX_PRICE)]
    
    # F2: å¸‚å€¼åŒºé—´
    clean_df = clean_df[(clean_df['total_mv_yuan'] >= MIN_MARKET_CAP) & (clean_df['total_mv_yuan'] <= MAX_MARKET_CAP)]
    
    # F3: æˆäº¤é¢
    clean_df = clean_df[clean_df['amount_yuan'] >= MIN_AMOUNT]
    
    # F4: ST / åŒ—äº¤æ‰€ / åœç‰Œ / æ— æˆäº¤
    clean_df = clean_df[~clean_df['name'].str.contains('ST|é€€', na=False)]
    clean_df = clean_df[~clean_df['ts_code'].str.startswith('4', na=False)]
    clean_df = clean_df[~clean_df['ts_code'].str.startswith('8', na=False)]
    clean_df = clean_df[(clean_df['vol'] > 0) & (clean_df['amount_yuan'] > 0)]
    
    st.write(f"ç¡¬æ€§è¿‡æ»¤åå€™é€‰æ•°é‡ï¼š{len(clean_df)} æ”¯ã€‚")
    if len(clean_df) == 0:
        st.error("ç¡¬æ€§è¿‡æ»¤åæ²¡æœ‰å€™é€‰ï¼Œè¯·æ”¾å®½ä¾§è¾¹æ æ¡ä»¶ã€‚")
        st.stop()
        
    # 5. é€ä¸ªè®¡ç®—æŒ‡æ ‡ä¸æ ¸å¿ƒè¿‡æ»¤ï¼ˆè€—æ—¶æ­¥éª¤ï¼‰
    st.write("ä¸ºå€™é€‰è‚¡é€ç¥¨è®¡ç®—æŒ‡æ ‡ï¼ˆMACD/RSI/è¶‹åŠ¿ï¼‰...")
    records = []
    pbar = st.progress(0)
    
    for idx, row in clean_df.iterrows():
        ts_code = row['ts_code']
        
        hist = get_hist_cached(ts_code, last_trade, days=60) # 60æ—¥å†å²æ•°æ®è¶³å¤Ÿ
        ind = compute_indicators(hist, MACD_FAST, MACD_SLOW, MACD_SIGNAL, RSI_PERIOD)
        
        # --- ç­–ç•¥æ ¸å¿ƒè¿‡æ»¤ï¼šMACD é‡‘å‰åçš„å›è°ƒä¹°ç‚¹ ---
        
        # F5: æ˜¨å¤© MACD å‘ç”Ÿé‡‘å‰ (è¶‹åŠ¿ç¡®è®¤)
        if not ind.get('macd_golden_yesterday', False):
            pbar.progress((idx+1)/len(clean_df))
            continue
            
        # F6: RSI ä¸­ä½å›è°ƒ (RSI < 50 è¡¨ç¤ºå›è°ƒä¹°ç‚¹)
        rsi_val = ind.get('rsi', np.nan)
        if pd.isna(rsi_val) or rsi_val >= 50.0:
            pbar.progress((idx+1)/len(clean_df))
            continue
            
        # F7: çŸ­æœŸæ¶¨å¹…é€‚ä¸­ (é¿å…è¶…é«˜å’Œè¶…ä½)
        d5_ret = ind.get('5d_return', np.nan)
        if pd.isna(d5_ret) or d5_ret > 10.0 or d5_ret < -10.0:
             pbar.progress((idx+1)/len(clean_df))
             continue

        # --- åˆå¹¶æŒ‡æ ‡ï¼Œå‡†å¤‡è¯„åˆ† ---
        row_dict = row.to_dict()
        row_dict.update(ind)
        records.append(row_dict)
        pbar.progress((idx+1)/len(clean_df))
    
    pbar.progress(1.0)
    fdf = pd.DataFrame(records)
    fdf = fdf.dropna(subset=['rsi']).reset_index(drop=True)
    st.write(f"ç­–ç•¥æ ¸å¿ƒè¿‡æ»¤åï¼Œè¿›å…¥è¯„åˆ†é˜¶æ®µçš„å€™é€‰æ•°é‡ï¼š{len(fdf)} æ”¯ã€‚")
    if fdf.empty:
        st.error("æ‰€æœ‰è‚¡ç¥¨éƒ½è¢«è¿‡æ»¤ï¼Œè¯·æ”¾å®½ç­–ç•¥è¿‡æ»¤æ¡ä»¶ã€‚")
        st.stop()

    # 6. å½’ä¸€åŒ–ä¸è¯„åˆ† (åå¥½ RSI ä½ã€çŸ­æœŸå›è°ƒæµ…ã€MACDåŠ¨èƒ½å¼ºçš„)
    
    def norm_col(s, reverse=False):
        s = s.fillna(s.median()).replace([np.inf,-np.inf], np.nan).fillna(s.median())
        mn = s.min(); mx = s.max()
        if mx - mn < 1e-9:
            return pd.Series([0.5]*len(s), index=s.index)
        
        normalized = (s - mn) / (mx - mn)
        return 1 - normalized if reverse else normalized

    # å½’ä¸€åŒ–å­æŒ‡æ ‡ (s_rsi åè½¬ï¼Œè¶Šä½è¶Šå¥½)
    fdf['s_rsi'] = norm_col(fdf['rsi'], reverse=True)
    fdf['s_5d_ret'] = norm_col(fdf['5d_return'], reverse=True) # çŸ­æœŸè·Œå¹…è¶Šå¤§è¶Šå¥½
    fdf['s_macd_hist'] = norm_col(fdf['macd_hist'], reverse=False) # MACDåŠ¨èƒ½è¶Šå¼ºè¶Šå¥½
    fdf['s_vol'] = norm_col(fdf['vol'], reverse=False) # é‡èƒ½è¶Šå¤§è¶Šå¥½
    
    # æœ€ç»ˆç»¼åˆè¯„åˆ†ï¼ˆæƒé‡åˆ†é… - é‡ç‚¹å¢å¼º MACD/RSI/çŸ­æœŸå›è°ƒä¿¡å·ï¼‰
    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['s_rsi'] * 0.30 +         # RSI ä½ä½å›è°ƒ
        fdf['s_5d_ret'] * 0.30 +      # çŸ­æœŸå›è°ƒæ·±åº¦
        fdf['s_macd_hist'] * 0.20 +   # MACDåŠ¨èƒ½
        fdf['s_vol'] * 0.20            # é‡èƒ½æ”¯æŒ
    )

    # 7. æ’åºä¸å±•ç¤º
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index = fdf.index + 1
    
    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(20, len(fdf))}ã€‚")
    display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','rsi','5d_return','macd_hist','macd_diff','macd_dea','close','total_mv','amount_yuan']
    
    final_cols = [c for c in display_cols if c in fdf.columns]
    
    st.dataframe(fdf[final_cols].head(20), use_container_width=True)

# ---------------------------
# å†å²å›æµ‹éƒ¨åˆ†
# ---------------------------
@st.cache_data(ttl=3600)
def load_backtest_data(all_trade_dates):
    """é¢„åŠ è½½æ‰€æœ‰å›æµ‹æ—¥æœŸçš„ daily æ•°æ®ã€‚"""
    data_cache = {}
    st.write(f"æ­£åœ¨é¢„åŠ è½½å›æµ‹æ‰€éœ€ {len(all_trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„ daily æ•°æ®...")
    pbar = st.progress(0)
    for i, date in enumerate(all_trade_dates):
        daily_df = safe_get(pro.daily, trade_date=date)
        if not daily_df.empty:
            data_cache[date] = daily_df
        pbar.progress((i + 1) / len(all_trade_dates))
    pbar.progress(1.0)
    return data_cache

@st.cache_data(ttl=36000)
def get_stock_basic_filter(cache_breaker):
    """ä¸€æ¬¡æ€§åŠ è½½è‚¡ç¥¨åŸºç¡€æ•°æ®ï¼Œå¹¶æ„å»ºç¡¬è¿‡æ»¤çš„ç™½åå•"""
    _ = cache_breaker # ç¡®ä¿å‚æ•°ä¿®æ”¹æ—¶ç¼“å­˜åˆ·æ–°
    st.write("æ­£åœ¨æ„å»ºå›æµ‹çš„è‚¡ç¥¨ç™½åå•ï¼ˆST/åŒ—äº¤æ‰€è¿‡æ»¤ï¼‰...")
    
    df = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,list_date')
    if df.empty:
        return pd.DataFrame()
        
    df = df[~df['name'].str.contains('ST|é€€', na=False)]
    df = df[~df['ts_code'].str.startswith('4', na=False)]
    df = df[~df['ts_code'].str.startswith('8', na=False)]
    
    return df[['ts_code']]


# V4.6 æ ¸å¿ƒä¿®å¤ï¼šä¿®æ”¹å‚æ•°ç­¾åï¼Œä¼ å…¥æ¶¨è·Œå¹…å‚æ•°
@st.cache_data(ttl=6000)
def run_backtest(start_date, end_date, hold_days, backtest_top_k, 
                 bt_min_pct_chg, bt_max_pct_chg, cache_breaker): 
    
    _ = cache_breaker 

    trade_dates = get_trade_cal(start_date, end_date)
    
    if not trade_dates:
        return {h: {'returns': [], 'wins': 0, 'total': 0} for h in hold_days}

    results = {h: {'returns': [], 'wins': 0, 'total': 0} for h in hold_days}
    
    # ... (ç¡®å®šå›æµ‹æ—¥æœŸéƒ¨åˆ†ä¸å˜) ...
    bt_start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=BACKTEST_DAYS * 2)).strftime("%Y%m%d")
    buy_dates_pool = [d for d in trade_dates if d >= bt_start and d <= end_date]
    backtest_dates = buy_dates_pool[-BACKTEST_DAYS:]
    
    required_dates = set(backtest_dates)
    for buy_date in backtest_dates:
        try:
            current_index = trade_dates.index(buy_date)
            for h in hold_days:
                required_dates.add(trade_dates[current_index + h])
        except (ValueError, IndexError):
            continue
    
    # --- é˜¶æ®µä¸€ï¼šæ•°æ®æ‰¹é‡åŠ è½½ä¸é¢„å¤„ç† ---
    
    # 1. æ„å»ºç¡¬è¿‡æ»¤ç™½åå•
    basic_filter_df = get_stock_basic_filter(cache_breaker)
    if basic_filter_df.empty:
        st.error("æ— æ³•æ„å»ºè‚¡ç¥¨ç™½åå•ï¼Œè¯·æ£€æŸ¥Tushareæƒé™ã€‚")
        return {h: {'returns': [], 'wins': 0, 'total': 0} for h in hold_days}
    
    valid_ts_codes = set(basic_filter_df['ts_code'])
    
    # 2. é¢„åŠ è½½ daily æ•°æ® (æœ‰è¿›åº¦æ¡)
    data_cache = load_backtest_data(sorted(list(required_dates)))

    # ----------------------------------------------------
    # --- é˜¶æ®µäºŒï¼šå›æµ‹ä¸»å¾ªç¯ ---
    # ----------------------------------------------------
    
    st.write(f"æ­£åœ¨æ¨¡æ‹Ÿ {len(backtest_dates)} ä¸ªäº¤æ˜“æ—¥çš„å‡å€¼å›å½’é€‰è‚¡å›æµ‹...")
    pbar_bt = st.progress(0)
    
    # å›æµ‹å†…éƒ¨ä½¿ç”¨ MIN_AMOUNT (1äº¿) çš„ 2å€ä½œä¸ºæµåŠ¨æ€§è¿‡æ»¤ï¼ˆé¿å… Tushare çš„ daily_basic æ•°æ®ç¼ºå¤±ï¼‰
    BACKTEST_MIN_AMOUNT_PROXY = MIN_AMOUNT * 2.0
    
    for i, buy_date in enumerate(backtest_dates):
        daily_df_raw = data_cache.get(buy_date)
        
        if daily_df_raw is None or daily_df_raw.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue

        daily_df = daily_df_raw.copy()
        
        # 0. åˆå§‹è¿‡æ»¤ï¼šåªä¿ç•™ç™½åå•ä¸­çš„è‚¡ç¥¨
        daily_df = daily_df[daily_df['ts_code'].isin(valid_ts_codes)]
        
        # V4.6: è½¬æ¢æˆäº¤é¢ (Tushare amount æ˜¯åƒå…ƒ)
        daily_df['amount_yuan'] = daily_df['amount'].fillna(0) * 1000.0
        
        # 1. åº”ç”¨ç¡¬è¿‡æ»¤ (å›æµ‹æ¨¡å—åªåº”ç”¨æœ€æ ¸å¿ƒçš„è¿‡æ»¤æ¡ä»¶)
        
        # è¿‡æ»¤ï¼šå‡å€¼å›å½’ç­–ç•¥ï¼šå¯»æ‰¾å›è°ƒ/ç›˜æ•´çš„è‚¡ç¥¨
        daily_df = daily_df[
            # F1: ä»·æ ¼åŒºé—´ï¼ˆæ­¤å¤„ä½¿ç”¨ç¡¬ç¼–ç ï¼Œå› ä¸º MIN/MAX_PRICE æœªä¼ é€’åˆ°æ­¤å‡½æ•°ï¼‰
            (daily_df['close'] >= MIN_PRICE) & 
            (daily_df['close'] <= MAX_PRICE) &
            
            # F2: æˆäº¤é¢æµåŠ¨æ€§ï¼ˆåŒå€è¿‡æ»¤ï¼‰
            (daily_df['amount_yuan'] >= BACKTEST_MIN_AMOUNT_PROXY) & 

            # F3: æ¶¨è·Œå¹…åŒºé—´ï¼ˆæ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨ä¾§è¾¹æ å‚æ•°ï¼‰
            (daily_df['pct_chg'] >= bt_min_pct_chg) & 
            (daily_df['pct_chg'] <= bt_max_pct_chg) & 
            
            # F4: åœç‰Œ/æ— æˆäº¤
            (daily_df['vol'] > 0) & 
            (daily_df['amount_yuan'] > 0)
        ].copy()
        
        # 2. ç­–ç•¥è¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼šæŒ‰ MACD é‡‘å‰åçš„å›è°ƒå¼ºåº¦æ’åºï¼‰
        # å‡å€¼å›å½’ç­–ç•¥ï¼šç”±äºæ— æ³•åœ¨å›æµ‹ä¸­é€æ—¥è®¡ç®— MACD/RSIï¼Œæˆ‘ä»¬ä½¿ç”¨ä»£ç†è¯„åˆ†ã€‚
        # ä»£ç†è¯„åˆ†ï¼šå¯»æ‰¾å›è°ƒ/ç›˜æ•´ï¼ˆä½ pct_chgï¼‰ï¼Œä½†æˆäº¤é‡ (vol) ç›¸å¯¹è¾ƒé«˜çš„è‚¡ç¥¨ã€‚
        # pct_chg * (-1) å¥–åŠ±è·Œå¹…ï¼Œvol å¥–åŠ±æµåŠ¨æ€§
        daily_df['score_proxy'] = (daily_df['pct_chg'] * -1) * daily_df['vol']
        
        scored_stocks = daily_df.sort_values("score_proxy", ascending=False).head(backtest_top_k).copy()
        
        for _, row in scored_stocks.iterrows():
            ts_code = row['ts_code']
            buy_price = float(row['close'])
            
            if pd.isna(buy_price) or buy_price <= 0: continue

            for h in hold_days:
                try:
                    current_index = trade_dates.index(buy_date)
                    sell_date = trade_dates[current_index + h]
                except (ValueError, IndexError):
                    continue
        
                # ä»ç¼“å­˜ä¸­æŸ¥æ‰¾å–å‡ºä»·æ ¼
                sell_df_cached = data_cache.get(sell_date)
                sell_price = np.nan
                if sell_df_cached is not None and ts_code in sell_df_cached['ts_code'].values:
                    sell_price = sell_df_cached[sell_df_cached['ts_code'] == ts_code]['close'].iloc[0]
                
                # æ£€æŸ¥å–å‡ºæ—¥æ˜¯å¦åœç‰Œæˆ–æ•°æ®ç¼ºå¤±
                if pd.isna(sell_price) or sell_price <= 0: continue
                
                ret = (sell_price / buy_price) - 1.0
                results[h]['total'] += 1
                results[h]['returns'].append(ret)
                if ret > 0:
                    results[h]['wins'] += 1

        pbar_bt.progress((i+1)/len(backtest_dates))

    pbar_bt.progress(1.0)
    
    final_results = {}
    for h, res in results.items():
        total = res['total']
        if total > 0:
            avg_return = np.mean(res['returns']) * 100.0
            win_rate = (res['wins'] / total) * 100.0
        else:
            avg_return = 0.0
            win_rate = 0.0
             
        final_results[h] = {
            'å¹³å‡æ”¶ç›Šç‡ (%)': f"{avg_return:.2f}",
            'èƒœç‡ (%)': f"{win_rate:.2f}",
            'æ€»äº¤æ˜“æ¬¡æ•°': total
        }
        
    return final_results

# ---------------------------
# å›æµ‹æ‰§è¡Œ
# ---------------------------
if st.checkbox("âœ… è¿è¡Œå†å²å›æµ‹", value=False):
    if not HOLD_DAYS_OPTIONS:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå›æµ‹æŒè‚¡å¤©æ•°ã€‚")
    else:
        st.header("ğŸ“ˆ å†å²å›æµ‹ç»“æœï¼ˆä¹°å…¥æ”¶ç›˜ä»· / å–å‡ºæ”¶ç›˜ä»·ï¼‰")
        
        try:
            start_date_for_cal = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
        except:
            start_date_for_cal = (datetime.now() - timedelta(days=200)).strftime("%Y%m%d")
            
        # V4.6 ä¿®å¤ï¼šä¼ å…¥ BT_MIN_PCT_FOR_CACHE å’Œ BT_MAX_PCT_FOR_CACHE
        backtest_result = run_backtest(
            start_date=start_date_for_cal,
            end_date=last_trade,
            hold_days=HOLD_DAYS_OPTIONS,
            backtest_top_k=BACKTEST_TOP_K,
            bt_min_pct_chg=BT_MIN_PCT_FOR_CACHE, # ä¼ å…¥æœ€ä½æ¶¨å¹…
            bt_max_pct_chg=BT_MAX_PCT_FOR_CACHE, # ä¼ å…¥æœ€é«˜æ¶¨å¹…
            cache_breaker=CACHE_BREAKER # ä¼ å…¥ç¼“å­˜ç ´åé”®
        )

        bt_df = pd.DataFrame(backtest_result).T
        bt_df.index.name = "æŒè‚¡å¤©æ•°"
        bt_df = bt_df.reset_index()
        bt_df['æŒè‚¡å¤©æ•°'] = bt_df['æŒè‚¡å¤©æ•°'].astype(str) + ' å¤©'
        
        st.dataframe(bt_df, use_container_width=True, hide_index=True)
        st.success("å›æµ‹å®Œæˆï¼")
        
        # ... (ä¸‹è½½æŒ‰é’®ä»£ç ä¸å˜) ...
        export_df = bt_df.copy()
        export_df.columns = ['HoldDays', 'AvgReturn', 'WinRate', 'TotalTrades']
        out_csv_bt = export_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "ä¸‹è½½å›æµ‹ç»“æœ CSV", 
            data=out_csv_bt, 
            file_name=f"backtest_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
