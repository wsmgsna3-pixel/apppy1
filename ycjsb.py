# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.25 ç»å…¸å¤åˆ»ç‰ˆ (å†…æ ¸V30.24 + ç»å…¸ä»ªè¡¨ç›˜)
æ ¸å¿ƒç†å¿µï¼š
1. [å†…æ ¸] æ²¿ç”¨ V30.24 çš„å…¨å¸‚åœºæ‰«æã€çº¯ç²¹è¯„åˆ†(MACD/Price)ã€å¤§ç›˜é£æ§ã€å»ä¸€å­—æ¿ã€‚
2. [ç•Œé¢] æ¢å¤ V30.22 çš„ç»å…¸æŒ‡æ ‡å¡è®¾è®¡ (D+1/D+3/D+5)ã€‚
3. [çµæ´»] ä¾§è¾¹æ å¢åŠ "æ¯æ—¥æŒä»“æ•°é‡"æ§åˆ¶ï¼Œç”±ç”¨æˆ·å†³å®šåªä¹°ç¬¬ä¸€åè¿˜æ˜¯å‰ä¸‰åã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time

# ---------------------------
# é¡µé¢é…ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· V30.25 ç»å…¸å¤åˆ»ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ Â· V30.25 ç»å…¸å¤åˆ»ç‰ˆ (ğŸ›¡ï¸ é£æ§å†…æ ¸ + ğŸ“Š ç»å…¸æŠ¥è¡¨)")
st.markdown("""
**ğŸ“ ç‰ˆæœ¬è¯´æ˜ï¼š**
* **å†…æ ¸ï¼š** ä¿æŒ V30.24 çš„æœ€å¼ºé€»è¾‘ (å…¨æ‰«æ + çº¯è¯„åˆ† + å¤§ç›˜é£æ§)ã€‚
* **äº¤äº’ï¼š** ä¾§è¾¹æ å¯è°ƒæ•´ **Top K** (å»ºè®®è®¾ä¸º 1)ã€‚
* **å±•ç¤ºï¼š** æ¢å¤ç»å…¸çš„æ”¶ç›Šç‡/èƒœç‡ä»ªè¡¨ç›˜ã€‚
""")

# ---------------------------
# å…¨å±€ç¼“å­˜
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 
GLOBAL_INDEX_DATA = pd.DataFrame() 

# ---------------------------
# åŸºç¡€å·¥å…·å‡½æ•°
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        if kwargs.get('is_index'): df = pro.index_daily(**kwargs)
        else: df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 5)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty or 'is_open' not in cal.columns:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ã€‚")
        return []
    return cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# æ•°æ®ä¸‹è½½
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_INDEX_DATA
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # 1. ä¸‹è½½å¤§ç›˜æ•°æ® (ä¸Šè¯æŒ‡æ•°) ç”¨äºé£æ§
    start_date_idx = (datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=60)).strftime("%Y%m%d")
    end_date_idx = (datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=10)).strftime("%Y%m%d")
    
    with st.spinner("æ­£åœ¨è·å–å¤§ç›˜æŒ‡æ•°æ•°æ®..."):
        GLOBAL_INDEX_DATA = safe_get('index_daily', ts_code='000001.SH', start_date=start_date_idx, end_date=end_date_idx)
        if not GLOBAL_INDEX_DATA.empty:
            GLOBAL_INDEX_DATA = GLOBAL_INDEX_DATA.sort_values('trade_date').set_index('trade_date')
            GLOBAL_INDEX_DATA['ma20'] = GLOBAL_INDEX_DATA['close'].rolling(window=20).mean()

    # 2. ä¸‹è½½ä¸ªè‚¡æ•°æ®
    start_date = (datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    end_date = (datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=25)).strftime("%Y%m%d") 
    
    all_dates = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')['cal_date'].tolist()
    st.info(f"â³ æ­£åœ¨æŒ‰æ—¥æœŸä¸‹è½½ {start_date} åˆ° {end_date} å…¨å¸‚åœºæ•°æ®...")

    adj_list, daily_list = [], []
    download_progress = st.progress(0, text="ä¸‹è½½è¿›åº¦...")
    
    total_dates = len(all_dates)
    for i, date in enumerate(all_dates):
        try:
            cached_data = fetch_and_cache_daily_data(date)
            if not cached_data['adj'].empty: adj_list.append(cached_data['adj'])
            if not cached_data['daily'].empty: daily_list.append(cached_data['daily'])
            if i % 5 == 0: 
                download_progress.progress((i + 1) / total_dates)
        except: continue 
    download_progress.empty()

    if not adj_list or not daily_list:
        st.error("æ— æ³•è·å–å†å²æ•°æ®ã€‚")
        return False
        
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    cols_to_keep = ['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'vol']
    valid_cols = [c for c in cols_to_keep if c in daily_list[0].columns]
    daily_raw = pd.concat(daily_list)[valid_cols]
    
    for col in ['open', 'high', 'low', 'close', 'pre_close', 'vol']:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_global_date:
        try:
            latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
        except: GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True

# ----------------------------------------------------------------------
# å¤æƒæ•°æ®æå–
# ----------------------------------------------------------------------
def get_qfq_data_v4(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    if GLOBAL_DAILY_RAW.empty or GLOBAL_ADJ_FACTOR.empty: return pd.DataFrame()
        
    base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(base_adj) or base_adj < 1e-9: return pd.DataFrame() 

    try:
        daily = GLOBAL_DAILY_RAW.loc[(ts_code, slice(start_date, end_date)), :]
        adj = GLOBAL_ADJ_FACTOR.loc[(ts_code, slice(start_date, end_date)), 'adj_factor']
    except KeyError: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    
    df = daily.join(adj, how='left').dropna(subset=['adj_factor'])
    
    factor = df['adj_factor'] / base_adj
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns: df[col] = df[col] * factor
    
    df = df.reset_index()
    df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
    return df.set_index('trade_date').sort_index()[['open', 'high', 'low', 'close', 'pre_close', 'vol']]

# ----------------------------------------------------------------------
# æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data_v4(ts_code, start_date=start_date, end_date=end_date)
    res = {}
    if df.empty or len(df) < 26: return res
         
    close = df['close']
    vol = df['vol']
    
    # æš´åŠ› MACD (8, 17, 5)
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=5, adjust=False).mean()
    macd_val = (diff - dea) * 2
    
    res['macd_val'] = macd_val.iloc[-1]
    
    ma20 = close.rolling(window=20).mean()
    ma5_vol = vol.rolling(window=5).mean()
    
    res['close_current'] = close.iloc[-1]
    res['ma20_current'] = ma20.iloc[-1] if not pd.isna(ma20.iloc[-1]) else 0
    res['vol_current'] = vol.iloc[-1]
    res['ma5_vol_current'] = ma5_vol.iloc[-1] if not pd.isna(ma5_vol.iloc[-1]) else 0
    
    return res

# ----------------------------------------------------------------------
# æœªæ¥æ”¶ç›Šè®¡ç®—
# ----------------------------------------------------------------------
def get_future_returns(ts_code, selection_date, buy_threshold_pct=1.5):
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_future = (d0 + timedelta(days=20)).strftime("%Y%m%d")
    
    hist = get_qfq_data_v4(ts_code, start_date=start_future, end_date=end_future)
    results = {'Return_D1': np.nan, 'Return_D3': np.nan, 'Return_D5': np.nan}

    if hist.empty: return results
    d1_data = hist.iloc[0]
    
    # å®æˆ˜æ¨¡æ‹Ÿï¼šæ‹’ç»ä½å¼€
    if d1_data['open'] <= d1_data['pre_close']: return results 
    
    # å®æˆ˜æ¨¡æ‹Ÿï¼šç›˜ä¸­å¿…é¡»è§¦åŠ +1.5% æ‰èƒ½æˆäº¤
    buy_price = d1_data['open'] * (1 + buy_threshold_pct / 100.0)
    if d1_data['high'] < buy_price: return results 

    # è®¡ç®—æ”¶ç›Š
    for n in [1, 3, 5]:
        idx = n - 1
        if len(hist) > idx:
            results[f'Return_D{n}'] = (hist.iloc[idx]['close'] / buy_price - 1) * 100
            
    return results

# ----------------------------------------------------
# ä¾§è¾¹æ è®¾ç½®
# ----------------------------------------------------
with st.sidebar:
    st.header("1. å›æµ‹å‚æ•°")
    backtest_date_end = st.date_input("ç»“æŸæ—¥æœŸ", value=datetime.now().date(), max_value=datetime.now().date())
    BACKTEST_DAYS = int(st.number_input("å›æµ‹å¤©æ•°", value=50, step=1))
    
    st.markdown("---")
    st.header("2. ç­–ç•¥æ§åˆ¶")
    # [æ¢å¤] æ¯æ—¥æŒä»“æ•°é‡è°ƒæ•´
    TOP_BACKTEST = int(st.number_input("æ¯æ—¥æŒä»“æ•°é‡ (Top K)", value=1, min_value=1, max_value=10, help="å»ºè®®è®¾ä¸º1ï¼Œåªä¹°æœ€å¼ºçš„é‚£åª"))
    BUY_THRESHOLD = st.number_input("ä¹°å…¥è§¦å‘æ¶¨å¹…(%)", value=1.5)

    st.markdown("---")
    st.header("3. é€‰è‚¡é—¨æ§›")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»·", value=20.0, step=1.0) 
    MAX_PRICE = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0, step=5.0)
    MIN_CIRC_MV = st.number_input("æœ€ä½æµé€šå¸‚å€¼(äº¿)", value=30.0, step=5.0) 

    st.markdown("---")
    st.info("âš ï¸ å·²å¯ç”¨å¤§ç›˜é£æ§ (MA20)ã€‚")

TS_TOKEN = st.text_input("Tushare Token", type="password")
if not TS_TOKEN: st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ----------------------------------------------------------------------
# V30.25 æ ¸å¿ƒé€»è¾‘ï¼šå…¨æ‰«æ + çº¯ç²¹è¯„åˆ† + Top Kæˆªå–
# ----------------------------------------------------------------------
def run_backtest_daily(date_str, top_k):
    # 1. å¤§ç›˜é£æ§
    if not GLOBAL_INDEX_DATA.empty and date_str in GLOBAL_INDEX_DATA.index:
        idx_today = GLOBAL_INDEX_DATA.loc[date_str]
        if idx_today['close'] < idx_today['ma20']:
            return pd.DataFrame(), "ğŸ›¡ï¸ å¤§ç›˜ç ´ä½ï¼Œç³»ç»Ÿç©ºä»“"
    
    # 2. è·å–æ•°æ®
    daily = safe_get('daily', trade_date=date_str)
    if daily.empty: return pd.DataFrame(), "æ•°æ®ç¼ºå¤±"
    
    # 3. åŸºç¡€è¿‡æ»¤
    pool = daily.copy()
    pool['close'] = pd.to_numeric(pool['close'], errors='coerce')
    d_basic = safe_get('daily_basic', trade_date=date_str, fields='ts_code,circ_mv,turnover_rate')
    if d_basic.empty: return pd.DataFrame(), "åŸºç¡€æ•°æ®ç¼ºå¤±"
    pool = pool.merge(d_basic, on='ts_code', how='inner')
    
    # 3.1 ä»·æ ¼/å¸‚å€¼/æ¿å—è¿‡æ»¤
    pool = pool[(pool['close'] >= MIN_PRICE) & (pool['close'] <= MAX_PRICE)]
    pool['circ_mv_billion'] = pool['circ_mv'] / 10000 
    pool = pool[pool['circ_mv_billion'] >= MIN_CIRC_MV]
    pool = pool[~pool['ts_code'].str.startswith(('8', '4', '92'))] 
    
    # 3.2 å»ä¸€å­—æ¿
    pool = pool[~((pool['high'] == pool['low']) & (pool['pct_chg'] > 9.0))]

    # 3.3 å…¨æ‰«æ (æ¶¨å¹…>0)
    candidates = pool[pool['pct_chg'] > 0]
    
    if len(candidates) > 400:
        candidates = candidates.sort_values('pct_chg', ascending=False).head(400)
    
    if candidates.empty: return pd.DataFrame(), "æ— åˆé€‰è‚¡ç¥¨"

    # 4. è®¡ç®— MACD
    records = []
    for row in candidates.itertuples():
        ind = compute_indicators(row.ts_code, date_str)
        
        if ind.get('close_current', 0) <= ind.get('ma20_current', 0): continue
        if ind.get('vol_current', 0) <= ind.get('ma5_vol_current', 0) * 1.2: continue
        if pd.isna(ind.get('macd_val')) or ind.get('macd_val') <= 0: continue
        
        future = get_future_returns(row.ts_code, date_str, buy_threshold_pct=BUY_THRESHOLD)
        
        # çº¯è¯„åˆ†
        score = (ind['macd_val'] / row.close) * 100000
        
        records.append({
            'ts_code': row.ts_code,
            'Close': row.close,
            'Pct_Chg': row.pct_chg,
            'MACD': ind['macd_val'],
            'Score': score,
            'Return_D1': future['Return_D1'],
            'Return_D3': future['Return_D3'],
            'Return_D5': future['Return_D5']
        })
    
    if not records: return pd.DataFrame(), "æ— è¾¾æ ‡è‚¡ç¥¨"
    
    # 5. [æ¢å¤] æ ¹æ®ç”¨æˆ·è®¾å®šçš„ Top K è¿›è¡Œæˆªå–
    df_res = pd.DataFrame(records)
    df_res = df_res.sort_values('Score', ascending=False).head(top_k)
    
    return df_res, "Success"

# ---------------------------
# ä¸»ç¨‹åº
# ---------------------------
if st.button(f"ğŸš€ è¿è¡Œ V30.25 å›æµ‹ (Top {TOP_BACKTEST})"):
    trade_days = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
    if not trade_days: st.stop()
    if not get_all_historical_data(trade_days): st.stop()
    
    st.success(f"âœ… V30.25 å¯åŠ¨ | æ¯æ—¥æŒä»“: Top {TOP_BACKTEST} | é£æ§: å¼€å¯")
    results = []
    bar = st.progress(0)
    status_text = st.empty()
    
    for i, date in enumerate(trade_days):
        status_text.text(f"æ­£åœ¨åˆ†æ: {date} ...")
        try:
            # ä¼ å…¥ TOP_BACKTEST å‚æ•°
            df, msg = run_backtest_daily(date, TOP_BACKTEST)
            if not df.empty:
                df['Trade_Date'] = date
                results.append(df)
        except Exception: pass
        bar.progress((i + 1) / len(trade_days))
    
    bar.empty()
    status_text.text("å›æµ‹å®Œæˆï¼")
    
    if not results:
        st.warning("åŒºé—´å†…æ— äº¤æ˜“æˆ–å¤§ç›˜ä¸€ç›´å¤„äºé¿é™©çŠ¶æ€ã€‚")
        st.stop()
        
    all_res = pd.concat(results)
    if all_res['Trade_Date'].dtype != 'object': all_res['Trade_Date'] = all_res['Trade_Date'].astype(str)
    
    # [æ¢å¤] ç»å…¸çš„æŒ‡æ ‡å¡æ ·å¼
    st.header(f"ğŸ“Š V30.25 å›æµ‹æŠ¥å‘Š (Top {TOP_BACKTEST})")
    
    # ç»Ÿè®¡é€»è¾‘ï¼šè®¡ç®—æ‰€æœ‰å…¥é€‰è‚¡ç¥¨çš„å¹³å‡è¡¨ç°
    # å¦‚æœ Top K = 1ï¼Œå°±æ˜¯ç¬¬ä¸€åçš„è¡¨ç°
    # å¦‚æœ Top K = 3ï¼Œå°±æ˜¯å‰ä¸‰åçš„å¹³å‡è¡¨ç°
    valid_days = all_res['Trade_Date'].nunique()
    total_trades = len(all_res.dropna(subset=['Return_D1']))
    
    st.markdown(f"**æœ‰æ•ˆäº¤æ˜“å¤©æ•°ï¼š** {valid_days} å¤© | **æ€»æˆäº¤ç¬”æ•°ï¼š** {total_trades} ç¬”")

    cols = st.columns(3)
    for idx, n in enumerate([1, 3, 5]):
        col = f'Return_D{n}'
        valid = all_res.dropna(subset=[col])
        if not valid.empty:
            avg_ret = valid[col].mean()
            hit_rate = (valid[col] > 0).sum() / len(valid) * 100
            count = len(valid)
        else: avg_ret, hit_rate, count = 0, 0, 0
        with cols[idx]:
            st.metric(f"D+{n} æ”¶ç›Š / èƒœç‡", f"{avg_ret:.2f}% / {hit_rate:.1f}%", help=f"æ ·æœ¬æ•°ï¼š{count}")

    st.header("ğŸ“‹ æ¯æ—¥æˆäº¤æ˜ç»†")
    st.dataframe(all_res.sort_values('Trade_Date', ascending=False), use_container_width=True)
