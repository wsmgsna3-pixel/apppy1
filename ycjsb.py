import streamlit as st
import tushare as ts
import pandas as pd
import datetime
import os
import time
from tenacity import retry, stop_after_attempt, wait_fixed

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="æ½œä¼åº•çªç ´ç­–ç•¥", page_icon="ğŸ²", layout="wide")

st.title("ğŸ² Aè‚¡æ½œä¼åº•çªç ´ç³»ç»Ÿ (Stage 2 Breakout)")
st.markdown("### æ ¸å¿ƒç­–ç•¥ï¼š60æ—¥æ½œä¼å¹³å° + å€é‡åˆ›æœºé«˜ + ç­¹ç é”å®š -> åªé€‰ Top 5")

# æ–‡ä»¶è·¯å¾„
CACHE_FILE = "scan_result_stage2.csv"
HISTORY_FILE = "scan_history_stage2.txt"

# ================= 2. ä¸»ç•Œé¢ï¼šTokenè¾“å…¥ =================
st.info("ğŸ‘‡ è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„ Tushare Token")
my_token = st.text_input("Tushare Token", type="password", key="token_main", placeholder="åœ¨æ­¤ç²˜è´´ Token...")

# ================= 3. ä¾§è¾¹æ ï¼šå‚æ•°è®¾ç½® =================
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°æ§åˆ¶å°")
    
    st.divider()
    st.subheader("ğŸ—“ï¸ æ¨¡å¼é€‰æ‹©")
    mode = st.radio("è¿è¡Œæ¨¡å¼", ["å•æ—¥æ‰«æ", "åŒºé—´å›æµ‹"], index=0)
    
    if mode == "å•æ—¥æ‰«æ":
        default_date = datetime.date.today() - datetime.timedelta(days=1)
        if datetime.date.today().weekday() == 0:
            default_date = datetime.date.today() - datetime.timedelta(days=3)
        selected_date = st.date_input("é€‰æ‹©æ—¥æœŸ", default_date)
        start_date_str = selected_date.strftime('%Y%m%d')
        end_date_str = start_date_str
    else:
        default_start = datetime.date(2025, 9, 1)
        c1, c2 = st.columns(2)
        with c1: d1 = st.date_input("å¼€å§‹", default_start)
        with c2: d2 = st.date_input("ç»“æŸ", datetime.date.today())
        start_date_str = d1.strftime('%Y%m%d')
        end_date_str = d2.strftime('%Y%m%d')

    st.divider()
    st.subheader("ğŸ¯ ç­›é€‰æ ‡å‡†")
    st.write("å·²é”å®šç­–ç•¥ï¼šæ½œä¼åº•çªç ´")
    
    # å¢åŠ æ‰«ææ ·æœ¬ï¼Œå› ä¸ºæˆ‘ä»¬è¦è¿‡æ»¤æ‰ç»å¤§å¤šæ•°å‡çªç ´
    scan_limit = st.slider("åˆç­›æ´»è·ƒè‚¡æ•°é‡", 200, 5000, 1000, step=50, help="ä¸ºäº†æ‰¾åˆ°çœŸæ­£çªç ´çš„ç¥¨ï¼Œåˆç­›èŒƒå›´å»ºè®®å¤§ä¸€ç‚¹")
    
    col_p1, col_p2 = st.columns(2)
    with col_p1:
        min_p = st.number_input("æœ€ä½ä»·(å…ƒ)", value=8.0)
        min_mv = st.number_input("æœ€å°å¸‚å€¼(äº¿)", value=30.0)
    with col_p2:
        max_p = st.number_input("æœ€é«˜ä»·(å…ƒ)", value=300.0)
        max_mv = st.number_input("æœ€å¤§å¸‚å€¼(äº¿)", value=2000.0)

    st.divider()
    if st.button("ğŸ—‘ï¸ å½»åº•æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
        if os.path.exists(CACHE_FILE): os.remove(CACHE_FILE)
        if os.path.exists(HISTORY_FILE): os.remove(HISTORY_FILE)
        st.toast("ç¼“å­˜å·²æ¸…ç©ºï¼Œä¸€åˆ‡é‡æ–°å¼€å§‹ï¼")

# ================= 4. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def get_trade_cal(pro, start, end):
    df = pro.trade_cal(exchange='', start_date=start, end_date=end, is_open='1')
    return df['cal_date'].tolist()

@retry(stop=stop_after_attempt(3), wait=wait_fixed(0.5))
def fetch_chips_safe(pro, ts_code, trade_date):
    return pro.cyq_perf(ts_code=ts_code, start_date=trade_date, end_date=trade_date)

def save_result_to_csv(item_list):
    # æ‰¹é‡ä¿å­˜ Top 5
    if not item_list: return
    df = pd.DataFrame(item_list)
    if not os.path.exists(CACHE_FILE):
        df.to_csv(CACHE_FILE, index=False, encoding='utf-8-sig')
    else:
        df.to_csv(CACHE_FILE, mode='a', header=False, index=False, encoding='utf-8-sig')

def mark_date_as_scanned(date_str):
    with open(HISTORY_FILE, 'a') as f:
        f.write(date_str + "\n")

def is_date_scanned(date_str):
    if os.path.exists(CACHE_FILE):
        try:
            df = pd.read_csv(CACHE_FILE)
            if str(date_str) in df['æ—¥æœŸ'].astype(str).values:
                return True
        except:
            pass
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r') as f:
            scanned_dates = f.read().splitlines()
            if str(date_str) in scanned_dates:
                return True
    return False

# --- æ‰¹é‡è·å– ---
def batch_get_daily(pro, codes, trade_date):
    try:
        chunk_size = 50
        all_df = []
        # è·å–è¿‡å»90å¤©æ•°æ®ï¼Œç”¨äºè®¡ç®—60æ—¥å‡çº¿å’Œå¹³å°æ–°é«˜
        start_dt = pd.to_datetime(trade_date) - pd.Timedelta(days=130)
        start_date_fmt = start_dt.strftime('%Y%m%d')
        for i in range(0, len(codes), chunk_size):
            chunk = codes[i:i+chunk_size]
            codes_str = ",".join(chunk)
            df = pro.daily(ts_code=codes_str, start_date=start_date_fmt, end_date=trade_date)
            if not df.empty: all_df.append(df)
            time.sleep(0.1)
        if not all_df: return pd.DataFrame()
        return pd.concat(all_df)
    except:
        return pd.DataFrame()

# ================= 5. æ½œä¼åº•çªç ´é€»è¾‘ (Stage 2) =================

def filter_stage2_batch(df_daily_all, trade_date):
    """
    é€»è¾‘ä¸¥è‹›ï¼š
    1. æ½œä¼æœŸï¼šè¿‡å»60å¤©æ¶¨å¹… < 40% (æ‹’ç»å·²ç»å¤§æ¶¨çš„)
    2. è¶‹åŠ¿å¥½ï¼šClose > MA60
    3. çœŸçªç ´ï¼šä»Šæ—¥æ”¶ç›˜ä»·åˆ›60æ—¥æ–°é«˜ + é‡æ¯” > 2.5 + æ¶¨å¹… > 4%
    """
    results = {}
    if df_daily_all.empty: return {}
    
    grouped = df_daily_all.groupby('ts_code')
    
    for code, group in grouped:
        group = group.sort_values('trade_date')
        if group.iloc[-1]['trade_date'] != trade_date: continue
        
        # æ•°æ®é•¿åº¦è¦æ±‚
        if len(group) < 60: continue
        
        # å–æœ€è¿‘60ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®
        recent_60 = group.tail(60)
        today = recent_60.iloc[-1]
        
        # 1. æ½œä¼æœŸéªŒè¯ (Platform Check)
        # è®¡ç®—è¿‡å»60å¤©çš„åŒºé—´æ¶¨å¹… (ä¸å«ä»Šå¤©)
        past_59 = recent_60.iloc[:-1]
        if past_59.empty: continue
        
        start_price = past_59.iloc[0]['close']
        end_price = past_59.iloc[-1]['close']
        
        period_chg = (end_price - start_price) / start_price
        
        # æ½œä¼æœŸæ¶¨å¹…å¿…é¡»åœ¨ 0% åˆ° 40% ä¹‹é—´
        # <0 è¯´æ˜è¶‹åŠ¿å‘ä¸‹(ç†Šå¸‚)ï¼Œ>40 è¯´æ˜å·²ç»æ¶¨å¤ªé«˜äº†
        if not (0 < period_chg < 0.40): continue
        
        # 2. è¶‹åŠ¿éªŒè¯ (Trend Check)
        ma60 = recent_60['close'].mean()
        if today['close'] < ma60: continue
        
        # 3. çªç ´éªŒè¯ (Breakout Check)
        # 3.1 åˆ›æ–°é«˜ï¼šä»Šå¤©çš„æ”¶ç›˜ä»· > è¿‡å»59å¤©çš„æœ€é«˜æ”¶ç›˜ä»·
        # è¿™å°±è¿‡æ»¤æ‰äº†"å­¤ç‹¬çš„é«˜æŸ±å­"(å¦‚æœæ²¡æœ‰åˆ›æ–°é«˜)
        max_past_close = past_59['close'].max()
        if today['close'] <= max_past_close: continue
        
        # 3.2 çˆ†å‘åŠ›ï¼šé‡æ¯” > 2.5, æ¶¨å¹… > 4.0%
        if not (4.0 < today['pct_chg'] < 10.5): continue
        
        v_ma5 = past_59['vol'].tail(5).mean()
        if v_ma5 == 0: continue
        vol_ratio = today['vol'] / v_ma5
        
        if vol_ratio < 2.5: continue
        
        results[code] = {
            'vol_ratio': round(vol_ratio, 2), 
            'pct_chg': today['pct_chg'],
            'period_chg': round(period_chg * 100, 1), # æ½œä¼æœŸæ¶¨å¹…
            'close': today['close']
        }
            
    return results

def get_sorted_pool(_pro, trade_date, _min_p, _max_p, _min_mv, _max_mv):
    try:
        # åŸºç¡€è¿‡æ»¤
        df_basic = _pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,list_date,market')
        df_basic = df_basic[~df_basic['name'].str.contains('ST|é€€')]
        df_basic = df_basic[~df_basic['ts_code'].str.contains('\.BJ')]
        limit_date = pd.to_datetime(trade_date) - pd.Timedelta(days=180)
        df_basic = df_basic[pd.to_datetime(df_basic['list_date']) < limit_date]
        
        # æˆäº¤é¢åˆç­›
        df_daily = _pro.daily(trade_date=trade_date, fields='ts_code,amount')
        df_basic_daily = _pro.daily_basic(trade_date=trade_date, fields='ts_code,circ_mv')
        
        if df_daily.empty or df_basic_daily.empty: return pd.DataFrame()
        
        df_merge = pd.merge(df_basic, df_daily, on='ts_code')
        df_merge = pd.merge(df_merge, df_basic_daily, on='ts_code')
        
        cond = (
            (df_merge['circ_mv'] >= _min_mv * 10000) & 
            (df_merge['circ_mv'] <= _max_mv * 10000)
        )
        pool = df_merge[cond]
        pool = pool.sort_values('amount', ascending=False)
        return pool
    except:
        return pd.DataFrame()

def calc_returns(pro, ts_code, buy_date):
    res = {'T+1': None, 'T+3': None, 'T+5': None}
    try:
        start_dt = pd.to_datetime(buy_date)
        end_check = (start_dt + pd.Timedelta(days=20)).strftime('%Y%m%d')
        df = pro.daily(ts_code=ts_code, start_date=buy_date, end_date=end_check)
        if df.empty or len(df) < 2: return res
        df = df.sort_values('trade_date').reset_index(drop=True)
        base = df.iloc[0]['close']
        if len(df) > 1: res['T+1'] = round((df.iloc[1]['close'] - base)/base*100, 2)
        if len(df) > 3: res['T+3'] = round((df.iloc[3]['close'] - base)/base*100, 2)
        if len(df) > 5: res['T+5'] = round((df.iloc[5]['close'] - base)/base*100, 2)
    except:
        pass
    return res

# ================= 6. ä¸»ç¨‹åº =================

if st.button("ğŸš€ å¯åŠ¨æ½œä¼åº•æ‰«æ", type="primary"):
    if not my_token:
        st.error("ğŸš¨ è¯·è¾“å…¥ Tokenï¼")
        st.stop()
        
    ts.set_token(my_token)
    pro = ts.pro_api()
    trade_dates = get_trade_cal(pro, start_date_str, end_date_str)
    
    if not trade_dates:
        st.error("âŒ æ— äº¤æ˜“æ—¥")
        st.stop()
        
    dashboard_placeholder = st.empty()
    progress_bar = st.progress(0)
    status_box = st.status("æ­£åœ¨é›·è¾¾æ‰«æ...", expanded=True)
    log_area = st.empty()

    for i, t_date in enumerate(trade_dates):
        if is_date_scanned(t_date):
            status_box.write(f"âš¡ï¸ {t_date} å·²è·³è¿‡...")
            progress_bar.progress((i+1)/len(trade_dates))
            continue
            
        status_box.write(f"ğŸ“† [{i+1}/{len(trade_dates)}] æ‰«æ {t_date} (æ½œä¼åº•+åˆ›æ–°é«˜) ...")
        progress_bar.progress((i)/len(trade_dates))
        
        # 1. åŸºç¡€æ± 
        pool = get_sorted_pool(pro, t_date, min_p, max_p, min_mv, max_mv)
        if pool.empty: 
            mark_date_as_scanned(t_date)
            continue
            
        target_codes = pool['ts_code'].tolist()[:scan_limit]
        
        # 2. æ‰¹é‡æ—¥çº¿ (åˆ¤æ–­æ½œä¼æœŸå’Œçªç ´)
        df_daily_all = batch_get_daily(pro, target_codes, t_date)
        
        # 3. æ ¸å¿ƒç­›é€‰ï¼šStage 2 Breakout
        valid_map = filter_stage2_batch(df_daily_all, t_date)
        
        survivors = list(valid_map.keys())
        
        # 4. æŸ¥ç­¹ç  & æ‰“åˆ† & æ’åº (åªå–Top 5)
        daily_candidates = []
        
        for code in survivors:
            # æŸ¥ç­¹ç 
            df_chips = fetch_chips_safe(pro, code, t_date)
            win_rate = 0
            
            if df_chips is not None and not df_chips.empty:
                win_rate = df_chips.iloc[0]['winner_rate']
            
            # ã€è¿‡æ»¤ã€‘è·åˆ©ç›˜å¿…é¡» > 50% (è¯´æ˜å¥—ç‰¢ç›˜å°‘ï¼Œæ˜¯çœŸçªç ´)
            if win_rate > 50:
                vol_ratio = valid_map[code]['vol_ratio']
                period_chg = valid_map[code]['period_chg']
                
                # æ‰“åˆ†å…¬å¼
                # é‡æ¯”è¶Šå¤§è¶Šå¥½(çˆ†å‘)ï¼Œè·åˆ©ç›˜è¶Šé«˜è¶Šå¥½(ç¨³)ï¼Œæ½œä¼æœŸæ¶¨å¹…é€‚ä¸­å°±å¥½
                s1 = min(vol_ratio, 6.0) * 10
                s2 = min(win_rate, 100) * 0.4
                total_score = round(s1 + s2, 1)
                
                # è·å–åç§°
                row = pool[pool['ts_code']==code].iloc[0]
                
                daily_candidates.append({
                    "æ—¥æœŸ": t_date,
                    "ä»£ç ": code,
                    "åç§°": row['name'],
                    "ç»¼åˆå¾—åˆ†": total_score,
                    "é‡æ¯”": vol_ratio,
                    "è·åˆ©ç›˜%": round(win_rate, 1),
                    "æ½œä¼æ¶¨å¹…%": period_chg,
                    "ts_code": code # ä¸´æ—¶ç”¨
                })
        
        # 5. æ¯æ—¥ç»“ç®—ï¼šåªç•™ Top 5
        if daily_candidates:
            # æŒ‰å¾—åˆ†é™åº
            daily_candidates.sort(key=lambda x: x["ç»¼åˆå¾—åˆ†"], reverse=True)
            top_5_today = daily_candidates[:5]
            
            # è¡¥å……è®¡ç®—æ”¶ç›Šç‡ (åªç»™è¿™5ä¸ªç®—ï¼Œçœæµ)
            for item in top_5_today:
                ret = calc_returns(pro, item['ts_code'], t_date)
                item['T+1'] = ret['T+1']
                item['T+3'] = ret['T+3']
                item['T+5'] = ret['T+5']
                del item['ts_code'] # åˆ æ‰ä¸´æ—¶å­—æ®µ
                
                log_area.text(f"ğŸ² {t_date} æ“’é¾™: {item['åç§°']} (é‡æ¯”{item['é‡æ¯”']} åˆ›60æ—¥æ–°é«˜)")
            
            # å†™å…¥ CSV
            save_result_to_csv(top_5_today)
        
        mark_date_as_scanned(t_date)

    progress_bar.progress(100)
    status_box.update(label="æ‰«æå®Œæˆï¼", state="complete", expanded=False)
    
    # ================= 7. ä»ªè¡¨ç›˜ =================
    if os.path.exists(CACHE_FILE):
        try:
            df_all = pd.read_csv(CACHE_FILE)
            
            if mode == "å•æ—¥æ‰«æ":
                df_all = df_all[df_all['æ—¥æœŸ'].astype(str) == start_date_str]
                if df_all.empty:
                    st.warning(f"{start_date_str} æœªå‘ç°çªç ´ä¸ªè‚¡ã€‚")
                    st.stop()
            
            # é»˜è®¤æŒ‰å¾—åˆ†å±•ç¤º
            df_sorted = df_all.sort_values("ç»¼åˆå¾—åˆ†", ascending=False)
            
            # å…¨å‘¨æœŸæˆ˜æŠ¥
            def get_metrics(df, col):
                valid_df = df.dropna(subset=[col])
                if valid_df.empty: return 0.0, 0.0
                avg = valid_df[col].mean()
                win = (len(valid_df[valid_df[col] > 0]) / len(valid_df) * 100)
                return avg, win

            t1_avg, t1_win = get_metrics(df_sorted, 'T+1')
            t3_avg, t3_win = get_metrics(df_sorted, 'T+3')
            t5_avg, t5_win = get_metrics(df_sorted, 'T+5')
            
            with dashboard_placeholder.container():
                st.divider()
                st.markdown(f"## ğŸ“ˆ æ½œä¼åº•æˆ˜æŠ¥ (æ—¥æœŸ: {start_date_str})")
                
                k1, k2, k3 = st.columns(3)
                k1.metric("T+1 å¹³å‡æ”¶ç›Š", f"{t1_avg:.2f}%", f"èƒœç‡ {t1_win:.1f}%")
                k2.metric("T+3 å¹³å‡æ”¶ç›Š", f"{t3_avg:.2f}%", f"èƒœç‡ {t3_win:.1f}%", delta_color="normal")
                k3.metric("T+5 å¹³å‡æ”¶ç›Š", f"{t5_avg:.2f}%", f"èƒœç‡ {t5_win:.1f}%")
                
                st.markdown("### ğŸ† ç²¾è‹± Top 5 (æ¯æ—¥ä»…é€‰5åª)")
                st.dataframe(df_sorted, use_container_width=True)
                
                with open(CACHE_FILE, "rb") as f:
                    st.download_button("ğŸ“¥ ä¸‹è½½ç²¾åCSV", f, "breakout_result.csv")
        except Exception as e:
            st.error(f"è¯»å–ç»“æœå‡ºé”™: {e}")
