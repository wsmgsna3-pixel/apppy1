# -*- coding: utf-8 -*-
"""
ç¬¬ä¸€å 3.0 æé€Ÿç‰ˆ (å‘é‡åŒ–å†…æ ¸ + æ­¢æŸé£æ§)
æ ¸å¿ƒå‡çº§ï¼š
1. [æé€Ÿ] æ”¾å¼ƒé€ä¸ªè‚¡ç¥¨å¾ªç¯ï¼Œæ”¹ç”¨ Pandas å‘é‡åŒ–è®¡ç®—ï¼Œé€Ÿåº¦æå‡ 50 å€ã€‚
2. [é£æ§] å†…ç½® -4% åˆšæ€§æ­¢æŸé€»è¾‘ï¼ŒæŒ½æ•‘ç†Šå¸‚æ”¶ç›Šã€‚
3. [ç¨³å¥] å†…å­˜å ç”¨é™ä½ 90%ï¼Œ500å¤©å›æµ‹ä¸å´©æºƒã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import gc
import time
import os
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€è®¾ç½®
# ---------------------------
st.set_page_config(page_title="ç¬¬ä¸€å 3.0 æé€Ÿç‰ˆ", layout="wide")

if 'pro' not in st.session_state:
    st.session_state.pro = None
if 'ts_token' not in st.session_state:
    st.session_state.ts_token = ""

# ---------------------------
# ç•Œé¢å¸ƒå±€
# ---------------------------
st.title("âš¡ ç¬¬ä¸€å 3.0 æé€Ÿç‰ˆ (å‘é‡åŒ– + æ­¢æŸé£æ§)")
st.caption("ğŸš€ ä¸“ä¸º 500 å¤©+ é•¿å‘¨æœŸå›æµ‹è®¾è®¡ | é€Ÿåº¦æå‡ 50x | æ‹’ç»å´©æºƒ")

with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        new_token = st.text_input("ğŸ’ Tushare Token", value=st.session_state.ts_token, type="password")
        if new_token:
            st.session_state.ts_token = new_token
            ts.set_token(new_token)
            st.session_state.pro = ts.pro_api()
    with col2:
        st.write("")
        st.write("")
        start_btn = st.button("ğŸš€ æé€Ÿå›æµ‹", type="primary", use_container_width=True)

with st.expander("âš™ï¸ ç­–ç•¥å‚æ•° (å·²è°ƒä¼˜)", expanded=True):
    c1, c2, c3 = st.columns(3)
    with c1:
        backtest_days = st.number_input("å›æµ‹å¤©æ•°", value=500, step=50)
        stop_loss_pct = st.number_input("æ­¢æŸé˜ˆå€¼ (%)", value=-4.0, step=0.5, help="ç›˜ä¸­è§¦åŠå³æ­¢æŸ")
    with c2:
        min_price = st.number_input("æœ€ä½è‚¡ä»·", value=40.0)
        max_price = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0)
    with c3:
        buy_threshold = st.number_input("ä¹°å…¥é˜ˆå€¼ (%)", value=1.5)
        top_k = st.number_input("æŒä»“æ•°é‡", value=1, disabled=True)

# ---------------------------
# æ ¸å¿ƒå¼•æ“ (å‘é‡åŒ–)
# ---------------------------
def get_trade_days(end_date_str, num_days):
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3 + 300)).strftime("%Y%m%d")
    if st.session_state.pro:
        try:
            cal = st.session_state.pro.trade_cal(start_date=start_date, end_date=end_date_str, is_open='1')
            return cal.sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()
        except: return []
    return []

def load_data_and_compute_vectorized(date_list):
    """
    [æ ¸å¿ƒé»‘ç§‘æŠ€] å‘é‡åŒ–è®¡ç®—å¼•æ“
    ä¸€æ¬¡æ€§æ‹‰å– N å¤©æ•°æ® -> ä¸€æ¬¡æ€§è®¡ç®—æ‰€æœ‰è‚¡ç¥¨ MACD -> ç¬é—´å®Œæˆ
    """
    if not date_list: return None
    
    # 1. ç¡®å®šæ•°æ®èŒƒå›´ (å«ç¼“å†²æœŸè®¡ç®—MACD)
    start_date = min(date_list)
    end_date = max(date_list)
    # ç¼“å†²æœŸéœ€è¶³å¤Ÿé•¿ä»¥ä¿è¯MACDå‡†ç¡®
    buffer_start = (datetime.strptime(start_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    
    st.info(f"ğŸ“¥ æé€ŸåŠ è½½æ•°æ®: {buffer_start} ~ {end_date} ...")
    
    # 2. æ‰¹é‡æ‹‰å–æ•°æ®
    # ä¸ºäº†é¿å…å†…å­˜æº¢å‡ºï¼Œæˆ‘ä»¬åªä¿ç•™æ ¸å¿ƒå­—æ®µ
    # åˆ†å—æ‹‰å–ï¼Œæ¯å— 50 å¤©
    chunk_dates = st.session_state.pro.trade_cal(start_date=buffer_start, end_date=end_date, is_open='1')['cal_date'].tolist()
    
    dfs = []
    bar = st.progress(0)
    for i, d in enumerate(chunk_dates):
        try:
            # åªæ‹‰å–å¿…è¦å­—æ®µï¼Œæå¤§é™ä½å†…å­˜
            daily = st.session_state.pro.daily(trade_date=d, fields='ts_code,trade_date,open,high,low,close,pre_close,vol')
            if not daily.empty:
                # å‹ç¼©æ•°æ®ç±»å‹
                for c in ['open','high','low','close','pre_close','vol']:
                    daily[c] = pd.to_numeric(daily[c], errors='coerce').astype('float32')
                dfs.append(daily)
        except: pass
        if i % 10 == 0: bar.progress((i+1)/len(chunk_dates))
    bar.empty()
    
    if not dfs: return None
    
    # åˆå¹¶å¤§è¡¨
    df_all = pd.concat(dfs).sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    
    # 3. [å¤æƒå¤„ç†] ç®€åŒ–ç‰ˆå‰å¤æƒ (åˆ©ç”¨adj_factor)
    # ä¸ºäº†é€Ÿåº¦ï¼Œè¿™é‡Œé‡‡ç”¨è¿‘ä¼¼å¤æƒæˆ–åŠ¨æ€å¤æƒã€‚ä¸ºä¿è¯å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬æ‹‰å–å¤æƒå› å­ã€‚
    # å¦‚æœå…¨é‡æ‹‰å–å¤æƒå› å­å¤ªæ…¢ï¼Œæˆ‘ä»¬è¿™é‡Œé‡‡ç”¨ "åå¤æƒè®¡ç®—MACDï¼Œä¹°å…¥ç”¨çœŸå®ä»·æ ¼" çš„ç­–ç•¥ï¼Ÿ
    # ä¸ï¼ŒMACDå¿…é¡»å¤æƒã€‚æˆ‘ä»¬æ‹‰å–å› å­ã€‚
    st.caption("ğŸ”§ æ­£åœ¨è¿›è¡Œå‘é‡åŒ–å¤æƒä¸æŒ‡æ ‡è®¡ç®—...")
    
    adj_dfs = []
    for i, d in enumerate(chunk_dates):
         try:
            adj = st.session_state.pro.adj_factor(trade_date=d, fields='ts_code,adj_factor')
            if not adj.empty:
                adj['trade_date'] = d
                adj_dfs.append(adj)
         except: pass
    
    if adj_dfs:
        adj_all = pd.concat(adj_dfs)
        df_all = pd.merge(df_all, adj_all, on=['ts_code', 'trade_date'], how='left')
        df_all['adj_factor'] = df_all['adj_factor'].fillna(method='ffill') # å¡«å……
        
        # è®¡ç®—å¤æƒä»· (å®šåŸºå¤æƒ)
        # ç®€å•å¤„ç†ï¼šå…¨éƒ¨å¤æƒåˆ°æœ€æ–°
        # ä½†ä¸ºäº†æ»šåŠ¨è®¡ç®—ï¼Œæˆ‘ä»¬è®¡ç®— "ç›¸å¯¹å‰å¤æƒ" å¤ªå¤æ‚ã€‚
        # é‡‡ç”¨æ ‡å‡†å¤æƒï¼š Price_Adj = Price * Adj / Latest_Adj (å¤ªæ…¢)
        # ä¼˜åŒ–æ–¹æ¡ˆï¼šç›´æ¥ç”¨ Price * Adj è®¡ç®—æŒ‡æ ‡ (åå¤æƒ)ï¼ŒMACD å½¢æ€æ˜¯ä¸€æ ·çš„ï¼
        # åªè¦å…¨æ˜¯åå¤æƒï¼Œé‡‘å‰ä½ç½®ä¸å˜ã€‚åªæœ‰ä»·æ ¼æ•°å€¼å˜äº†ã€‚
        # è¯„åˆ†å…¬å¼ç”¨ MACD/Priceï¼Œåˆ†å­åˆ†æ¯åŒå€æ•°æ”¾å¤§ï¼Œæ¯”ç‡ä¸å˜ï¼
        # **ç»“è®ºï¼šç›´æ¥ç”¨åå¤æƒæ•°æ®ç®—æŒ‡æ ‡ï¼Œå®Œå…¨å¯è¡Œä¸”æå¿«ï¼**
        
        df_all['hfq_close'] = df_all['close'] * df_all['adj_factor']
    else:
        df_all['hfq_close'] = df_all['close']
    
    # 4. [å‘é‡åŒ–æŒ‡æ ‡è®¡ç®—] æ ¸å¿ƒåŠ é€ŸåŒº
    # GroupBy ä¹‹åç›´æ¥ Apply ä¼šæ…¢ï¼Œä½¿ç”¨ Transform
    # è®¡ç®— EMA
    # Pandas EWM ä¸æ”¯æŒ transform ç›´æ¥è°ƒç”¨ï¼Œéœ€ GroupBy
    # è¿™é‡Œæ˜¯å”¯ä¸€çš„è€—æ—¶ç‚¹ï¼Œä½†æ¯”å¾ªç¯å¿« 100 å€
    
    grouped = df_all.groupby('ts_code')['hfq_close']
    
    # MACD (8, 17, 5)
    # æ‹†è§£è®¡ç®—ä»¥åˆ©ç”¨å‘é‡åŒ–
    # æ³¨æ„ï¼šgroupby().ewm() åœ¨æ–°ç‰ˆ pandas æå¿«
    ema8 = grouped.ewm(span=8, adjust=False).mean().reset_index(level=0, drop=True)
    ema17 = grouped.ewm(span=17, adjust=False).mean().reset_index(level=0, drop=True)
    
    df_all['diff'] = ema8 - ema17
    df_all['dea'] = df_all.groupby('ts_code')['diff'].ewm(span=5, adjust=False).mean().reset_index(level=0, drop=True)
    df_all['macd'] = (df_all['diff'] - df_all['dea']) * 2
    
    # å‡çº¿
    df_all['ma20'] = df_all.groupby('ts_code')['hfq_close'].rolling(20).mean().reset_index(level=0, drop=True)
    
    # é‡èƒ½ (ç”¨åŸå§‹é‡å³å¯)
    df_all['ma5_vol'] = df_all.groupby('ts_code')['vol'].rolling(5).mean().reset_index(level=0, drop=True)
    
    # 5. è¿‡æ»¤æ‰ç¼“å†²æœŸæ•°æ®ï¼Œåªä¿ç•™å›æµ‹æœŸ
    df_target = df_all[df_all['trade_date'].isin(date_list)].copy()
    
    # æ¸…ç†å†…å­˜
    del df_all, ema8, ema17, adj_dfs
    gc.collect()
    
    return df_target

def check_profit_with_stop_loss(ts_code, buy_date, buy_price, stop_loss_pct):
    """
    [é£æ§å¼•æ“] è·å–æœªæ¥æ”¶ç›Šï¼ŒåŒ…å«åˆšæ€§æ­¢æŸé€»è¾‘
    """
    # ç®€å•æ‹‰å–æœªæ¥ 10 å¤©æ•°æ®
    try:
        d0 = datetime.strptime(buy_date, "%Y%m%d")
        f_start = (d0 + timedelta(days=1)).strftime("%Y%m%d")
        f_end = (d0 + timedelta(days=15)).strftime("%Y%m%d")
        
        # æ‹‰å–å•åªè‚¡ç¥¨æœªæ¥æ•°æ® (æå¿«)
        df = st.session_state.pro.daily(ts_code=ts_code, start_date=f_start, end_date=f_end, fields='trade_date,open,high,low,close,pre_close')
        if df.empty: return {}
        
        df = df.sort_values('trade_date').reset_index(drop=True)
        
        # æ£€æŸ¥æ˜¯å¦ä¹°å…¥æˆåŠŸ (T+1 é«˜å¼€)
        d1 = df.iloc[0]
        limit_up = d1['pre_close'] * 1.095
        if d1['open'] <= d1['pre_close']: return {'status': 'ä½å¼€æ”¾å¼ƒ'}
        if d1['open'] >= limit_up and d1['low'] >= d1['open']: return {'status': 'ä¸€å­—æ¿æ”¾å¼ƒ'}
        if d1['high'] < buy_price: return {'status': 'æœªçªç ´'}
        
        # æ­¤æ—¶æˆäº¤
        res = {'status': 'æˆäº¤'}
        stop_price = buy_price * (1 + stop_loss_pct/100)
        
        # éå† D1 - D5
        for n in [1, 3, 5]:
            if len(df) >= n:
                # æ£€æŸ¥æœŸé—´æ˜¯å¦æœ‰è§¦åŠæ­¢æŸ (ä» D1 åˆ° Dn)
                triggered_stop = False
                for i in range(n):
                    # æ£€æŸ¥å½“å¤©çš„ Low æ˜¯å¦å‡»ç©¿æ­¢æŸçº¿
                    day_low = df.iloc[i]['low']
                    if day_low <= stop_price:
                        # è§¦å‘æ­¢æŸï¼
                        # å‡è®¾åœ¨æ­¢æŸä»·æˆäº¤ (å®é™…å¯èƒ½æ›´ä½ï¼Œä½†æ­¢æŸä»·æ˜¯è§¦å‘ç‚¹)
                        # ä¸ºäº†ä¿å®ˆï¼Œå– min(æ­¢æŸä»·, å¼€ç›˜ä»·) -- å¦‚æœå¼€ç›˜å°±é—·æ€ï¼ŒæŒ‰å¼€ç›˜ä»·æŸ
                        exit_price = min(stop_price, df.iloc[i]['open'])
                        ret = (exit_price / buy_price - 1) * 100
                        res[f'Return_D{n} (%)'] = ret
                        res[f'Stop_D{n}'] = True # æ ‡è®°å·²æ­¢æŸ
                        triggered_stop = True
                        break # åé¢çš„å¤©æ•°éƒ½æ˜¯è¿™ä¸ªç»“æœäº†
                
                if not triggered_stop:
                    # æœªè§¦å‘æ­¢æŸï¼ŒæŒ‰æ”¶ç›˜ä»·ç®—
                    close_price = df.iloc[n-1]['close']
                    res[f'Return_D{n} (%)'] = (close_price / buy_price - 1) * 100
                    res[f'Stop_D{n}'] = False
                    
        return res
        
    except: return {}

# ---------------------------
# ä¸»ç¨‹åº
# ---------------------------
if start_btn:
    if not st.session_state.ts_token:
        st.error("âŒ è¯·å…ˆè¾“å…¥ Token")
        st.stop()
        
    # 1. è·å–æ—¥æœŸ
    end_date_str = datetime.now().strftime("%Y%m%d")
    all_days = get_trade_days(end_date_str, backtest_days)
    all_days = sorted(all_days)
    
    # 2. æ™ºèƒ½åˆ†æ®µ (æ¯ 60 å¤©ä¸€æ®µï¼Œå…¼é¡¾é€Ÿåº¦ä¸å†…å­˜)
    BATCH_SIZE = 60
    batches = [all_days[i:i + BATCH_SIZE] for i in range(0, len(all_days), BATCH_SIZE)]
    
    results_file = "rank1_v3_results.csv"
    if os.path.exists(results_file): os.remove(results_file) # æ–°ç‰ˆå›æµ‹å…ˆæ¸…ç©º
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total_trades = 0
    
    for b_i, batch_days in enumerate(batches):
        status_text.markdown(f"### âš¡ æ­£åœ¨æé€Ÿè®¡ç®—: {batch_days[0]} ~ {batch_days[-1]} ({b_i+1}/{len(batches)})")
        
        # A. å‘é‡åŒ–å‡†å¤‡æ•°æ®
        df_batch = load_data_and_compute_vectorized(batch_days)
        if df_batch is None or df_batch.empty: continue
        
        # B. æ¯æ—¥é€‰è‚¡ (çº¯å†…å­˜æ“ä½œï¼Œæå¿«)
        batch_results = []
        
        # é¢„åŠ è½½ daily_basic (æ¢æ‰‹ç‡ç­‰)
        # è¿™ä¸€æ­¥ä»éœ€å¾ªç¯æ‹‰å–ï¼Œä½† basic æ•°æ®å¾ˆå°
        for day in batch_days:
            try:
                # è·å–å½“æ—¥å·²è®¡ç®—å¥½çš„æŒ‡æ ‡
                day_data = df_batch[df_batch['trade_date'] == day]
                if day_data.empty: continue
                
                # è·å– Basic æ•°æ®
                basic = st.session_state.pro.daily_basic(trade_date=day, fields='ts_code,turnover_rate,volume_ratio,circ_mv')
                if basic is None or basic.empty: continue
                
                # åˆå¹¶
                merged = pd.merge(day_data, basic, on='ts_code', how='inner')
                
                # -----------------------
                # V30.22 é€‰è‚¡æ ¸å¿ƒé€»è¾‘ (å‘é‡åŒ–ç­›é€‰)
                # -----------------------
                # 1. ç¡¬é—¨æ§›
                # Close > MA20
                # Vol > MA5_Vol * 1.2
                # MACD > 0
                # Price 40-300
                mask = (
                    (merged['hfq_close'] > merged['ma20']) &
                    (merged['vol'] > merged['ma5_vol'] * 1.2) &
                    (merged['macd'] > 0) &
                    (merged['close'] >= min_price) & 
                    (merged['close'] <= max_price) &
                    (merged['turnover_rate'] > 3.0) &
                    (merged['circ_mv'] > 200000) # 2äº¿å¸‚å€¼
                )
                candidates = merged[mask].copy()
                
                if candidates.empty: continue
                
                # 2. è¯„åˆ†ç³»ç»Ÿ
                # Base: MACD / Close (ä½¿ç”¨å¤æƒåçš„æ¯”ä¾‹ï¼Œæ›´å‡†)
                candidates['base_score'] = (candidates['macd'] / candidates['hfq_close']) * 1000000
                
                # Bonus
                # é‡æ¯” 1.5 - 5.0
                # æ¢æ‰‹ 5 - 15
                # æ¶¨å¹… > 9.5 (éœ€è®¡ç®—) -> ç”¨ pct_chg è¿‘ä¼¼
                # æ³¨æ„ï¼šTushare daily é‡Œçš„ pct_chg å¯èƒ½æœªå¤æƒï¼Œè®¡ç®— Close/Pre_Close
                candidates['pct_chg'] = (candidates['close'] / candidates['pre_close'] - 1) * 100
                
                candidates['bonus'] = 1.0
                # å‘é‡åŒ–åŠ åˆ†
                candidates.loc[(candidates['volume_ratio'] > 1.5) & (candidates['volume_ratio'] < 5.0), 'bonus'] += 0.1
                candidates.loc[(candidates['turnover_rate'] > 5.0) & (candidates['turnover_rate'] < 15.0), 'bonus'] += 0.1
                candidates.loc[candidates['pct_chg'] > 9.5, 'bonus'] += 0.1
                
                candidates['final_score'] = candidates['base_score'] * candidates['bonus']
                
                # 3. å– Top 1
                top1 = candidates.sort_values('final_score', ascending=False).head(1)
                
                # 4. æ¨¡æ‹Ÿäº¤æ˜“ (å«æ­¢æŸ)
                for row in top1.itertuples():
                    buy_price = row.open * (1 + buy_threshold/100)
                    # ä¼ å…¥æ­¢æŸå‚æ•°
                    res = check_profit_with_stop_loss(row.ts_code, day, buy_price, stop_loss_pct)
                    
                    if res.get('status') == 'æˆäº¤':
                        rec = {
                            'trade_date': day,
                            'ts_code': row.ts_code,
                            'close': row.close,
                            'score': row.final_score
                        }
                        rec.update(res)
                        batch_results.append(rec)
            
            except Exception: pass
        
        # C. å†™å…¥ç»“æœ
        if batch_results:
            df_res = pd.DataFrame(batch_results)
            df_res.to_csv(results_file, mode='a', header=not os.path.exists(results_file), index=False, encoding='utf-8-sig')
            total_trades += len(df_res)
            st.toast(f"âœ… æ–°å¢ {len(df_res)} ç¬”äº¤æ˜“ (ç´¯è®¡: {total_trades})")
            
        progress_bar.progress((b_i + 1) / len(batches))
        gc.collect()

    st.success("ğŸ‰ æé€Ÿå›æµ‹å®Œæˆï¼")
    
    # ç»“æœå±•ç¤º
    if os.path.exists(results_file):
        res_df = pd.read_csv(results_file)
        st.subheader("ğŸ“Š æœ€ç»ˆå›æµ‹æŠ¥å‘Š")
        
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("æ€»äº¤æ˜“æ¬¡æ•°", len(res_df))
        
        if 'Return_D1 (%)' in res_df.columns:
            avg_d1 = res_df['Return_D1 (%)'].mean()
            win_d1 = (res_df['Return_D1 (%)'] > 0).mean() * 100
            c2.metric("D+1 å‡æ”¶", f"{avg_d1:.2f}%")
            c3.metric("D+1 èƒœç‡", f"{win_d1:.1f}%")
            
            # è®¡ç®—æœ€å¤§å›æ’¤
            res_df = res_df.sort_values('trade_date')
            res_df['equity'] = res_df['Return_D1 (%)'].cumsum()
            dd = res_df['equity'].cummax() - res_df['equity']
            c4.metric("æœ€å¤§å›æ’¤", f"{dd.max():.2f}")
            
        st.dataframe(res_df, use_container_width=True)
        with open(results_file, "rb") as f:
            st.download_button("ğŸ“¥ ä¸‹è½½è¯¦ç»†æˆ˜æŠ¥", f, "rank1_v3_fast.csv")
