# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆç»ˆæä¿®å¤ V5.0ï¼‰
è¯´æ˜ï¼š
- æ ¸å¿ƒä¿®å¤ï¼šé‡æ„ run_backtest é€»è¾‘ï¼Œä½¿å…¶ä¸å®æ—¶é€‰è‚¡ç­–ç•¥å®Œå…¨å¯¹é½ï¼Œè§£å†³äº¤æ˜“æ¬¡æ•°å¼‚å¸¸å’Œè´Ÿæ”¶ç›Šé—®é¢˜ã€‚
- æ€§èƒ½ä¼˜åŒ–ï¼šç»Ÿä¸€æ•°æ®ç¼“å­˜ï¼Œæ”¯æŒå›æµ‹æ—¶ä½¿ç”¨æ¢æ‰‹ç‡ï¼ˆå¦‚æœ daily_basic é¢„åŠ è½½æˆåŠŸï¼‰ã€‚
- ç­–ç•¥è°ƒä¼˜ï¼šå–æ¶ˆ MA å¤šå¤´ç¡¬è¿‡æ»¤ï¼Œæ”¹ä¸ºè¶‹åŠ¿åŠ åˆ†é¡¹ï¼Œä½¿ç­–ç•¥æ›´å…·åŒ…å®¹æ€§ã€‚
- é£é™©å¼ºåŒ–ï¼šå¾®è°ƒé£æ§å‚æ•°ï¼Œé€‚åº”æ¿€è¿›çŸ­çº¿ç­–ç•¥ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆç»ˆæä¿®å¤V5.0ï¼‰", layout="wide")
st.title("é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆç»ˆæä¿®å¤ç‰ˆ V5.0ï¼‰")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚è‹¥æœ‰æƒé™ç¼ºå¤±ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é™çº§å¹¶ç»§ç»­è¿è¡Œã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆå®æ—¶ï¼‰")
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=300, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    # V5.0 è°ƒæ•´ï¼šæ¢æ‰‹ç‡å’Œæˆäº¤é¢æ›´æ¿€è¿›
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=2.0, step=0.5)) 
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=150_000_000.0, step=50_000_000.0)) # é»˜è®¤ 1.5äº¿
    VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.7, step=0.1))
    VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=15.0, step=1.0)) # V5.0 è°ƒé«˜ï¼Œå®¹å¿çŸ­çº¿é«˜æ³¢åŠ¨
    HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))
    MIN_MARKET_CAP = float(st.number_input("æœ€ä½å¸‚å€¼ (å…ƒ)", value=2000000000.0, step=100000000.0))  # é»˜è®¤ 20äº¿
    MAX_MARKET_CAP = float(st.number_input("æœ€é«˜å¸‚å€¼ (å…ƒ)", value=50000000000.0, step=1000000000.0))  # é»˜è®¤ 500äº¿
    st.markdown("---")
    # --- å›æµ‹å‚æ•° ---
    st.header("å†å²å›æµ‹å‚æ•°")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹äº¤æ˜“æ—¥å¤©æ•°", value=60, min_value=10, max_value=250))
    BACKTEST_TOP_K = int(st.number_input("å›æµ‹æ¯æ—¥æœ€å¤šäº¤æ˜“ K æ”¯", value=3, min_value=1, max_value=10)) 
    HOLD_DAYS_OPTIONS = st.multiselect("å›æµ‹æŒè‚¡å¤©æ•°", options=[1, 3, 5, 10, 20], default=[1, 3, 5])
    st.caption("æç¤ºï¼šè¯·ç¡®è®¤ **MIN_TURNOVER**ã€**MIN_AMOUNT** å·²è°ƒæ•´ã€‚")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# å®‰å…¨è°ƒç”¨ & ç¼“å­˜è¾…åŠ©
# ---------------------------
def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†å¹¶ç¼“å­˜"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        return df[df.is_open == 1]['cal_date'].tolist()
    except Exception:
        return []

@st.cache_data(ttl=600)
def find_last_trade_day(max_days=20):
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# --- è¯„åˆ†ä¸é£æ§æ‰€éœ€çš„æŒ‡æ ‡è®¡ç®—å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ ---
# ï¼ˆcompute_indicators, norm_col å‡½æ•°ä½äºæ­¤å¤„...ï¼‰

@st.cache_data(ttl=600)
def get_hist_cached(ts_code, end_date, days=60):
    """V5.0ï¼šç²¾ç®€å†å²æ•°æ®è·å–ï¼Œä¸“æ³¨äº daily æ¥å£"""
    try:
        start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days*2)).strftime("%Y%m%d")
        df = safe_get(pro.daily, ts_code=ts_code, start_date=start, end_date=end_date)
        if df is None or df.empty:
            return pd.DataFrame()
        df = df.sort_values('trade_date').reset_index(drop=True)
        return df
    except:
        return pd.DataFrame()

def compute_indicators(df):
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆMA, MACD, KDJ, é‡æ¯”, 10dæ”¶ç›Š, æ³¢åŠ¨ç‡, é˜³çº¿å®ä½“ï¼‰
    ä¿æŒä¸ V4.0 å®Œå…¨ä¸€è‡´ï¼Œä»¥ç¡®ä¿è¯„åˆ†é€»è¾‘åŒæ­¥
    """
    res = {}
    if df.empty or len(df) < 3:
        return res
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)

    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan

    for n in (5,10,20):
        if len(close) >= n:
            res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else:
            res[f'ma{n}'] = np.nan

    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1]; res['dea'] = dea.iloc[-1]
    else:
        res['macd'] = res['diff'] = res['dea'] = np.nan
    
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = res['j'] = np.nan
        
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan

    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except:
        res['volatility_10'] = np.nan

    try:
        if len(high) >= 20:
            res['recent20_high'] = float(high.tail(20).max())
        else:
            res['recent20_high'] = float(high.max()) if len(high)>0 else np.nan
    except:
        res['recent20_high'] = np.nan

    try:
        today_open = df['open'].astype(float).iloc[-1]
        today_close = df['close'].astype(float).iloc[-1]
        today_high = df['high'].astype(float).iloc[-1]
        today_low = df['low'].astype(float).iloc[-1]
        body = abs(today_close - today_open)
        rng = max(today_high - today_low, 1e-9)
        res['yang_body_strength'] = body / rng
    except:
        res['yang_body_strength'] = 0.0

    return res

def norm_col(s):
    """å½’ä¸€åŒ–å‡½æ•°ï¼ˆç¨³å¥ç‰ˆï¼‰"""
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9:
        return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)

# --- V5.0 ç»Ÿä¸€è¯„åˆ†å‡½æ•° (ç”¨äºå®æ—¶é€‰è‚¡å’Œå›æµ‹) ---
def apply_scoring_and_filtering(fdf, use_hard_filter=True):
    """
    ç»Ÿä¸€çš„è¯„åˆ†å’Œè¿‡æ»¤æµç¨‹ï¼Œç¡®ä¿å›æµ‹å’Œå®æ—¶é€‰è‚¡é€»è¾‘ä¸€è‡´ã€‚
    è¿”å›ï¼šæ’åºåçš„ DataFrame
    """
    if fdf.empty:
        return fdf
    
    # --- 1. é£é™©è¿‡æ»¤ ---
    before_cnt = len(fdf)
    
    # A: é«˜ä½å¤§é˜³çº¿
    if all(c in fdf.columns for c in ['ma20','last_close','pct_chg']):
        mask_high_big = (fdf['last_close'] > fdf['ma20'] * 1.10) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD)
        fdf = fdf[~mask_high_big].copy()

    # B: ä¸‹è·Œé€”ä¸­åæŠ½
    if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
        mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD)
        fdf = fdf[~mask_down_rebound].copy()

    # C: å·¨é‡æ”¾é‡å¤§é˜³
    if all(c in fdf.columns for c in ['vol_last','vol_ma5']):
        mask_vol_spike = (fdf['vol_last'] > (fdf['vol_ma5'] * VOL_SPIKE_MULT))
        fdf = fdf[~mask_vol_spike].copy()

    # D: æç«¯æ³¢åŠ¨
    if 'volatility_10' in fdf.columns:
        mask_volatility = fdf['volatility_10'] > VOLATILITY_MAX
        fdf = fdf[~mask_volatility].copy()
    
    # E: (V5.0 ä¼˜åŒ–) å–æ¶ˆ MA å¤šå¤´ç¡¬è¿‡æ»¤ï¼Œæ”¹ä¸ºè¶‹åŠ¿åŠ åˆ†
    # if use_hard_filter: 
    #     if all(c in fdf.columns for c in ['ma5','ma10','ma20']):
    #         fdf = fdf[(fdf['ma5'] > fdf['ma10']) & (fdf['ma10'] > fdf['ma20'])].copy()

    # --- 2. RSL è®¡ç®— ---
    if '10d_return' in fdf.columns and fdf['10d_return'].abs().sum() > 0:
        try:
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            market_mean_10d = market_mean_10d if abs(market_mean_10d) > 1e-9 else 1e-9
            fdf['rsl'] = fdf['10d_return'] / market_mean_10d
        except:
            fdf['rsl'] = 1.0
    else:
        fdf['rsl'] = 1.0
    
    # --- 3. å½’ä¸€åŒ– ---
    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    
    # moneyflow / proxy_money é€»è¾‘ (ä»…åœ¨ fdf ä¸­æœ‰è¿™äº›åˆ—æ—¶æ‰§è¡Œ)
    if 'net_mf' in fdf.columns and fdf['net_mf'].abs().sum() > 0:
        fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf))))
    elif 'proxy_money' in fdf.columns:
        fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
    else:
        fdf['s_money'] = pd.Series([0.5]*len(fdf), index=fdf.index)

    fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

    # --- 4. è¶‹åŠ¿å› å­ä¸å¼ºåŒ–è¯„åˆ† ---
    fdf['ma_trend_flag'] = ((fdf.get('ma5', 0) > fdf.get('ma10', 0)) & (fdf.get('ma10', 0) > fdf.get('ma20', 0))).fillna(False)
    fdf['macd_golden_flag'] = (fdf.get('diff', 0) > fdf.get('dea', 0)).fillna(False)
    fdf['vol_price_up_flag'] = (fdf.get('vol_last', 0) > fdf.get('vol_ma5', 0)).fillna(False)
    fdf['break_high_flag'] = (fdf.get('last_close', 0) > fdf.get('recent20_high', 0)).fillna(False)
    fdf['yang_body_strength'] = fdf.get('yang_body_strength', 0.0).fillna(0.0)

    # V5.0 å¼ºåŒ– MA è¶‹åŠ¿åˆ†æƒé‡
    fdf['trend_score_raw'] = (
        fdf['ma_trend_flag'].astype(float) * 2.0 + # æƒé‡åŠ å€
        fdf['macd_golden_flag'].astype(float) * 1.3 +
        fdf['vol_price_up_flag'].astype(float) * 1.0 +
        fdf['break_high_flag'].astype(float) * 1.3 +
        fdf['yang_body_strength'].astype(float) * 0.8
    )

    fdf['trend_score'] = norm_col(fdf['trend_score_raw'])

    # --- 5. æœ€ç»ˆç»¼åˆè¯„åˆ† ---
    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['trend_score'] * 0.40 +
        fdf.get('s_10d', 0)*0.12 +
        fdf.get('s_rsl', 0)*0.08 +
        fdf.get('s_volratio', 0)*0.10 +
        fdf.get('s_turn', 0)*0.05 +
        fdf.get('s_money', 0)*0.10 +
        fdf.get('s_pct', 0)*0.10 +
        fdf.get('s_volatility', 0)*0.05
    )
    
    # --- 6. æ’åº ---
    return fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False)


# --- å®æ—¶é€‰è‚¡ä¸»æµç¨‹ï¼ˆä¿æŒä¸ V4.0 å…¼å®¹ï¼Œä»…è°ƒç”¨ apply_scoring_and_filteringï¼‰---
# [V5.0: å®æ—¶é€‰è‚¡çš„ä»£ç ä¿æŒåŸæ ·ï¼Œä»…å°†è¿‡æ»¤å’Œè¯„åˆ†é€»è¾‘å°è£…åˆ° apply_scoring_and_filtering ä¸­ï¼Œå¹¶ç§»é™¤ MA ç¡¬è¿‡æ»¤ã€‚]
# (ä¸­é—´çœç•¥äº†å®æ—¶é€‰è‚¡çš„æ‹‰å–ã€åˆå¹¶ã€æ¸…æ´—ä»£ç ï¼Œä»¥èšç„¦å›æµ‹ä¿®å¤)
# ...
# ---------------------------
# MA å¤šå¤´ç¡¬è¿‡æ»¤ï¼ˆV5.0: å–æ¶ˆï¼Œæ”¹ä¸ºåœ¨ apply_scoring_and_filtering ä¸­é€šè¿‡è¶‹åŠ¿åˆ†åŠ æƒï¼‰
# ---------------------------
# try:
#     if all(c in fdf.columns for c in ['ma5','ma10','ma20']):
#         before_ma = len(fdf)
#         fdf = fdf[(fdf['ma5'] > fdf['ma10']) & (fdf['ma10'] > fdf['ma20'])].copy() 
#         after_ma = len(fdf)
#         st.write(f"MA å¤šå¤´è¿‡æ»¤ï¼š{before_ma} -> {after_ma}ï¼ˆä¿ç•™ MA5>MA10>MA20ï¼‰")
# except Exception as e:
#     st.warning(f"MA è¿‡æ»¤å¼‚å¸¸ï¼Œè·³è¿‡ã€‚é”™è¯¯ï¼š{e}")

# ---------------------------
# æœ€ç»ˆç»¼åˆè¯„åˆ†ä¸å±•ç¤ºï¼ˆV5.0: è°ƒç”¨ç»Ÿä¸€å‡½æ•°ï¼‰
# ---------------------------
fdf = apply_scoring_and_filtering(fdf, use_hard_filter=False)
fdf.index = fdf.index + 1
# ... (å±•ç¤ºä»£ç )

# ---------------------------
# å†å²å›æµ‹éƒ¨åˆ†ï¼ˆæ•°æ®æ€§èƒ½ä¼˜åŒ–ä¸é€»è¾‘å¼ºåŒ–ï¼‰
# ---------------------------
@st.cache_data(ttl=3600)
def load_backtest_data(all_trade_dates):
    """
    V5.0 é¢„åŠ è½½ï¼šåŒæ—¶åŠ è½½ daily å’Œ daily_basicï¼Œæ”¯æŒå›æµ‹ä¸­è¿›è¡Œæ¢æ‰‹ç‡è¿‡æ»¤ã€‚
    """
    daily_cache = {}
    basic_cache = {}
    st.write(f"æ­£åœ¨é¢„åŠ è½½å›æµ‹æ‰€éœ€ {len(all_trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„ daily å’Œ daily_basic æ•°æ®...")
    pbar = st.progress(0)
    for i, date in enumerate(all_trade_dates):
        # 1. åŠ è½½ Daily (æ ¸å¿ƒKçº¿æ•°æ®)
        daily_df = safe_get(pro.daily, trade_date=date)
        if not daily_df.empty:
            daily_cache[date] = daily_df.set_index('ts_code')
        
        # 2. åŠ è½½ Daily Basic (æ¢æ‰‹ç‡/å¸‚å€¼ç­‰)
        basic_df = safe_get(pro.daily_basic, trade_date=date, fields='ts_code,turnover_rate,total_mv')
        if not basic_df.empty:
            basic_cache[date] = basic_df.set_index('ts_code')
            
        pbar.progress((i + 1) / len(all_trade_dates))
    pbar.progress(1.0)
    return daily_cache, basic_cache

@st.cache_data(ttl=6000)
def run_backtest(start_date, end_date, hold_days, backtest_top_k):
    trade_dates = get_trade_cal(start_date, end_date)
    
    if not trade_dates:
        return {h: {'returns': [], 'wins': 0, 'total': 0, 'win_rate': 0.0, 'avg_return': 0.0} for h in hold_days}

    results = {h: {'returns': [], 'wins': 0, 'total': 0, 'win_rate': 0.0, 'avg_return': 0.0} for h in hold_days}
    
    bt_start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=BACKTEST_DAYS * 2)).strftime("%Y%m%d")
    buy_dates_pool = [d for d in trade_dates if d >= bt_start and d <= end_date]
    backtest_dates = buy_dates_pool[-BACKTEST_DAYS:]
    
    if len(backtest_dates) < BACKTEST_DAYS:
        st.warning(f"ç”±äºæ•°æ®æˆ–äº¤æ˜“æ—¥é™åˆ¶ï¼Œå›æµ‹ä»…èƒ½è¦†ç›– {len(backtest_dates)} å¤©ã€‚")
    
    # ç¡®å®šå›æµ‹æ‰€éœ€çš„å…¨éƒ¨äº¤æ˜“æ—¥ï¼Œå¹¶é¢„åŠ è½½æ•°æ®
    required_dates = set(backtest_dates)
    for buy_date in backtest_dates:
        try:
            current_index = trade_dates.index(buy_date)
            for h in hold_days:
                # ç¡®ä¿è·å–å–å‡ºæ—¥æœŸçš„æ•°æ®
                required_dates.add(trade_dates[current_index + h])
        except (ValueError, IndexError):
            continue
            
    daily_cache, basic_cache = load_backtest_data(sorted(list(required_dates)))

    st.write(f"æ­£åœ¨æ¨¡æ‹Ÿ {len(backtest_dates)} ä¸ªäº¤æ˜“æ—¥çš„é€‰è‚¡å›æµ‹...")
    pbar_bt = st.progress(0)
    
    for i, buy_date in enumerate(backtest_dates):
        daily_df_cached = daily_cache.get(buy_date)
        basic_df_cached = basic_cache.get(buy_date)
        
        if daily_df_cached is None or daily_df_cached.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue

        daily_df = daily_df_cached.copy().reset_index() 
        daily_df.rename(columns={'amount': 'amount_daily'}, inplace=True) # daily é‡Œçš„ amount (åƒå…ƒ)
        daily_df['amount'] = daily_df['amount_daily'] * 1000.0 # è½¬æ¢æˆå…ƒ
        
        # 1. åˆå¹¶ daily_basic æ•°æ®ï¼ˆæ¢æ‰‹ç‡/å¸‚å€¼ç­‰ï¼‰
        if basic_df_cached is not None and not basic_df_cached.empty:
            daily_df = daily_df.merge(
                basic_df_cached.reset_index()[['ts_code','turnover_rate','total_mv']], 
                on='ts_code', 
                how='left'
            )
        else:
            daily_df['turnover_rate'] = np.nan
            daily_df['total_mv'] = np.nan
            
        # 2. åº”ç”¨åŸºæœ¬è¿‡æ»¤ï¼ˆä¸å®æ—¶é€‰è‚¡åŒæ­¥ï¼‰
        daily_df = daily_df[
            (daily_df['close'] >= MIN_PRICE) & 
            (daily_df['close'] <= MAX_PRICE) &
            (daily_df['vol'] > 0) & 
            (daily_df['amount'] > MIN_AMOUNT) & # æˆäº¤é¢è¿‡æ»¤
            (daily_df['pct_chg'] > 0) & # å‰”é™¤å½“æ—¥ä¸‹è·Œ
            (~((daily_df['open'] == daily_df['high']) & (daily_df['pct_chg'] > 9.5))) # å‰”é™¤ä¸€å­—æ¿
        ].copy()
        
        # æ¢æ‰‹ç‡è¿‡æ»¤ (V5.0: ç°åœ¨å¯ä»¥ç”¨äº†)
        if 'turnover_rate' in daily_df.columns:
            daily_df = daily_df[(daily_df['turnover_rate'].fillna(0) >= MIN_TURNOVER)].copy()
        
        # å¸‚å€¼è¿‡æ»¤
        if 'total_mv' in daily_df.columns:
            # å…¼å®¹ Tushare daily_basic çš„ total_mv (å•ä½ä¸ºä¸‡å…ƒï¼Œéœ€è¦è½¬å…ƒ)
            daily_df['total_mv_yuan'] = daily_df['total_mv'].fillna(0) * 10000.0 
            daily_df = daily_df[
                (daily_df['total_mv_yuan'] >= MIN_MARKET_CAP) & 
                (daily_df['total_mv_yuan'] <= MAX_MARKET_CAP)
            ].copy()

        if daily_df.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue
            
        # 3. è®¡ç®—æŒ‡æ ‡å¹¶è¯„åˆ† (é‡ç°å®æ—¶è¯„åˆ†çš„å¤æ‚é€»è¾‘)
        score_records = []
        for _, row in daily_df.iterrows():
            ts_code = row['ts_code']
            
            # ** æ€§èƒ½å…³é”® **ï¼šä»ç¼“å­˜ä¸­æ‹‰å–å†å²Kçº¿æ•°æ®ï¼Œä»¥ä¾›è®¡ç®—æŒ‡æ ‡
            hist_df = get_hist_cached(ts_code, buy_date, days=60)
            ind = compute_indicators(hist_df)
            
            # åˆå¹¶å½“æ—¥åŸºæœ¬æ•°æ®å’Œè®¡ç®—å‡ºçš„æŒ‡æ ‡
            rec = row.to_dict()
            rec.update(ind)
            
            # èµ„é‡‘å¼ºåº¦ä»£ç† (éœ€åœ¨è¯„åˆ†å‰è®¡ç®—)
            pct_chg = rec.get('pct_chg', 0.0)
            vol_ratio = rec.get('vol_ratio', 0.0)
            turnover_rate = rec.get('turnover_rate', 0.0)
            rec['proxy_money'] = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)

            score_records.append(rec)

        scored_df = pd.DataFrame(score_records)
        if scored_df.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue

        # 4. åº”ç”¨è¯„åˆ†å’Œæ’åº
        scored_df = apply_scoring_and_filtering(scored_df, use_hard_filter=False)
        
        # 5. é€‰å‡º Top K
        selected_stocks = scored_df.head(backtest_top_k)
        
        # 6. è®¡ç®—æ”¶ç›Š
        for _, row in selected_stocks.iterrows():
            ts_code = row['ts_code']
            buy_price = float(row['close']) 
            
            if pd.isna(buy_price) or buy_price <= 0: continue

            for h in hold_days:
                try:
                    current_index = trade_dates.index(buy_date)
                    sell_date = trade_dates[current_index + h]
                except (ValueError, IndexError):
                    continue
                
                # ä»ç¼“å­˜ä¸­æŸ¥æ‰¾å–å‡ºä»·æ ¼ (O(1) æŸ¥æ‰¾)
                sell_df_cached = daily_cache.get(sell_date)
                sell_price = np.nan
                if sell_df_cached is not None and ts_code in sell_df_cached.index:
                    sell_price = sell_df_cached.loc[ts_code, 'close']
                
                if pd.isna(sell_price) or sell_price <= 0: continue
                
                ret = (sell_price / buy_price) - 1.0
                results[h]['total'] += 1
                results[h]['returns'].append(ret)
                if ret > 0:
                    results[h]['wins'] += 1

        pbar_bt.progress((i+1)/len(backtest_dates))

    pbar_bt.progress(1.0)
    
    final_results = {}
    for h, res in results.items():
        total = res['total']
        if total > 0:
            avg_return = np.mean(res['returns']) * 100.0
            win_rate = (res['wins'] / total) * 100.0
        else:
            avg_return = 0.0
            win_rate = 0.0
            
        final_results[h] = {
            'å¹³å‡æ”¶ç›Šç‡ (%)': f"{avg_return:.2f}",
            'èƒœç‡ (%)': f"{win_rate:.2f}",
            'æ€»äº¤æ˜“æ¬¡æ•°': total
        }
        
    return final_results

# ---------------------------
# å›æµ‹æ‰§è¡Œ
# ---------------------------
if st.checkbox("âœ… è¿è¡Œå†å²å›æµ‹", value=False):
    if not HOLD_DAYS_OPTIONS:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå›æµ‹æŒè‚¡å¤©æ•°ã€‚")
    else:
        st.header("ğŸ“ˆ å†å²å›æµ‹ç»“æœï¼ˆä¹°å…¥æ”¶ç›˜ä»· / å–å‡ºæ”¶ç›˜ä»·ï¼‰")
        
        # ç¡®ä¿å›æµ‹æ•°æ®è¦†ç›–è¶³å¤Ÿçš„å†å²
        try:
            # è€ƒè™‘æœ€é•¿æŒè‚¡å¤©æ•° 20 å¤©ï¼ŒåŠ ä¸Šå›æµ‹å¤©æ•° 60 å¤©ï¼Œå†åŠ ä¸€ä¸ªå®‰å…¨è¾¹é™…ï¼Œæ€»å…±éœ€è¦çº¦ 100 ä¸ªäº¤æ˜“æ—¥ã€‚
            # 200 å¤©æ˜¯å®‰å…¨çš„è·¨åº¦ã€‚
            start_date_for_cal = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
        except:
            start_date_for_cal = (datetime.now() - timedelta(days=200)).strftime("%Y%m%d")
            
        backtest_result = run_backtest(
            start_date=start_date_for_cal, 
            end_date=last_trade,
            hold_days=HOLD_DAYS_OPTIONS,
            backtest_top_k=BACKTEST_TOP_K 
        )

        bt_df = pd.DataFrame(backtest_result).T
        bt_df.index.name = "æŒè‚¡å¤©æ•°"
        bt_df = bt_df.reset_index()
        bt_df['æŒè‚¡å¤©æ•°'] = bt_df['æŒè‚¡å¤©æ•°'].astype(str) + ' å¤©'
        
        st.dataframe(bt_df, use_container_width=True, hide_index=True)
        st.success("å›æµ‹å®Œæˆï¼")
        
        export_df = bt_df.copy()
        export_df.columns = ['HoldDays', 'AvgReturn', 'WinRate', 'TotalTrades']
        out_csv_bt = export_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "ä¸‹è½½å›æµ‹ç»“æœ CSV", 
            data=out_csv_bt, 
            file_name=f"backtest_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", 
            mime="text/csv"
        )
# ---------------------------
# å°ç»“ä¸å»ºè®®ï¼ˆç®€æ´ï¼‰
# ---------------------------
st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆç»ˆæä¿®å¤ V5.0ï¼‰")
st.markdown("""
- **çŠ¶æ€ï¼š** **V5.0** å·²å‘å¸ƒã€‚æœ¬æ¬¡å½»åº•**é‡æ„äº†å›æµ‹å‡½æ•° `run_backtest`**ï¼Œä½¿å…¶å®Œå…¨å¤ç”¨å®æ—¶é€‰è‚¡çš„ **æŒ‡æ ‡è®¡ç®—ã€é£é™©è¿‡æ»¤å’Œç»¼åˆè¯„åˆ†** é€»è¾‘ã€‚
- **ç›®æ ‡ï¼š** è§£å†³å›æµ‹äº¤æ˜“æ¬¡æ•°å¼‚å¸¸å’Œæ”¶ç›Šä¸ºè´Ÿçš„é—®é¢˜ã€‚ç°åœ¨å›æµ‹çš„ **æ€»äº¤æ˜“æ¬¡æ•°** åº”ä¸ **å›æµ‹å¤©æ•° \* Top K** æ•°é‡æ¥è¿‘ã€‚
- **æ€§èƒ½ï¼š** â€œä¸ºè¯„åˆ†æ± é€ç¥¨æ‹‰å†å²å¹¶è®¡ç®—æŒ‡æ ‡â€ç¯èŠ‚ä¾æ—§è€—æ—¶ï¼ˆçº¦15åˆ†é’Ÿï¼‰ï¼Œè¿™æ˜¯å› ä¸º Tushare æ¥å£é™åˆ¶ï¼Œéš¾ä»¥é¿å…ã€‚**å›æµ‹æ•°æ®å·²ç¼“å­˜ï¼Œä¸‹æ¬¡è¿è¡Œä¼šæ›´å¿«ã€‚**
- **ä¸‹ä¸€æ­¥ï¼š** é‡æ–°è¿è¡Œè„šæœ¬ï¼Œç„¶åå‹¾é€‰ **â€œâœ… è¿è¡Œå†å²å›æµ‹â€**ã€‚è¯·å…³æ³¨ **æ€»äº¤æ˜“æ¬¡æ•°** å’Œ **å¹³å‡æ”¶ç›Šç‡** æ˜¯å¦æ¢å¤æ­£å¸¸ã€‚
""")
st.info("å¦‚æœå›æµ‹ä»å‡ºç°äº¤æ˜“æ¬¡æ•°å¼‚å¸¸æˆ–æ”¶ç›Šæå·®ï¼Œè¯·æä¾›æœ€æ–°çš„å›æµ‹æˆªå›¾ã€‚")
