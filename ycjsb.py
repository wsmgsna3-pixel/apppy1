# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.12.3 æœ€ç»ˆä¿®æ­£å›é€€ç‰ˆ (Revert)
------------------------------------------------
ç‰ˆæœ¬æ ¸å¿ƒï¼š
1. **é“è¡€é£æ§**ï¼šæ¢å¤æœ€ä¸¥å‰çš„ 19% æ¶¨å¹…é™åˆ¶ã€‚
   - åªè¦æ˜¨æ—¥æ¶¨å¹… > 19.0% (20CMæ¶¨åœ)ï¼Œä¸€å¾‹å‰”é™¤ï¼
   - å½»åº•è§„é¿â€œå¹¸ç¦è“æµ·(-30%)â€å¼çš„æ¬¡æ—¥å¤§é¢ã€‚
2. **RSI ç­–ç•¥**ï¼šä¿ç•™ RSI > 90 åŠ  1000åˆ†ï¼Œåªå¥–åŠ±ç¨³å¥çš„çœŸé¾™ã€‚
3. **å®‰å…¨ç¨³å¥**ï¼š3çº¿ç¨‹å¹¶å‘ + å…¨å¥—é˜²å´©æºƒè¡¥ä¸ã€‚
------------------------------------------------
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time
import concurrent.futures 

warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 
GLOBAL_STOCK_INDUSTRY = {} 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ V30.12.3ï¼šæœ€ç»ˆä¿®æ­£å›é€€ç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ V30.12.3ï¼šæœ€ç»ˆä¿®æ­£å›é€€ç‰ˆï¼ˆğŸ›¡ï¸ é“è¡€é£æ§ + ğŸ‰ ç¨³å¥æ“’é¾™ï¼‰")
st.markdown("""
**âš ï¸ å®æˆ˜ä»¿çœŸæ¨¡å¼è¯´æ˜ï¼š**
1. **ä¹°å…¥æ¡ä»¶**ï¼šD1å¼€ç›˜ä»· > D0æ”¶ç›˜ä»· (æ‹’ç»ä½å¼€) **ä¸”** D1æœ€é«˜ä»· >= D1å¼€ç›˜ä»· * 1.015 (ç¡®è®¤çªç ´)ã€‚
2. **é“è¡€æ’é›·**ï¼š
   - **æ‹’ç»è¯±æƒ‘**ï¼šæ˜¨æ—¥æ¶¨å¹… > 19.0% (20CMæ¶¨åœ) **ä¸€å¾‹å‰”é™¤**ã€‚æ•°æ®è¯æ˜æ¬¡æ—¥å¤§é¢ç‡æé«˜ã€‚
   - **é˜²å¥—ç‰¢**ï¼šå‰”é™¤è·åˆ©ç›˜ < 80% çš„ä¸ªè‚¡ã€‚
3. **ç­–ç•¥æ ¸å¿ƒ**ï¼šRSI > 90 ç»™äºˆ **1000åˆ†** å¥–åŠ±ï¼Œä¼˜é€‰ç¼©é‡ä¸»å‡æµªã€‚
""")

# ---------------------------
# åŸºç¡€ API å‡½æ•°
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: 
        return pd.DataFrame(columns=['ts_code']) 
   
    func = getattr(pro, func_name) 
    try:
        for _ in range(3):
            try:
                if kwargs.get('is_index'):
                    df = pro.index_daily(**kwargs)
                else:
                    df = func(**kwargs)
                
                if df is not None and not df.empty:
                    return df
                time.sleep(0.5)
            except:
                time.sleep(1)
                continue
        return pd.DataFrame(columns=['ts_code']) 
    except Exception as e:
        return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    lookback_days = max(num_days * 3, 365) 
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=lookback_days)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    
    if cal.empty or 'cal_date' not in cal.columns:
        return []
        
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    return trade_days_df['cal_date'].head(num_days).tolist()

@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

# --- è¡Œä¸šåŠ è½½å‡½æ•° ---
@st.cache_data(ttl=3600*24*7) 
def load_industry_mapping():
    global pro
    if pro is None: return {}
    try:
        sw_indices = pro.index_classify(level='L1', src='SW2021')
        if sw_indices.empty: return {}
        index_codes = sw_indices['index_code'].tolist()
        all_members = []
        load_bar = st.progress(0, text="æ­£åœ¨éå†åŠ è½½è¡Œä¸šæ•°æ®...")
        for i, idx_code in enumerate(index_codes):
            df = pro.index_member(index_code=idx_code, is_new='Y')
            if not df.empty: all_members.append(df)
            time.sleep(0.02) 
            load_bar.progress((i + 1) / len(index_codes), text=f"åŠ è½½è¡Œä¸šæ•°æ®: {idx_code}")
        load_bar.empty()
        if not all_members: return {}
        full_df = pd.concat(all_members)
        full_df = full_df.drop_duplicates(subset=['con_code'])
        return dict(zip(full_df['con_code'], full_df['index_code']))
    except Exception as e:
        return {}

# ---------------------------
# æ•°æ®è·å–æ ¸å¿ƒ (3çº¿ç¨‹å®‰å…¨ç‰ˆ)
# ---------------------------
def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_STOCK_INDUSTRY
    if not trade_days_list: return False
    
    with st.spinner("æ­£åœ¨åŒæ­¥å…¨å¸‚åœºè¡Œä¸šæ•°æ®..."):
        GLOBAL_STOCK_INDUSTRY = load_industry_mapping()

    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=200)
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=30)
  
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    all_trade_dates_df = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')
    
    if all_trade_dates_df.empty or 'cal_date' not in all_trade_dates_df.columns:
        st.error("âŒ æ— æ³•è·å–äº¤æ˜“æ—¥å†æ•°æ®ã€‚å¯èƒ½æ˜¯ Tushare æ¥å£å¼‚å¸¸ã€‚")
        return False
        
    all_dates = all_trade_dates_df['cal_date'].tolist()
    
    st.info(f"âš¡ [å®‰å…¨åŠ é€Ÿæ¨¡å¼] æ­£åœ¨å¼€å¯ 3 çº¿ç¨‹å¹¶å‘åŠ è½½æ•°æ®: {start_date} è‡³ {end_date}...")

    adj_factor_data_list = [] 
    daily_data_list = []
    
    def fetch_worker(date):
        return fetch_and_cache_daily_data(date)

    progress_text = "Tushare æ•°æ®å¤šçº¿ç¨‹åŒæ­¥ä¸­..."
    my_bar = st.progress(0, text=progress_text)
    total_steps = len(all_dates)
    
    # === å…³é”®ï¼šmax_workers=3ï¼Œé˜²æ­¢è¢«å° ===
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        future_to_date = {executor.submit(fetch_worker, date): date for date in all_dates}
        for i, future in enumerate(concurrent.futures.as_completed(future_to_date)):
            try:
                data = future.result()
                if not data['adj'].empty: adj_factor_data_list.append(data['adj'])
                if not data['daily'].empty: daily_data_list.append(data['daily'])
            except Exception as exc: pass
            
            if i % 5 == 0 or i == total_steps - 1:
                my_bar.progress((i + 1) / total_steps, text=f"åŠ è½½ä¸­: {i+1}/{total_steps}")

    my_bar.empty()
    
    if not daily_data_list:
        st.error("âŒ æ•°æ®åŒæ­¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ä¼‘æ¯ç‰‡åˆ»å†è¯•ã€‚")
        return False
   
    with st.spinner("æ­£åœ¨åˆå¹¶å¹¶æ„å»ºå…¨å¸‚åœºç´¢å¼•..."):
        adj_factor_data = pd.concat(adj_factor_data_list)
        adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(0)
        GLOBAL_ADJ_FACTOR = adj_factor_data.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
        
        daily_raw_data = pd.concat(daily_data_list)
        GLOBAL_DAILY_RAW = daily_raw_data.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

        latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
        if latest_global_date:
            try:
                latest_adj_df = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
                GLOBAL_QFQ_BASE_FACTORS = latest_adj_df.droplevel(1).to_dict()
            except: GLOBAL_QFQ_BASE_FACTORS = {}
            
    return True

# ---------------------------
# å¤æƒè®¡ç®—æ ¸å¿ƒé€»è¾‘
# ---------------------------
def get_qfq_data_v4_optimized_final(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    if GLOBAL_DAILY_RAW.empty: return pd.DataFrame()
    
    latest_adj_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(latest_adj_factor): return pd.DataFrame() 

    try:
        daily_df = GLOBAL_DAILY_RAW.loc[ts_code]
        daily_df = daily_df.loc[(daily_df.index >= start_date) & (daily_df.index <= end_date)]
        adj_series = GLOBAL_ADJ_FACTOR.loc[ts_code]['adj_factor']
        adj_series = adj_series.loc[(adj_series.index >= start_date) & (adj_series.index <= end_date)]
    except KeyError: return pd.DataFrame()
    
    if daily_df.empty or adj_series.empty: return pd.DataFrame()
    
    df = daily_df.merge(adj_series.rename('adj_factor'), left_index=True, right_index=True, how='left')
    df = df.dropna(subset=['adj_factor'])
    
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns:
            df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
    
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df = df.sort_values('trade_date_str').set_index('trade_date_str')
    
    for col in ['open', 'high', 'low', 'close']:
        df[col] = df[col + '_qfq']
        
    return df[['open', 'high', 'low', 'close', 'vol']].copy() 

# ---------------------------
# å®æˆ˜ä»¿çœŸä¸æŒ‡æ ‡è®¡ç®—
# ---------------------------
def get_future_prices(ts_code, selection_date, d0_qfq_close, days_ahead=[1, 3, 5]):
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_future = (d0 + timedelta(days=15)).strftime("%Y%m%d")
    
    hist = get_qfq_data_v4_optimized_final(ts_code, start_date=start_future, end_date=end_future)
    results = {}
    
    if hist.empty or len(hist) < 1: return results
    
    hist['open'] = pd.to_numeric(hist['open'], errors='coerce')
    hist['high'] = pd.to_numeric(hist['high'], errors='coerce')
    hist['close'] = pd.to_numeric(hist['close'], errors='coerce')
    
    d1_data = hist.iloc[0]
    next_open = d1_data['open']
    next_high = d1_data['high']
    
    if next_open <= d0_qfq_close: return results 
    target_buy_price = next_open * 1.015
    if next_high < target_buy_price: return results
        
    for n in days_ahead:
        col = f'Return_D{n}'
        if len(hist) >= n:
            sell_price = hist.iloc[n-1]['close']
            results[col] = (sell_price - target_buy_price) / target_buy_price * 100
        else:
            results[col] = np.nan
    return results

def calculate_rsi(series, period=12):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / (loss + 1e-9)
    return 100 - (100 / (1 + rs))

@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    df = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date, end_date=end_date)
    res = {}
    if df.empty or len(df) < 26: return res 
    
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    res['last_close'] = close.iloc[-1]
    res['last_open'] = df['open'].iloc[-1]
    res['last_high'] = df['high'].iloc[-1]
    res['last_low'] = df['low'].iloc[-1]
    
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    diff = ema12 - ema26
    dea = diff.ewm(span=9, adjust=False).mean()
    res['macd_val'] = ((diff - dea) * 2).iloc[-1]
    
    res['ma20'] = close.tail(20).mean()
    res['ma60'] = close.tail(60).mean()
    
    rsi_series = calculate_rsi(close, period=12)
    res['rsi_12'] = rsi_series.iloc[-1]
    
    hist_60 = df.tail(60)
    res['position_60d'] = (close.iloc[-1] - hist_60['low'].min()) / (hist_60['high'].max() - hist_60['low'].min() + 1e-9) * 100
  
    return res

@st.cache_data(ttl=3600*12)
def get_market_state(trade_date):
    start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=40)).strftime("%Y%m%d")
    index_data = safe_get('daily', ts_code='000300.SH', start_date=start_date, end_date=trade_date, is_index=True)
    if index_data.empty or len(index_data) < 20: return 'Weak'
    index_data = index_data.sort_values('trade_date')
    latest_close = index_data.iloc[-1]['close']
    ma20 = index_data['close'].tail(20).mean()
    return 'Strong' if latest_close > ma20 else 'Weak'

# ---------------------------
# æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° (æœ€ç»ˆç¨³å®šç‰ˆ)
# ---------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, MAX_UPPER_SHADOW, MAX_TURNOVER_RATE, MIN_BODY_POS, RSI_LIMIT, CHIP_MIN_WIN_RATE, SECTOR_THRESHOLD, MIN_MV, MAX_MV, MAX_PREV_PCT, MIN_PRICE):
    global GLOBAL_STOCK_INDUSTRY
    
    market_state = get_market_state(last_trade)
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤± {last_trade}"

    # === å®‰å…¨è·å– stock_basic ===
    stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date')
    if stock_basic.empty or 'name' not in stock_basic.columns:
        stock_basic = safe_get('stock_basic', list_status='L')
    
    # ç­¹ç æ•°æ®
    chip_dict = {}
    try:
        chip_df = safe_get('cyq_perf', trade_date=last_trade)
        if not chip_df.empty:
            chip_dict = dict(zip(chip_df['ts_code'], chip_df['winner_rate']))
    except: pass 
    
    strong_industry_codes = set()
    try:
        sw_df = safe_get('sw_daily', trade_date=last_trade)
        if not sw_df.empty:
            strong_sw = sw_df[sw_df['pct_chg'] >= SECTOR_THRESHOLD]
            strong_industry_codes = set(strong_sw['index_code'].tolist())
    except: pass 
        
    df = daily_all.merge(stock_basic, on='ts_code', how='left')
    if 'name' not in df.columns: df['name'] = ''

    daily_basic = safe_get('daily_basic', trade_date=last_trade)
    if not daily_basic.empty:
        needed_cols = ['ts_code','turnover_rate','circ_mv','amount']
        existing_cols = [c for c in needed_cols if c in daily_basic.columns]
        df = df.merge(daily_basic[existing_cols], on='ts_code', how='left')
    
    mf_raw = safe_get('moneyflow', trade_date=last_trade)
    if not mf_raw.empty:
        mf = mf_raw[['ts_code','net_mf_amount']].rename(columns={'net_mf_amount':'net_mf'})
        df = df.merge(mf, on='ts_code', how='left')
    
    for col in ['net_mf', 'turnover_rate', 'circ_mv', 'amount']:
        if col not in df.columns: df[col] = 0
    df['net_mf'] = df['net_mf'].fillna(0)
    df['circ_mv_billion'] = df['circ_mv'] / 10000 
    
    df = df[~df['name'].str.contains('ST|é€€', na=False)]
    df = df[~df['ts_code'].str.startswith('92')]
    
    # === ä½¿ç”¨ä¾§è¾¹æ é…ç½®çš„ä»·æ ¼é™åˆ¶ ===
    df = df[(df['close'] >= MIN_PRICE) & (df['close'] <= 2000.0)]
    
    df = df[(df['circ_mv_billion'] >= MIN_MV) & (df['circ_mv_billion'] <= MAX_MV)]
    df = df[df['turnover_rate'] <= MAX_TURNOVER_RATE] 

    if len(df) == 0: return pd.DataFrame(), "è¿‡æ»¤åæ— æ ‡çš„"

    candidates = df.sort_values('pct_chg', ascending=False).head(FINAL_POOL)
    records = []
    
    for row in candidates.itertuples():
        if GLOBAL_STOCK_INDUSTRY and strong_industry_codes:
            ind_code = GLOBAL_STOCK_INDUSTRY.get(row.ts_code)
            if ind_code and (ind_code not in strong_industry_codes): continue
        
        # === æ ¸å¿ƒé£æ§ï¼šé“è¡€æ‰§è¡Œ 19% é™åˆ¶ ===
        # ä¸ç®¡ RSI å¤šé«˜ï¼Œåªè¦æ˜¨æ—¥æ¶¨å¹… > 19%ï¼Œä¸€å¾‹å‰”é™¤ï¼
        if row.pct_chg > MAX_PREV_PCT: 
            continue
        # ================================

        ind = compute_indicators(row.ts_code, last_trade)
        if not ind: continue
        d0_close = ind['last_close']
        d0_rsi = ind.get('rsi_12', 50)
        
        # åŸºç¡€é£æ§
        if market_state == 'Weak':
            if d0_rsi > RSI_LIMIT: continue
            if d0_close < ind['ma20'] or ind['position_60d'] > 20.0: continue
        if d0_close < ind['ma60']: continue
        
        upper_shadow = (ind['last_high'] - d0_close) / d0_close * 100
        if upper_shadow > MAX_UPPER_SHADOW: continue
        range_len = ind['last_high'] - ind['last_low']
        if range_len > 0:
            body_pos = (d0_close - ind['last_low']) / range_len
            if body_pos < MIN_BODY_POS: continue

        # ç­¹ç é£æ§
        win_rate = chip_dict.get(row.ts_code, None)
        if win_rate is not None:
            if win_rate < CHIP_MIN_WIN_RATE: continue
        else: win_rate = 50 

        future = get_future_prices(row.ts_code, last_trade, d0_close)
        records.append({
            'ts_code': row.ts_code, 'name': row.name, 'Close': row.close, 'Pct_Chg': row.pct_chg,
            'rsi': d0_rsi, 'winner_rate': win_rate, 'macd': ind['macd_val'], 'net_mf': row.net_mf,
            'Return_D1 (%)': future.get('Return_D1', np.nan),
            'Return_D3 (%)': future.get('Return_D3', np.nan),
            'Return_D5 (%)': future.get('Return_D5', np.nan),
            'market_state': market_state,
            'Sector_Boost': 'Yes' if GLOBAL_STOCK_INDUSTRY else 'N/A'
        })
            
    if not records: return pd.DataFrame(), "æ·±åº¦ç­›é€‰åæ— æ ‡çš„"
    fdf = pd.DataFrame(records)
    
    def dynamic_score(r):
        base_score = r['macd'] * 1000 + (r['net_mf'] / 10000) 
        if r['winner_rate'] > 90: base_score += 1000
        
        # === RSI ç­–ç•¥ï¼šåŠ åˆ† 1000 ===
        # å¥–åŠ±ç¼©é‡çœŸé¾™ï¼Œä½†ä¸è®©æŒ‡æ ‡è™šé«˜çš„ç¥¨æ’é˜Ÿ
        if r['rsi'] > 90: base_score += 3000
            
        if r['market_state'] == 'Strong':
            penalty = 0
            if r['rsi'] > RSI_LIMIT: penalty += 500
            return base_score - penalty
        return base_score

    fdf['Score'] = fdf.apply(dynamic_score, axis=1)
    return fdf.sort_values('Score', ascending=False).head(TOP_BACKTEST), None

# ---------------------------
# UI åŠ ä¸»ç¨‹åº
# ---------------------------
with st.sidebar:
    st.header("V30.12.3 æœ€ç»ˆä¿®æ­£å›é€€ç‰ˆ")
    backtest_date_end = st.date_input("åˆ†ææˆªæ­¢æ—¥æœŸ", value=datetime.now().date())
    BACKTEST_DAYS = st.number_input("åˆ†æå¤©æ•°", value=30, step=1)
    TOP_BACKTEST = st.number_input("æ¯æ—¥ä¼˜é€‰ TopK", value=5, help="ä¿æŒ Top 5 ç²¾è‹±ç­–ç•¥")
    
    st.markdown("---")
    st.subheader("ğŸ’° åŸºç¡€è¿‡æ»¤")
    col1, col2 = st.columns(2)
    MIN_PRICE = col1.number_input("æœ€ä½è‚¡ä»·", value=2.0, help="å»ºè®®è®¾ä¸º2.0ï¼Œé˜²æ­¢è¯¯æ€ä½ä»·é¾™å¤´")
    MIN_MV = col2.number_input("æœ€å°å¸‚å€¼(äº¿)", value=50.0)
    MAX_MV = st.number_input("æœ€å¤§å¸‚å€¼(äº¿)", value=1000.0)
    
    st.markdown("---")
    st.subheader("âš”ï¸ æ ¸å¿ƒé£æ§å‚æ•°")
    
    # 1. 20CM é“è¡€é£æ§
    MAX_PREV_PCT = st.number_input("æ˜¨æ—¥æœ€å¤§æ¶¨å¹…é™åˆ¶ (%)", value=19.0, 
                                 help="â­ æ ¸å¿ƒé£æ§ï¼šå®šæ­»19.0ï¼Œç²¾å‡†å‰”é™¤20CMæ¶¨åœçš„æ·±å¥—è‚¡")
    
    # 2. RSI ç­–ç•¥
    RSI_LIMIT = st.number_input("RSI æ‹¦æˆªçº¿ (å»ºè®®100)", value=100.0, 
                              help="è®¾ä¸º100è¡¨ç¤ºä¸æ‹¦æˆªã€‚")
    
    # 3. ç­¹ç åº•çº¿
    CHIP_MIN_WIN_RATE = st.number_input("æœ€ä½è·åˆ©ç›˜ (%)", value=80.0, 
                                      help="ä½äºæ­¤æ¯”ä¾‹(å¥—ç‰¢ç›˜å¤š)ç›´æ¥å‰”é™¤")
    
    st.markdown("---")
    SECTOR_THRESHOLD = st.number_input("æ¿å—æ¶¨å¹… (%)", value=1.5)
    MAX_UPPER_SHADOW = st.number_input("ä¸Šå½±çº¿ (%)", value=4.0)
    MIN_BODY_POS = st.number_input("å®ä½“ä½ç½®", value=0.7)
    MAX_TURNOVER_RATE = st.number_input("æ¢æ‰‹ç‡ (%)", value=20.0)

TS_TOKEN = st.text_input("Tushare Token", type="password")
if not TS_TOKEN: st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

if st.button(f"ğŸš€ å¯åŠ¨ V30.12.3 å›é€€ç‰ˆå›æµ‹"):
    trade_days_list = get_trade_days(backtest_date_end.strftime("%Y%m%d"), int(BACKTEST_DAYS))
    
    if not trade_days_list:
        st.error("âŒ æ— æ³•è·å–äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– Tokenã€‚")
        st.stop()
        
    if not get_all_historical_data(trade_days_list):
        st.stop()
        
    results = []
    bar = st.progress(0, text="å›æµ‹å¼•æ“æµæ°´çº¿å¯åŠ¨...")
    
    for i, date in enumerate(trade_days_list):
        res, err = run_backtest_for_a_day(date, int(TOP_BACKTEST), 100, MAX_UPPER_SHADOW, MAX_TURNOVER_RATE, MIN_BODY_POS, RSI_LIMIT, CHIP_MIN_WIN_RATE, SECTOR_THRESHOLD, MIN_MV, MAX_MV, MAX_PREV_PCT, MIN_PRICE)
        if not res.empty:
            res['Trade_Date'] = date
            results.append(res)
        
        bar.progress((i+1)/len(trade_days_list), text=f"æ­£åœ¨åˆ†æç¬¬ {i+1} å¤©: {date}")
        
    bar.empty()
    
    if results:
        all_res = pd.concat(results)
        
        st.header("ğŸ“Š V30.12.3 ç»Ÿè®¡ä»ªè¡¨ç›˜")
        cols = st.columns(3)
        for idx, n in enumerate([1, 3, 5]):
            col_name = f'Return_D{n} (%)'
            valid = all_res.dropna(subset=[col_name]) 
            if not valid.empty:
                avg = valid[col_name].mean()
                win = (valid[col_name] > 0).mean() * 100
                cols[idx].metric(f"D+{n} å‡ç›Š / èƒœç‡", f"{avg:.2f}% / {win:.1f}%")
        
        st.subheader("ğŸ“‹ å›æµ‹æ¸…å•")
        display_cols = ['Trade_Date','name','ts_code','Close','Pct_Chg',
             'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)',
                        'rsi','winner_rate','Sector_Boost']
        st.dataframe(all_res[display_cols].sort_values('Trade_Date', ascending=False), use_container_width=True)
        
        csv = all_res.to_csv(index=False).encode('utf-8-sig')
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½å›æµ‹ç»“æœ (CSV)",
            data=csv,
            file_name=f"{datetime.now().strftime('%Y-%m-%d_%H-%M')}_simulation_export.csv",
            mime="text/csv",
        )
    else:
        st.warning("âš ï¸ æ²¡æœ‰é€‰å‡ºä»»ä½•è‚¡ç¥¨ã€‚")
