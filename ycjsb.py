# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆå›æµ‹æ—¥æœŸä¿®æ­£ç»ˆæç‰ˆï¼‰
è¯´æ˜ï¼š
- ç›®æ ‡ï¼š**æ¿€è¿›çŸ­çº¿çˆ†å‘ (B) + å¦–è‚¡æ•æ‰ (C)**
- ã€2025-11-23 æœ€ç»ˆä¿®å¤ã€‘ï¼š
    - ä¿®å¤æˆäº¤é¢å•ä½ï¼ˆå·²è§£å†³é€‰è‚¡æˆåŠŸï¼‰
    - å¢å¼ºå›æµ‹æ•°æ®é²æ£’æ€§ï¼ˆå·²è§£å†³æ•°æ®ç¢ç‰‡åŒ–ï¼‰
    - **ä¿®å¤å›æµ‹æ—¥æœŸèµ·å§‹ç‚¹é”™è¯¯ï¼Œè§£å†³â€œå›æµ‹ä»…è¦†ç›– 1 å¤©â€å’Œâ€œäº¤æ˜“æ¬¡æ•° 0â€çš„é—®é¢˜ã€‚**
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆæ—¥æœŸä¿®æ­£ï¼‰", layout="wide")
st.title("é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆå›æµ‹æ—¥æœŸä¿®æ­£ç»ˆæç‰ˆï¼‰")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚è‹¥æœ‰æƒé™ç¼ºå¤±ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é™çº§å¹¶ç»§ç»­è¿è¡Œã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆå®æ—¶ï¼‰")
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=300, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    # å‚æ•°é»˜è®¤å€¼ï¼šè°ƒè‡³æä½ï¼Œç¡®ä¿é€šè¿‡
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=3.0, step=0.5)) 
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=0.5, step=0.5)) 
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=20_000_000.0, step=10_000_000.0)) # 2000 ä¸‡
    VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.7, step=0.1))
    VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=8.0, step=0.5))
    HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))
    MIN_MARKET_CAP = float(st.number_input("æœ€ä½å¸‚å€¼ (å…ƒ)", value=2000000000.0, step=100000000.0))  
    MAX_MARKET_CAP = float(st.number_input("æœ€é«˜å¸‚å€¼ (å…ƒ)", value=50000000000.0, step=1000000000.0))  
    st.markdown("---")
    # --- æ–°å¢å›æµ‹å‚æ•° ---
    st.header("å†å²å›æµ‹å‚æ•°")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹äº¤æ˜“æ—¥å¤©æ•°", value=60, min_value=10, max_value=250))
    HOLD_DAYS_OPTIONS = st.multiselect("å›æµ‹æŒè‚¡å¤©æ•°", options=[1, 3, 5, 10, 20], default=[1, 3, 5])
    # ---
    st.caption("æç¤ºï¼š**å›æµ‹æ—¥æœŸå·²ä¿®æ­£ï¼Œåº”èƒ½è¦†ç›–è¶³å¤Ÿçš„å¤©æ•°ã€‚**")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# å®‰å…¨è°ƒç”¨ & ç¼“å­˜è¾…åŠ©
# ---------------------------
def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†å¹¶ç¼“å­˜"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        return df[df.is_open == 1]['cal_date'].tolist()
    except Exception:
        return []

@st.cache_data(ttl=6000)
def get_bulk_daily_data(ts_codes, start_date, end_date):
    """æ‰¹é‡è·å–æŒ‡å®šè‚¡ç¥¨å’Œæ—¥æœŸçš„ daily æ•°æ® (ä»…ç”¨äºå®æ—¶è¯„åˆ†)"""
    all_data = []
    trade_dates = get_trade_cal(start_date, end_date)
    
    st.write(f"æ­£åœ¨æ‰¹é‡åŠ è½½ {len(trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„ daily æ•°æ® (ç”¨äºæŒ‡æ ‡è®¡ç®—)...")
    pbar = st.progress(0)
    for i, date in enumerate(trade_dates):
        daily_df = safe_get(pro.daily, trade_date=date)
        if not daily_df.empty:
            all_data.append(daily_df)
        pbar.progress((i + 1) / len(trade_dates))
    pbar.progress(1.0)
    
    if not all_data:
        return pd.DataFrame()

    full_df = pd.concat(all_data, ignore_index=True)
    if ts_codes:
        full_df = full_df[full_df['ts_code'].isin(ts_codes)]
    
    return full_df.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)

@st.cache_data(ttl=600)
def find_last_trade_day(max_days=20):
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# ---------------------------
# æ‹‰å½“æ—¥æ¶¨å¹…æ¦œåˆç­›
# ---------------------------
st.write("æ­£åœ¨æ‹‰å–å½“æ—¥ dailyï¼ˆæ¶¨å¹…æ¦œï¼‰ä½œä¸ºåˆç­›...")
daily_all = safe_get(pro.daily, trade_date=last_trade)
if daily_all.empty:
    st.error("æ— æ³•è·å–å½“æ—¥ daily æ•°æ®ï¼ˆTushare è¿”å›ç©ºï¼‰ã€‚è¯·ç¡®è®¤ Token æƒé™ã€‚")
    st.stop()

daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
st.write(f"å½“æ—¥è®°å½•ï¼š{len(daily_all)}ï¼Œå–æ¶¨å¹…å‰ {INITIAL_TOP_N} ä½œä¸ºåˆç­›ã€‚")
pool0 = daily_all.head(int(INITIAL_TOP_N)).copy().reset_index(drop=True)

# ---------------------------
# å°è¯•åŠ è½½é«˜çº§æ¥å£ï¼ˆæœ‰æƒé™æ—¶å¯ç”¨ï¼‰
# ---------------------------
st.write("å°è¯•åŠ è½½ stock_basic / daily_basic / moneyflow ç­‰é«˜çº§æ¥å£ï¼ˆè‹¥æƒé™å…è®¸ï¼‰...")
stock_list = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,list_date,total_mv,circ_mv')
daily_basic = safe_get(pro.daily_basic, trade_date=last_trade, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
mf_raw = safe_get(pro.moneyflow, trade_date=last_trade)

# moneyflow é¢„å¤„ç†
if not mf_raw.empty:
    possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out']
    col = None
    for c in possible:
        if c in mf_raw.columns:
            col = c; break
    if col is None:
        numeric_cols = [c for c in mf_raw.columns if c != 'ts_code' and pd.api.types.is_numeric_dtype(mf_raw[c])]
        col = numeric_cols[0] if numeric_cols else None
    if col:
        moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
    else:
        moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
else:
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    st.warning("moneyflow æœªè·å–åˆ°ï¼Œå°†æŠŠä¸»åŠ›æµå‘å› å­ç½®ä¸º 0ã€‚")

# ---------------------------
# åˆå¹¶åŸºæœ¬ä¿¡æ¯ï¼ˆsafeï¼‰
# ---------------------------
def safe_merge_pool(pool_df, other_df, cols):
    pool = pool_df.copy()
    if other_df is None or other_df.empty or 'ts_code' not in other_df.columns:
        return pool
    cols_to_merge = [c for c in cols if c in other_df.columns]
    if not cols_to_merge:
        return pool
    try:
        joined = pool.merge(other_df[['ts_code'] + cols_to_merge], on='ts_code', how='left')
        return joined
    except Exception:
        return pool

# merge stock_basic
if not stock_list.empty:
    keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv'] if c in stock_list.columns]
    try:
        pool0 = pool0.merge(stock_list[keep], on='ts_code', how='left')
    except Exception:
        pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
else:
    pool0['name'] = pool0['ts_code']; pool0['industry'] = ''

# merge daily_basic
pool_merged = safe_merge_pool(pool0, daily_basic, ['turnover_rate','amount','total_mv','circ_mv'])

# merge moneyflow robustly
if not moneyflow.empty:
    pool_merged = pool_merged.merge(moneyflow, on='ts_code', how='left')
if 'net_mf' not in pool_merged.columns:
    pool_merged['net_mf'] = 0.0
pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0.0)

# ---------------------------
# åŸºæœ¬æ¸…æ´—ï¼ˆST / åœç‰Œ / ä»·æ ¼åŒºé—´ / ä¸€å­—æ¿ / æ¢æ‰‹ / æˆäº¤é¢ / å¸‚å€¼ï¼‰
# ---------------------------
st.write("å¯¹åˆç­›æ± è¿›è¡Œæ¸…æ´—ï¼ˆST/åœç‰Œ/ä»·æ ¼/ä¸€å­—æ¿/æ¢æ‰‹/æˆäº¤é¢ç­‰ï¼‰...")

pool_merged['total_mv_yuan'] = pool_merged['total_mv'].fillna(0) * 10000

clean_df = pool_merged.copy()

# 1. è¿‡æ»¤ ST / é€€å¸‚ / åŒ—äº¤æ‰€
clean_df = clean_df[~clean_df['name'].str.contains('ST|é€€|N', na=False, case=False)]
clean_df = clean_df[~clean_df['ts_code'].str.startswith('4', na=False)]
clean_df = clean_df[~clean_df['ts_code'].str.startswith('8', na=False)]

# 2. ä»·æ ¼è¿‡æ»¤
clean_df = clean_df[(clean_df['close'] >= MIN_PRICE) & (clean_df['close'] <= MAX_PRICE)]

# 3. å¸‚å€¼è¿‡æ»¤
clean_df = clean_df[(clean_df['total_mv_yuan'] >= MIN_MARKET_CAP) & (clean_df['total_mv_yuan'] <= MAX_MARKET_CAP)]

# 4. æ¢æ‰‹ç‡è¿‡æ»¤
if 'turnover_rate' in clean_df.columns:
    clean_df['turnover_rate'] = clean_df['turnover_rate'].fillna(0)
    clean_df = clean_df[clean_df['turnover_rate'] >= MIN_TURNOVER]
else:
    st.warning("daily_basic æ¥å£ç¼ºå¤±ï¼Œè·³è¿‡æ¢æ‰‹ç‡è¿‡æ»¤ã€‚")

# 5. ã€å…³é”®ä¿®æ­£ï¼šæˆäº¤é¢å•ä½è½¬æ¢ã€‘
daily_amount = daily_all[['ts_code', 'amount']].copy()
daily_amount['amount_actual_yuan'] = daily_amount['amount'].astype(float) * 1000.0 

clean_df = clean_df.merge(daily_amount[['ts_code', 'amount_actual_yuan']], on='ts_code', how='left')
clean_df['amount_actual_yuan'] = clean_df['amount_actual_yuan'].fillna(0) 

# è¿‡æ»¤ï¼šæˆäº¤é¢(å…ƒ) >= æœ€ä½æˆäº¤é¢(å…ƒ)
clean_df = clean_df[clean_df['amount_actual_yuan'] >= MIN_AMOUNT]

# 6. è¿‡æ»¤åœç‰Œ/æ— æˆäº¤
clean_df = clean_df[(clean_df['vol'] > 0) & (clean_df['amount_actual_yuan'] > 0)]

# 7. è¿‡æ»¤ä¸€å­—æ¶¨åœæ¿ (ä½¿ç”¨ open == high)
clean_df['is_zt'] = (clean_df['open'] == clean_df['high']) & (clean_df['pct_chg'] > 9.5)
clean_df = clean_df[~clean_df['is_zt']]


st.write(f"æ¸…æ´—åå€™é€‰æ•°é‡ï¼š{len(clean_df)} ï¼ˆå°†ä»ä¸­å–æ¶¨å¹…å‰ {FINAL_POOL} è¿›å…¥è¯„åˆ†é˜¶æ®µï¼‰")
if len(clean_df) == 0:
    st.error("æ¸…æ´—åæ²¡æœ‰å€™é€‰ï¼Œè¿™é€šå¸¸æ˜¯ Tushare Token æ¥å£æƒé™ç¼ºå¤±ï¼Œæ— æ³•è·å–åˆ°åŸºæœ¬çš„ daily/daily_basic æ•°æ®å¯¼è‡´ã€‚")
    st.stop()

# ---------------------------
# å–æ¶¨å¹…å‰ FINAL_POOL è¿›å…¥è¯„åˆ†æ± 
# ---------------------------
clean_df = clean_df.sort_values('pct_chg', ascending=False).head(int(FINAL_POOL)).reset_index(drop=True)
st.write(f"ç”¨äºè¯„åˆ†çš„æ± å­å¤§å°ï¼š{len(clean_df)}")

# ---------------------------
# æ‰¹é‡è·å– K çº¿å†å²æ•°æ® (ä»…ç”¨äºå®æ—¶è¯„åˆ†ï¼Œæ•°æ®å¯èƒ½ä¼šä¸å…¨)
# ---------------------------
latest_date = last_trade
max_hist_days = 60 
start_date_hist = (datetime.strptime(latest_date, "%Y%m%d") - timedelta(days=max_hist_days * 2)).strftime("%Y%m%d")
GLOBAL_KLINE_DATA = get_bulk_daily_data(clean_df['ts_code'].unique().tolist(), start_date_hist, latest_date)

def get_hist_cached_bulk(ts_code, end_date, days=60):
    """ä»å…¨å±€ç¼“å­˜ä¸­è·å–å†å² K çº¿æ•°æ®"""
    if GLOBAL_KLINE_DATA.empty:
        return pd.DataFrame()
        
    hist_df = GLOBAL_KLINE_DATA[GLOBAL_KLINE_DATA['ts_code'] == ts_code].copy()
    
    if hist_df.empty:
        return pd.DataFrame()
    
    hist_df = hist_df[hist_df['trade_date'] <= end_date]
    hist_df = hist_df.tail(days * 2) 
    
    return hist_df.sort_values('trade_date').reset_index(drop=True)

# ---------------------------
# æŒ‡æ ‡è®¡ç®—ï¼ˆä½¿ç”¨ bulk ç¼“å­˜ï¼‰
# ---------------------------
def compute_indicators(df):
    res = {}
    if df.empty or len(df) < 3: return res
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)

    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan

    # MA
    for n in (5,10,20):
        if len(close) >= n:
            res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else:
            res[f'ma{n}'] = np.nan

    # MACD 
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1]; res['dea'] = dea.iloc[-1]
    else:
        res['macd'] = res['diff'] = res['dea'] = np.nan

    # KDJ
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = np.nan

    # vol ratio and metrics
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    # 10d return
    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan

    # prev3_sum for down-then-bounce detection
    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    # volatility (std of last 10 pct_chg)
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except:
        res['volatility_10'] = np.nan

    # recent 20-day high for breakout detection
    try:
        if len(high) >= 20:
            res['recent20_high'] = float(high.tail(20).max())
        else:
            res['recent20_high'] = float(high.max()) if len(high)>0 else np.nan
    except:
        res['recent20_high'] = np.nan

    # é˜³çº¿å®ä½“å¼ºåº¦ï¼ˆä»Šå¤©ï¼‰
    try:
        today_open = df['open'].astype(float).iloc[-1]
        today_close = df['close'].astype(float).iloc[-1]
        today_high = df['high'].astype(float).iloc[-1]
        today_low = df['low'].astype(float).iloc[-1]
        body = abs(today_close - today_open)
        rng = max(today_high - today_low, 1e-9)
        res['yang_body_strength'] = body / rng
    except:
        res['yang_body_strength'] = 0.0

    return res

# è¯„åˆ†è®¡ç®—
st.write("ä¸ºè¯„åˆ†æ± é€ç¥¨è®¡ç®—æŒ‡æ ‡...")
records = []
pbar2 = st.progress(0)
for idx, row in enumerate(clean_df.itertuples()):
    ts_code = getattr(row, 'ts_code')
    name = getattr(row, 'name', ts_code)
    pct_chg = getattr(row, 'pct_chg', 0.0)
    amount = getattr(row, 'amount_actual_yuan', 0.0) 
    turnover_rate = getattr(row, 'turnover_rate', np.nan)
    net_mf = float(getattr(row, 'net_mf', 0.0))

    hist = get_hist_cached_bulk(ts_code, last_trade, days=60)
    ind = compute_indicators(hist)

    vol_ratio = ind.get('vol_ratio', np.nan)
    ten_return = ind.get('10d_return', np.nan)
    ma5 = ind.get('ma5', np.nan)
    ma10 = ind.get('ma10', np.nan)
    ma20 = ind.get('ma20', np.nan)
    macd = ind.get('macd', np.nan)
    diff = ind.get('diff', np.nan)
    dea = ind.get('dea', np.nan)
    k, d, j = ind.get('k', np.nan), ind.get('d', np.nan), ind.get('j', np.nan)
    last_close = ind.get('last_close', np.nan)
    vol_last = ind.get('vol_last', np.nan)
    vol_ma5 = ind.get('vol_ma5', np.nan)
    prev3_sum = ind.get('prev3_sum', np.nan)
    volatility_10 = ind.get('volatility_10', np.nan)
    recent20_high = ind.get('recent20_high', np.nan)
    yang_body_strength = ind.get('yang_body_strength', 0.0)

    # èµ„é‡‘å¼ºåº¦ä»£ç†
    try:
        proxy_money = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)
    except:
        proxy_money = 0.0

    rec = {
        'ts_code': ts_code, 'name': name, 'pct_chg': pct_chg,
        'amount': amount,
        'turnover_rate': turnover_rate if not pd.isna(turnover_rate) else np.nan,
        'net_mf': net_mf,
        'vol_ratio': vol_ratio if not pd.isna(vol_ratio) else np.nan,
        '10d_return': ten_return if not pd.isna(ten_return) else np.nan,
        'ma5': ma5, 'ma10': ma10, 'ma20': ma20,
        'macd': macd, 'diff': diff, 'dea': dea, 'k': k, 'd': k, 'j': j,
        'last_close': last_close, 'vol_last': vol_last, 'vol_ma5': vol_ma5, 'recent20_high': recent20_high, 'yang_body_strength': yang_body_strength,
        'prev3_sum': prev3_sum, 'volatility_10': volatility_10,
        'proxy_money': proxy_money
    }

    records.append(rec)
    pbar2.progress((idx+1)/len(clean_df))

pbar2.progress(1.0)
fdf = pd.DataFrame(records)
if fdf.empty:
    st.error("è¯„åˆ†è®¡ç®—å¤±è´¥æˆ–æ— æ•°æ®ï¼Œè¯·æ£€æŸ¥ Token æƒé™ä¸æ¥å£ã€‚")
    st.stop()


# ---------------------------
# é£é™©è¿‡æ»¤
# ---------------------------
st.write("æ‰§è¡Œé£é™©è¿‡æ»¤ï¼šä¸‹è·Œé€”ä¸­å¤§é˜³ / é«˜ä½å¤§é˜³ ...")
try:
    before_cnt = len(fdf)
    # A: é«˜ä½å¤§é˜³çº¿
    HIGH_PCT_THRESHOLD_VAL = float(HIGH_PCT_THRESHOLD) # ä½¿ç”¨å‚æ•°
    if all(c in fdf.columns for c in ['ma20','last_close','pct_chg']):
        mask_high_big = (fdf['last_close'] > fdf['ma20'] * 1.10) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD_VAL)
        fdf = fdf[~mask_high_big]

    # B: ä¸‹è·Œé€”ä¸­åæŠ½
    if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
        mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD_VAL)
        fdf = fdf[~mask_down_rebound]

    after_cnt = len(fdf)
    st.write(f"é£é™©è¿‡æ»¤ï¼š{before_cnt} -> {after_cnt}ï¼ˆä»…ä¿ç•™è¿½é«˜é£é™©ï¼‰")
except Exception as e:
    st.warning(f"é£é™©è¿‡æ»¤æ¨¡å—å¼‚å¸¸ï¼Œè·³è¿‡è¿‡æ»¤ã€‚é”™è¯¯ï¼š{e}")

# ---------------------------
# RSLï¼ˆç›¸å¯¹å¼ºå¼±ï¼‰
# ---------------------------
if '10d_return' in fdf.columns:
    try:
        market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
        if np.isnan(market_mean_10d) or abs(market_mean_10d) < 1e-9:
            market_mean_10d = 1e-9
        fdf['rsl'] = fdf['10d_return'] / market_mean_10d
    except:
        fdf['rsl'] = 1.0
else:
    fdf['rsl'] = 1.0

# ---------------------------
# å­æŒ‡æ ‡å½’ä¸€åŒ–ï¼ˆç¨³å¥ï¼‰
# ---------------------------
def norm_col(s):
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9:
        return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)

fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
if 'net_mf' in fdf.columns and fdf['net_mf'].abs().sum() > 0:
    fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf))))
else:
    fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
fdf['s_volatility'] = norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

# ---------------------------
# è¶‹åŠ¿å› å­ä¸å¼ºåŒ–è¯„åˆ†
# ---------------------------
fdf['ma_trend_flag'] = ((fdf.get('ma5', pd.Series([])) > fdf.get('ma10', pd.Series([]))) & (fdf.get('ma10', pd.Series([])) > fdf.get('ma20', pd.Series([])))).fillna(False)
fdf['macd_golden_flag'] = (fdf.get('diff', 0) > fdf.get('dea', 0)).fillna(False)
fdf['vol_price_up_flag'] = (fdf.get('vol_last', 0) > fdf.get('vol_ma5', 0)).fillna(False)
fdf['break_high_flag'] = (fdf.get('last_close', 0) > fdf.get('recent20_high', 0)).fillna(False)
fdf['yang_body_strength'] = fdf.get('yang_body_strength', 0.0).fillna(0.0)

# ç»„åˆæˆè¶‹åŠ¿åŸå§‹åˆ†
fdf['trend_score_raw'] = (
    fdf['ma_trend_flag'].astype(float) * 1.5 +  
    fdf['macd_golden_flag'].astype(float) * 1.3 +
    fdf['vol_price_up_flag'].astype(float) * 1.0 +
    fdf['break_high_flag'].astype(float) * 1.3 +
    fdf['yang_body_strength'].astype(float) * 0.8
)

# å½’ä¸€åŒ–è¶‹åŠ¿åˆ†
fdf['trend_score'] = norm_col(fdf['trend_score_raw'])

# ---------------------------
# æœ€ç»ˆç»¼åˆè¯„åˆ†
# ---------------------------
fdf['ç»¼åˆè¯„åˆ†'] = (
    fdf['trend_score'] * 0.40 +      
    fdf.get('s_10d', 0)*0.10 +       
    fdf.get('s_rsl', 0)*0.08 +       
    fdf.get('s_volratio', 0)*0.10 +  
    fdf.get('s_turn', 0)*0.10 +      
    fdf.get('s_money', 0)*0.10 +     
    fdf.get('s_pct', 0)*0.05 +       
    fdf.get('s_volatility', 0)*0.07  
)

# ---------------------------
# æœ€ç»ˆæ’åºä¸å±•ç¤º
# ---------------------------
fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
fdf.index = fdf.index + 1

st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(TOP_DISPLAY, len(fdf))}ã€‚")
display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','vol_ratio','turnover_rate','net_mf','proxy_money','amount','10d_return','macd','diff','dea','k','d','j','rsl','volatility_10']
for c in display_cols:
    if c not in fdf.columns:
        fdf[c] = np.nan

st.dataframe(fdf[display_cols].head(TOP_DISPLAY), use_container_width=True)

# ä¸‹è½½
out_csv = fdf[display_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}.csv", mime="text/csv")

# ---------------------------
# å†å²å›æµ‹éƒ¨åˆ†ï¼ˆæ•°æ®é²æ£’æ€§å¢å¼º & æ—¥æœŸä¿®æ­£ï¼‰
# ---------------------------
@st.cache_data(ttl=6000)
def run_backtest(start_date, end_date, hold_days, top_k):
    # start_date å’Œ end_date ä¹‹é—´åº”è¯¥æœ‰è¶³å¤Ÿå¤šçš„äº¤æ˜“æ—¥
    trade_dates = get_trade_cal(start_date, end_date)
    
    if not trade_dates:
        return {h: {'returns': [], 'wins': 0, 'total': 0, 'win_rate': 0.0, 'avg_return': 0.0} for h in hold_days}

    results = {h: {'returns': [], 'wins': 0, 'total': 0, 'win_rate': 0.0, 'avg_return': 0.0} for h in hold_days}
    
    # ç¡®å®šå›æµ‹å®é™…çš„èµ·å§‹æ—¥ï¼ˆå›æº¯ x å¤©ï¼‰
    bt_start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=BACKTEST_DAYS * 1.5)).strftime("%Y%m%d")
    
    # ç¡®ä¿åªå›æµ‹ BACKTEST_DAYS ä¸ªäº¤æ˜“æ—¥
    backtest_dates = [d for d in trade_dates if d >= bt_start and d <= end_date]
    if len(backtest_dates) < BACKTEST_DAYS:
        st.warning(f"ç”±äºæ•°æ®æˆ–äº¤æ˜“æ—¥é™åˆ¶ï¼Œå›æµ‹ä»…èƒ½è¦†ç›– {len(backtest_dates)} å¤©ã€‚")
    
    # å–æœ€è¿‘çš„ BACKTEST_DAYS ä¸ªäº¤æ˜“æ—¥ä½œä¸ºä¹°å…¥æ—¥æœŸæ± 
    backtest_dates = backtest_dates[-BACKTEST_DAYS:]
    
    st.write(f"æ­£åœ¨æ¨¡æ‹Ÿ {len(backtest_dates)} ä¸ªäº¤æ˜“æ—¥çš„é€‰è‚¡å›æµ‹...")
    pbar_bt = st.progress(0)
    
    for i, buy_date in enumerate(backtest_dates):
        # æ¨¡æ‹Ÿå½“æ—¥é€‰è‚¡ï¼šç›´æ¥è°ƒç”¨ API è·å–å½“æ—¥æ•°æ®ï¼Œæ›´ç¨³å®š
        daily_df = safe_get(pro.daily, trade_date=buy_date)
        
        if daily_df.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue

        # æ¨¡æ‹Ÿå½“æ—¥çš„ç­›é€‰é€»è¾‘ (ç®€åŒ–ç‰ˆ)
        daily_df = daily_df.sort_values("pct_chg", ascending=False).head(INITIAL_TOP_N).copy()
        
        # 1. ä»·æ ¼ã€æˆäº¤é¢è¿‡æ»¤ (å›æµ‹ä¸­ä¿®æ­£å•ä½)
        daily_df['amount_yuan'] = daily_df['amount'].fillna(0) * 1000.0 # **å›æµ‹ä¸­ä¿®æ­£å•ä½**
        daily_df = daily_df[(daily_df['close'] >= MIN_PRICE) & (daily_df['close'] <= MAX_PRICE)]
        daily_df = daily_df[daily_df['amount_yuan'] >= MIN_AMOUNT]
        
        # 2. è¿‡æ»¤åœç‰Œ/æ— æˆäº¤
        daily_df = daily_df[(daily_df['vol'] > 0) & (daily_df['amount_yuan'] > 0)]

        # 3. è¿‡æ»¤ä¸€å­—æ¶¨åœæ¿ (ä½¿ç”¨ open == high)
        daily_df['is_zt'] = (daily_df['open'] == daily_df['high']) & (daily_df['pct_chg'] > 9.5)
        daily_df = daily_df[~daily_df['is_zt']]

        # æ¨¡æ‹Ÿè¯„åˆ†ï¼šç®€åŒ–ä¸ºå–å½“æ—¥æ¶¨å¹…æ¦œå‰ top_k
        scored_stocks = daily_df.head(top_k).copy()
        
        for _, row in scored_stocks.iterrows():
            ts_code = row['ts_code']
            buy_price = float(row['close']) 
            
            if pd.isna(buy_price) or buy_price <= 0: continue

            for h in hold_days:
                try:
                    # ç¡®å®šå–å‡ºæ—¥æœŸåœ¨ trade_dates ä¸­çš„ä½ç½®
                    current_index = trade_dates.index(buy_date)
                    sell_date = trade_dates[current_index + h]
                except (ValueError, IndexError):
                    continue
                
                # è·å–å–å‡ºä»·æ ¼ - ç›´æ¥è°ƒç”¨ APIï¼Œå¢åŠ é²æ£’æ€§
                sell_price_df = safe_get(pro.daily, trade_date=sell_date, ts_code=ts_code)
                sell_price = sell_price_df['close'].iloc[0] if not sell_price_df.empty else np.nan
                
                if pd.isna(sell_price) or sell_price <= 0: continue
                
                ret = (sell_price / buy_price) - 1.0
                results[h]['total'] += 1
                results[h]['returns'].append(ret)
                if ret > 0:
                    results[h]['wins'] += 1

        pbar_bt.progress((i+1)/len(backtest_dates))

    pbar_bt.progress(1.0)
    
    final_results = {}
    for h, res in results.items():
        total = res['total']
        if total > 0:
            avg_return = np.mean(res['returns']) * 100.0
            win_rate = (res['wins'] / total) * 100.0
        else:
            avg_return = 0.0
            win_rate = 0.0
            
        final_results[h] = {
            'å¹³å‡æ”¶ç›Šç‡ (%)': f"{avg_return:.2f}",
            'èƒœç‡ (%)': f"{win_rate:.2f}",
            'æ€»äº¤æ˜“æ¬¡æ•°': total
        }
        
    return final_results

# ---------------------------
# å›æµ‹æ‰§è¡Œ
# ---------------------------
if st.checkbox("âœ… è¿è¡Œå†å²å›æµ‹ (ä½¿ç”¨ Top K)", value=False):
    if not HOLD_DAYS_OPTIONS:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå›æµ‹æŒè‚¡å¤©æ•°ã€‚")
    else:
        st.header("ğŸ“ˆ å†å²å›æµ‹ç»“æœï¼ˆä¹°å…¥æ”¶ç›˜ä»· / å–å‡ºæ”¶ç›˜ä»·ï¼‰")
        
        # ã€æ ¸å¿ƒä¿®å¤ã€‘ï¼šè®¡ç®—ä¸€ä¸ªè¶³å¤Ÿè¿œçš„èµ·å§‹æ—¥æœŸ
        try:
            # å¾€å›æ¨ 200 ä¸ªæ—¥å†æ—¥ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„äº¤æ˜“æ—¥è¢«åŒ…å«
            start_date_for_cal = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
        except:
            start_date_for_cal = (datetime.now() - timedelta(days=200)).strftime("%Y%m%d")
            
        backtest_result = run_backtest(
            start_date=start_date_for_cal, # ä¼ å…¥ä¸€ä¸ªè¶³å¤Ÿæ—©çš„æ—¥æœŸ
            end_date=last_trade,
            hold_days=HOLD_DAYS_OPTIONS,
            top_k=TOP_DISPLAY
        )

        bt_df = pd.DataFrame(backtest_result).T
        bt_df.index.name = "æŒè‚¡å¤©æ•°"
        bt_df = bt_df.reset_index()
        bt_df['æŒè‚¡å¤©æ•°'] = bt_df['æŒè‚¡å¤©æ•°'].astype(str) + ' å¤©'
        
        st.dataframe(bt_df, use_container_width=True, hide_index=True)
        st.success("å›æµ‹å®Œæˆï¼")
        
        export_df = bt_df.copy()
        export_df.columns = ['HoldDays', 'AvgReturn', 'WinRate', 'TotalTrades']
        out_csv_bt = export_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "ä¸‹è½½å›æµ‹ç»“æœ CSV", 
            data=out_csv_bt, 
            file_name=f"backtest_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv", 
            mime="text/csv"
        )


# ---------------------------
# å°ç»“ä¸å»ºè®®ï¼ˆç®€æ´ï¼‰
# ---------------------------
st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆå›æµ‹æ—¥æœŸä¿®æ­£ç‰ˆï¼‰")
st.markdown("""
- **å½“å‰ä»£ç ï¼š** **å›æµ‹æ—¥æœŸä¿®æ­£ç»ˆæç‰ˆ**ï¼Œå·²ä¿®å¤å›æµ‹èµ·å§‹æ—¥æœŸé”™è¯¯ã€‚
- **æ“ä½œï¼š** è¯·é‡æ–°è¿è¡Œè„šæœ¬ï¼Œå¹¶å‹¾é€‰åº•éƒ¨çš„ **â€œâœ… è¿è¡Œå†å²å›æµ‹â€** é€‰é¡¹ã€‚
""")
