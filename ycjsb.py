# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· å³ä¾§å¯åŠ¨/å¼ºåŠ¿è‚¡ç­–ç•¥ v1.0
è¯´æ˜ï¼š
- æ ¸å¿ƒç­–ç•¥ï¼šå¯»æ‰¾ MACD é‡‘å‰ã€å‡çº¿å¤šå¤´ã€æ”¾é‡çªç ´ 20 æ—¥é«˜ç‚¹çš„â€œå³ä¾§å¯åŠ¨â€å¼ºåŠ¿è‚¡ã€‚
- ç¡¬æ€§è¿‡æ»¤ï¼šå¸‚å€¼/ä»·æ ¼åŒºé—´ã€ST/åŒ—äº¤æ‰€ã€20æ—¥æ¶¨å¹…ä¸è¶…è¿‡60%ã€‚
- å›æµ‹æ¨¡å—ï¼šåŠ å…¥ 1/3/5 å¤©æŒè‚¡å›æµ‹ï¼Œä»¥éªŒè¯çŸ­æœŸè¡¨ç°ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· å³ä¾§å¯åŠ¨/å¼ºåŠ¿è‚¡ç­–ç•¥ v1.0", layout="wide")
st.title("é€‰è‚¡ç‹ Â· å³ä¾§å¯åŠ¨/å¼ºåŠ¿è‚¡ç­–ç•¥ v1.0")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenã€‚æœ¬ç­–ç•¥æ ¸å¿ƒä¸º**å¯»æ‰¾çªç ´å¼ºåŠ¿è‚¡**ï¼Œä¸å‡å€¼å›å½’ç­–ç•¥å®Œå…¨ç›¸åã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆç­–ç•¥æ ¸å¿ƒï¼‰")
    # ç­–ç•¥ç¡¬æ€§è¿‡æ»¤å‚æ•°
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    MIN_MARKET_CAP = float(st.number_input("æœ€ä½å¸‚å€¼ (å…ƒ)", value=2000000000.0, step=100000000.0)) # é»˜è®¤ 20äº¿
    MAX_MARKET_CAP = float(st.number_input("æœ€é«˜å¸‚å€¼ (å…ƒ)", value=50000000000.0, step=1000000000.0)) # é»˜è®¤ 500äº¿
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=3.0, step=0.5))
    VOL_RATIO_THRESHOLD = float(st.number_input("æœ€ä½é‡æ¯”é˜ˆå€¼ (vol_ratio >= x)", value=1.5, step=0.1, help="é‡æ¯” 1.5 è¡¨ç¤ºä»Šæ—¥æˆäº¤é‡æ¯”å‰5æ—¥å¹³å‡æ”¾å¤§50%"))
    MAX_20D_RETURN = float(st.number_input("æœ€å¤§20æ—¥æ¶¨å¹…é™åˆ¶ (%)", value=60.0, step=5.0))
    
    st.markdown("---")
    # ç­–ç•¥è¯„åˆ†å‚æ•°
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1500, step=100))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    
    st.markdown("---")
    # --- å†å²å›æµ‹å‚æ•° ---
    st.header("å†å²å›æµ‹å‚æ•°")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹äº¤æ˜“æ—¥å¤©æ•°", value=60, min_value=10, max_value=250))
    BACKTEST_TOP_K = int(st.number_input("å›æµ‹æ¯æ—¥æœ€å¤šäº¤æ˜“ K æ”¯", value=3, min_value=1, max_value=10))
    HOLD_DAYS_OPTIONS = st.multiselect("å›æµ‹æŒè‚¡å¤©æ•°", options=[1, 3, 5, 10, 20], default=[1, 3, 5])
    # ç¼“å­˜ç ´åé”®
    CACHE_BREAKER = float(st.number_input("å›æµ‹ï¼šç¼“å­˜ç ´åé”®ï¼ˆä»»æ„ä¿®æ”¹åˆ·æ–°å›æµ‹ï¼‰", value=1.0, step=0.1))
    st.caption("æç¤ºï¼š**æœ¬æ¬¡å›æµ‹å¼ºåˆ¶ä½¿ç”¨å³ä¾§å¯åŠ¨ç­–ç•¥ã€‚**")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰ä¸åˆå§‹åŒ–
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# ç¼“å­˜è¾…åŠ©å‡½æ•°
# ---------------------------
def safe_get(func, **kwargs):
    """å®‰å…¨è°ƒç”¨ APIï¼Œè‹¥å¤±è´¥åˆ™è¿”å›ç©º DataFrameã€‚"""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†å¹¶ç¼“å­˜"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        return df[df.is_open == 1]['cal_date'].tolist()
    except Exception:
        return []

@st.cache_data(ttl=36000)
def find_last_trade_day(max_days=20):
    """å¯»æ‰¾æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥"""
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# ---------------------------
# æ ¸å¿ƒæŒ‡æ ‡è®¡ç®—å‡½æ•°
# ---------------------------
@st.cache_data(ttl=36000)
def get_hist_cached(ts_code, end_date, days=120): # å¢åŠ å†å²å¤©æ•°ä»¥è®¡ç®—æ›´å¤šæŒ‡æ ‡
    """è·å–å•åªè‚¡ç¥¨å†å²æ•°æ®å¹¶ç¼“å­˜"""
    try:
        start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days * 2)).strftime("%Y%m%d")
        df = safe_get(pro.daily, ts_code=ts_code, start_date=start, end_date=end_date)
        if df is None or df.empty:
            return pd.DataFrame()
        df = df.sort_values('trade_date').reset_index(drop=True)
        return df.tail(days).reset_index(drop=True) # ä»…ä¿ç•™æ‰€éœ€å¤©æ•°
    except:
        return pd.DataFrame()

def compute_indicators(df):
    """è®¡ç®— MA, MACD, é‡æ¯”, 20æ—¥æ”¶ç›Š/é«˜ç‚¹ç­‰å…³é”®æŒ‡æ ‡"""
    res = {}
    if df.empty or len(df) < 20:
        return res
    
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    pct = df['pct_chg'].astype(float)
    
    # MA
    for n in (5, 10, 20):
        res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        
    # MACD (12,26,9)
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    diff = ema12 - ema26
    dea = diff.ewm(span=9, adjust=False).mean()
    res['macd_diff'] = diff.iloc[-1]
    res['macd_dea'] = dea.iloc[-1]
    res['macd_golden'] = res['macd_diff'] > res['macd_dea']
    
    # Vol Ratio (é‡æ¯”)
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
    else:
        res['vol_ratio'] = np.nan
        
    # 20d Return (çŸ­æœŸæ¶¨å¹…é™åˆ¶)
    if len(close) >= 20:
        res['20d_return'] = (close.iloc[-1] / close.iloc[-20] - 1) * 100
        res['recent20_high'] = float(high.iloc[-20:].max())
        res['break_20d_high'] = close.iloc[-1] > res['recent20_high']
    else:
        res['20d_return'] = np.nan
        res['recent20_high'] = np.nan
        res['break_20d_high'] = False
        
    # Prev3 Sum for Rebound Filter (æ’é™¤åå¼¹è‚¡)
    if len(pct) >= 4:
        res['prev3_sum'] = pct.iloc[-4:-1].sum()
    else:
        res['prev3_sum'] = np.nan
        
    # Last Close
    res['last_close'] = close.iloc[-1]
        
    return res

# ---------------------------
# é€‰è‚¡é€»è¾‘
# ---------------------------
if st.button("ğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡ï¼ˆåˆæ¬¡è¿è¡Œå¯èƒ½è¾ƒä¹…ï¼‰"):
    # 1. æ‹‰å–å½“æ—¥æ¶¨å¹…æ¦œåˆç­›
    st.write("æ­£åœ¨æ‹‰å–å½“æ—¥ dailyï¼ˆæ¶¨å¹…æ¦œï¼‰ä½œä¸ºåˆç­›...")
    daily_all = safe_get(pro.daily, trade_date=last_trade)
    if daily_all.empty:
        st.error("æ— æ³•è·å–å½“æ—¥ daily æ•°æ®ã€‚")
        st.stop()
        
    daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
    pool0 = daily_all.head(INITIAL_TOP_N).copy()
    
    # 2. æ‹‰å–é«˜çº§æ¥å£æ•°æ®
    st.write("å°è¯•åŠ è½½ stock_basic / daily_basic / moneyflow ç­‰é«˜çº§æ¥å£...")
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,total_mv,circ_mv')
    daily_basic = safe_get(pro.daily_basic, trade_date=last_trade, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    mf_raw = safe_get(pro.moneyflow, trade_date=last_trade)
    
    # Moneyflow é¢„å¤„ç†ï¼ˆç®€åŒ–å¤„ç†ï¼‰
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out']
        col = next((c for c in possible if c in mf_raw.columns), None)
        if col:
            moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
    
    # 3. æ•°æ®åˆå¹¶
    pool_merged = pool0.copy()
    if not stock_basic.empty:
        pool_merged = pool_merged.merge(stock_basic[['ts_code','name','industry','total_mv','circ_mv']], 
                                        on='ts_code', how='left')
    if not daily_basic.empty:
        pool_merged = pool_merged.merge(daily_basic[['ts_code','turnover_rate','amount','total_mv','circ_mv']], 
                                        on='ts_code', how='left', suffixes=('_daily','_basic'))
    if not moneyflow.empty:
        pool_merged = pool_merged.merge(moneyflow, on='ts_code', how='left').fillna({'net_mf': 0.0})
        
    # ä½¿ç”¨ daily çš„ amount (åƒå…ƒ) å’Œ daily_basic çš„ turnover_rate (%)
    pool_merged['amount_yuan'] = pool_merged['amount_daily'].fillna(0) * 1000.0
    
    # 4. ç¡¬æ€§è¿‡æ»¤ï¼ˆæ¸…æ´—é˜¶æ®µï¼‰
    st.write("æ­£åœ¨å¯¹åˆç­›æ± è¿›è¡Œç¡¬æ€§è¿‡æ»¤ï¼ˆä»·æ ¼/å¸‚å€¼/ST/åŒ—äº¤æ‰€/æ¢æ‰‹/æˆäº¤é¢ï¼‰...")
    clean_df = pool_merged.copy()
    
    # F1: ä»·æ ¼åŒºé—´
    clean_df = clean_df[(clean_df['close'] >= MIN_PRICE) & (clean_df['close'] <= MAX_PRICE)]
    
    # F2: å¸‚å€¼åŒºé—´ (å…¼å®¹ä¸‡å…ƒ/å…ƒå•ä½ï¼Œè¿™é‡Œç»Ÿä¸€æŒ‰ Tushare æ¥å£è¿”å›çš„å•ä½ï¼Œé€šå¸¸æ˜¯ä¸‡å…ƒ)
    # Tushare çš„ total_mv/circ_mv é»˜è®¤å•ä½æ˜¯ä¸‡å…ƒ
    # å°† MIN_MARKET_CAP å’Œ MAX_MARKET_CAP è½¬æ¢ä¸ºä¸‡å…ƒ
    MIN_CAP_WAN = MIN_MARKET_CAP / 10000.0
    MAX_CAP_WAN = MAX_MARKET_CAP / 10000.0
    clean_df = clean_df[(clean_df['total_mv_basic'] >= MIN_CAP_WAN) & (clean_df['total_mv_basic'] <= MAX_CAP_WAN)]
    
    # F3: ST / åŒ—äº¤æ‰€ / åœç‰Œ / æ— æˆäº¤
    clean_df = clean_df[~clean_df['name'].str.contains('ST|é€€', na=False)]
    clean_df = clean_df[~clean_df['ts_code'].str.startswith('4', na=False)]
    clean_df = clean_df[~clean_df['ts_code'].str.startswith('8', na=False)]
    clean_df = clean_df[(clean_df['vol'] > 0) & (clean_df['amount_yuan'] > 0)]
    
    # F4: æœ€ä½æ¢æ‰‹ç‡ (é¿å…æµåŠ¨æ€§å·®çš„)
    clean_df = clean_df[clean_df['turnover_rate'] >= MIN_TURNOVER]
    
    st.write(f"ç¡¬æ€§è¿‡æ»¤åå€™é€‰æ•°é‡ï¼š{len(clean_df)} æ”¯ã€‚")
    if len(clean_df) == 0:
        st.error("ç¡¬æ€§è¿‡æ»¤åæ²¡æœ‰å€™é€‰ï¼Œè¯·æ”¾å®½ä¾§è¾¹æ æ¡ä»¶ã€‚")
        st.stop()
        
    # 5. é€ä¸ªè®¡ç®—æŒ‡æ ‡ä¸æ ¸å¿ƒè¿‡æ»¤ï¼ˆè€—æ—¶æ­¥éª¤ï¼‰
    st.write("ä¸ºå€™é€‰è‚¡é€ç¥¨è®¡ç®—æŒ‡æ ‡ï¼ˆMA/MACD/çªç ´/20æ—¥æ¶¨å¹…ç­‰ï¼‰...")
    records = []
    pbar = st.progress(0)
    
    for idx, row in clean_df.iterrows():
        ts_code = row['ts_code']
        name = row['name']
        
        hist = get_hist_cached(ts_code, last_trade, days=60) # 60æ—¥å†å²æ•°æ®è¶³å¤Ÿ
        ind = compute_indicators(hist)
        
        # --- è¶‹åŠ¿ä¸é£é™©ç¡¬è¿‡æ»¤ ---
        
        # F5: 20æ—¥æ¶¨å¹…é™åˆ¶ (ä¸è¶…è¿‡ 60%)
        d20_ret = ind.get('20d_return', 0)
        if d20_ret > MAX_20D_RETURN:
            pbar.progress((idx+1)/len(clean_df))
            continue
            
        # F6: MA å¤šå¤´ç¡¬è¿‡æ»¤ (è¶‹åŠ¿ç¡®è®¤)
        ma5, ma10, ma20 = ind.get('ma5'), ind.get('ma10'), ind.get('ma20')
        if not (ma5 > ma10 and ma10 > ma20):
            pbar.progress((idx+1)/len(clean_df))
            continue
            
        # F7: æ’é™¤ä¸‹è·Œé€”ä¸­åæŠ½è‚¡ (é¿å…åå¼¹è‚¡)
        # æ’é™¤ è¿‡å»3å¤©ç´¯è®¡è·Œå¹…è¾ƒå¤§ (ä¾‹å¦‚ < -5) ä¸” ä»Šæ—¥æ¶¨å¹…ä¹Ÿä¸å° (> 4)
        prev3_sum = ind.get('prev3_sum', 0)
        if prev3_sum < -5.0 and row['pct_chg'] > 4.0:
            pbar.progress((idx+1)/len(clean_df))
            continue

        # --- åˆå¹¶æŒ‡æ ‡ï¼Œå‡†å¤‡è¯„åˆ† ---
        row_dict = row.to_dict()
        row_dict.update(ind)
        records.append(row_dict)
        pbar.progress((idx+1)/len(clean_df))
    
    pbar.progress(1.0)
    fdf = pd.DataFrame(records)
    st.write(f"ç­–ç•¥ç¡¬è¿‡æ»¤åï¼Œè¿›å…¥è¯„åˆ†é˜¶æ®µçš„å€™é€‰æ•°é‡ï¼š{len(fdf)} æ”¯ã€‚")
    if fdf.empty:
        st.error("æ‰€æœ‰è‚¡ç¥¨éƒ½è¢«è¿‡æ»¤ï¼Œè¯·æ”¾å®½è¿‡æ»¤æ¡ä»¶ã€‚")
        st.stop()

    # 6. å½’ä¸€åŒ–ä¸è¯„åˆ†
    
    def norm_col(s):
        s = s.fillna(s.median()).replace([np.inf,-np.inf], np.nan).fillna(s.median())
        mn = s.min(); mx = s.max()
        if mx - mn < 1e-9:
            return pd.Series([0.5]*len(s), index=s.index)
        return (s - mn) / (mx - mn)

    # å½’ä¸€åŒ–å­æŒ‡æ ‡ (å½’ä¸€åŒ–åçš„æŒ‡æ ‡ä»¥ 's_' å¼€å¤´)
    fdf['s_pct'] = norm_col(fdf['pct_chg'])
    fdf['s_volratio'] = norm_col(fdf['vol_ratio'])
    fdf['s_turn'] = norm_col(fdf['turnover_rate'])
    fdf['s_net_mf'] = norm_col(fdf['net_mf'])
    fdf['s_macd_diff'] = norm_col(fdf['macd_diff'])
    
    # ç­–ç•¥å› å­ (å¸ƒå°”è½¬ float)
    fdf['f_break_20d'] = (fdf['break_20d_high']).astype(float) # çªç ´20æ—¥é«˜ç‚¹
    fdf['f_macd_golden'] = (fdf['macd_golden']).astype(float) # MACDé‡‘å‰
    fdf['f_vol_price_up'] = ((fdf['vol_ratio'] >= VOL_RATIO_THRESHOLD) & (fdf['pct_chg'] > 0)).astype(float) # é‡ä»·é½å‡
    
    # æœ€ç»ˆç»¼åˆè¯„åˆ†ï¼ˆæƒé‡åˆ†é… - é‡ç‚¹å¢å¼ºå³ä¾§è¶‹åŠ¿ä¿¡å·ï¼‰
    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['f_break_20d'] * 0.25 +       # çªç ´å› å­ï¼šæœ€é«˜æƒé‡
        fdf['f_macd_golden'] * 0.20 +     # MACDåŠ¨èƒ½ï¼šé«˜æƒé‡
        fdf['f_vol_price_up'] * 0.15 +    # é‡ä»·é½å‡ï¼šé«˜æƒé‡
        fdf['s_pct'] * 0.10 +             # å½“æ—¥å¼ºåŠ¿
        fdf['s_volratio'] * 0.10 +        # è¡¥å……é‡æ¯”å¼ºåº¦
        fdf['s_turn'] * 0.10 +            # æµåŠ¨æ€§/æ¢æ‰‹ç‡
        fdf['s_net_mf'] * 0.10             # èµ„é‡‘æµå‘
    )

    # 7. æ’åºä¸å±•ç¤º
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index = fdf.index + 1
    
    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(TOP_DISPLAY, len(fdf))}ã€‚")
    display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','turnover_rate','vol_ratio','net_mf','f_break_20d','f_macd_golden','f_vol_price_up','20d_return','ma5','ma10','ma20']
    
    # ç­›é€‰åªåŒ…å«åœ¨fdfä¸­çš„åˆ—
    final_cols = [c for c in display_cols if c in fdf.columns]
    
    st.dataframe(fdf[final_cols].head(TOP_DISPLAY), use_container_width=True)

# ---------------------------
# å†å²å›æµ‹éƒ¨åˆ†
# ---------------------------
@st.cache_data(ttl=3600)
def load_backtest_data(all_trade_dates):
    """é¢„åŠ è½½æ‰€æœ‰å›æµ‹æ—¥æœŸçš„ daily æ•°æ®ã€‚"""
    data_cache = {}
    st.write(f"æ­£åœ¨é¢„åŠ è½½å›æµ‹æ‰€éœ€ {len(all_trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„ daily æ•°æ®...")
    pbar = st.progress(0)
    for i, date in enumerate(all_trade_dates):
        daily_df = safe_get(pro.daily, trade_date=date)
        if not daily_df.empty:
            data_cache[date] = daily_df.set_index('ts_code')
        pbar.progress((i + 1) / len(all_trade_dates))
    pbar.progress(1.0)
    return data_cache

@st.cache_data(ttl=6000)
def run_backtest_right_side(start_date, end_date, hold_days, backtest_top_k, cache_breaker, 
                            min_price, max_price, min_cap, max_cap, min_turnover, vol_ratio_threshold, max_20d_ret):
    
    # ç¡®ä¿ç¼“å­˜ç ´åé”®è¢«ä½¿ç”¨
    _ = cache_breaker 

    trade_dates = get_trade_cal(start_date, end_date)
    
    if not trade_dates:
        return {h: {'returns': [], 'wins': 0, 'total': 0} for h in hold_days}

    results = {h: {'returns': [], 'wins': 0, 'total': 0} for h in hold_days}
    
    # ç¡®å®šå›æµ‹çš„äº¤æ˜“æ—¥
    bt_start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=BACKTEST_DAYS * 2)).strftime("%Y%m%d")
    buy_dates_pool = [d for d in trade_dates if d >= bt_start and d <= end_date]
    backtest_dates = buy_dates_pool[-BACKTEST_DAYS:]
    
    # ç¡®å®šå›æµ‹æ‰€éœ€çš„å…¨éƒ¨äº¤æ˜“æ—¥ï¼Œå¹¶é¢„åŠ è½½æ•°æ®
    required_dates = set(backtest_dates)
    for buy_date in backtest_dates:
        try:
            current_index = trade_dates.index(buy_date)
            for h in hold_days:
                required_dates.add(trade_dates[current_index + h])
        except (ValueError, IndexError):
            continue
            
    data_cache = load_backtest_data(sorted(list(required_dates)))

    # é¢„åŠ è½½ daily_basic, moneyflow ç­‰ç”¨äºå›æµ‹ç¡¬è¿‡æ»¤
    st.write("æ­£åœ¨é¢„åŠ è½½å›æµ‹æ‰€éœ€çš„ daily_basic/moneyflow æ•°æ®...")
    daily_basic_cache = {}
    moneyflow_cache = {}
    for date in required_dates:
        daily_basic_cache[date] = safe_get(pro.daily_basic, trade_date=date).set_index('ts_code')
        mf_raw = safe_get(pro.moneyflow, trade_date=date)
        if not mf_raw.empty:
            col = next((c for c in ['net_mf','net_mf_amount'] if c in mf_raw.columns), None)
            if col:
                 moneyflow_cache[date] = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).set_index('ts_code')

    
    st.write(f"æ­£åœ¨æ¨¡æ‹Ÿ {len(backtest_dates)} ä¸ªäº¤æ˜“æ—¥çš„å³ä¾§å¯åŠ¨é€‰è‚¡å›æµ‹...")
    pbar_bt = st.progress(0)
    
    for i, buy_date in enumerate(backtest_dates):
        daily_df = data_cache.get(buy_date)
        daily_basic_df = daily_basic_cache.get(buy_date)
        
        if daily_df is None or daily_df.empty or daily_basic_df is None or daily_basic_df.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue

        # åˆå¹¶æ¯æ—¥åŸºç¡€æ•°æ®
        merged_df = daily_df.join(daily_basic_df, how='inner', lsuffix='_daily', rsuffix='_basic').reset_index()
        
        # 1. åº”ç”¨ç¡¬è¿‡æ»¤ (æ³¨æ„å•ä½è½¬æ¢)
        MIN_CAP_WAN = min_cap / 10000.0
        MAX_CAP_WAN = max_cap / 10000.0
        
        filtered_df = merged_df.copy()
        
        # F1: ä»·æ ¼åŒºé—´
        filtered_df = filtered_df[(filtered_df['close_daily'] >= min_price) & (filtered_df['close_daily'] <= max_price)]
        
        # F2: å¸‚å€¼åŒºé—´ (Tushare å•ä½ä¸‡å…ƒ)
        filtered_df = filtered_df[(filtered_df['total_mv_basic'] >= MIN_CAP_WAN) & (filtered_df['total_mv_basic'] <= MAX_CAP_WAN)]
        
        # F3: æœ€ä½æ¢æ‰‹ç‡ (é¿å…æµåŠ¨æ€§å·®çš„)
        filtered_df = filtered_df[filtered_df['turnover_rate_basic'] >= min_turnover]
        
        # F4: åœç‰Œ / æ— æˆäº¤
        filtered_df = filtered_df[(filtered_df['vol_daily'] > 0)]
        
        # 2. æ¨¡æ‹Ÿç­–ç•¥è¯„åˆ†ï¼ˆç®€åŒ–ç‰ˆï¼šæŒ‰ MACD é‡‘å‰ + é‡æ¯” + æ¶¨å¹…ç»¼åˆæ’åºï¼‰
        # æ­¤å¤„æ— æ³•åœ¨å›æµ‹ä¸­é€æ—¥è®¡ç®— MACD/20æ—¥çªç ´ï¼Œç®€åŒ–ä¸ºæŒ‰å½“æ—¥å¼ºåŠ¿æŒ‡æ ‡æ’åº
        
        # ç®€åŒ–ç‰ˆè¯„åˆ†é€»è¾‘: æ¶¨å¹… * é‡æ¯” * æ¢æ‰‹ç‡
        filtered_df['score_proxy'] = filtered_df['pct_chg_daily'] * filtered_df['turnover_rate_basic']
        
        # å¼ºåˆ¶è¿‡æ»¤å½“æ—¥æ¶¨å¹…å°äº 1% çš„ (é¿å…å¤ªå¤šå‡çªç ´è¢«é€‰å…¥ï¼Œæé«˜å¯åŠ¨è´¨é‡)
        filtered_df = filtered_df[filtered_df['pct_chg_daily'] >= 1.0].copy() 
        
        scored_stocks = filtered_df.sort_values("score_proxy", ascending=False).head(backtest_top_k).copy()
        
        for _, row in scored_stocks.iterrows():
            ts_code = row['ts_code']
            buy_price = float(row['close_daily'])
            
            if pd.isna(buy_price) or buy_price <= 0: continue

            for h in hold_days:
                try:
                    current_index = trade_dates.index(buy_date)
                    sell_date = trade_dates[current_index + h]
                except (ValueError, IndexError):
                    continue
        
                # ä»ç¼“å­˜ä¸­æŸ¥æ‰¾å–å‡ºä»·æ ¼ (O(1) æŸ¥æ‰¾)
                sell_df_cached = data_cache.get(sell_date)
                sell_price = np.nan
                if sell_df_cached is not None and ts_code in sell_df_cached.index:
                    sell_price = sell_df_cached.loc[ts_code, 'close']
                
                if pd.isna(sell_price) or sell_price <= 0: continue
                
                ret = (sell_price / buy_price) - 1.0
                results[h]['total'] += 1
                results[h]['returns'].append(ret)
                if ret > 0:
                    results[h]['wins'] += 1

        pbar_bt.progress((i+1)/len(backtest_dates))

    pbar_bt.progress(1.0)
    
    final_results = {}
    for h, res in results.items():
        total = res['total']
        if total > 0:
            avg_return = np.mean(res['returns']) * 100.0
            win_rate = (res['wins'] / total) * 100.0
        else:
            avg_return = 0.0
            win_rate = 0.0
             
        final_results[h] = {
            'å¹³å‡æ”¶ç›Šç‡ (%)': f"{avg_return:.2f}",
            'èƒœç‡ (%)': f"{win_rate:.2f}",
            'æ€»äº¤æ˜“æ¬¡æ•°': total
        }
        
    return final_results

# ---------------------------
# å›æµ‹æ‰§è¡Œ (æ–°æŒ‰é’®)
# ---------------------------
if st.checkbox("âœ… è¿è¡Œå†å²å›æµ‹ï¼ˆå³ä¾§å¯åŠ¨ç­–ç•¥ï¼‰", value=False):
    if not HOLD_DAYS_OPTIONS:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå›æµ‹æŒè‚¡å¤©æ•°ã€‚")
    else:
        st.header("ğŸ“ˆ å†å²å›æµ‹ç»“æœï¼ˆä¹°å…¥æ”¶ç›˜ä»· / å–å‡ºæ”¶ç›˜ä»·ï¼‰")
        
        # ç¡®å®šå›æµ‹çš„èµ·å§‹æ—¥æœŸ
        try:
            start_date_for_cal = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
        except:
            start_date_for_cal = (datetime.now() - timedelta(days=200)).strftime("%Y%m%d")
            
        backtest_result = run_backtest_right_side(
            start_date=start_date_for_cal,
            end_date=last_trade,
            hold_days=HOLD_DAYS_OPTIONS,
            backtest_top_k=BACKTEST_TOP_K,
            cache_breaker=CACHE_BREAKER, # ç¼“å­˜ç ´åé”®
            min_price=MIN_PRICE, 
            max_price=MAX_PRICE,
            min_cap=MIN_MARKET_CAP,
            max_cap=MAX_MARKET_CAP,
            min_turnover=MIN_TURNOVER,
            vol_ratio_threshold=VOL_RATIO_THRESHOLD,
            max_20d_ret=MAX_20D_RETURN
        )

        bt_df = pd.DataFrame(backtest_result).T
        bt_df.index.name = "æŒè‚¡å¤©æ•°"
        bt_df = bt_df.reset_index()
        bt_df['æŒè‚¡å¤©æ•°'] = bt_df['æŒè‚¡å¤©æ•°'].astype(str) + ' å¤©'
        
        st.dataframe(bt_df, use_container_width=True, hide_index=True)
        st.success("å›æµ‹å®Œæˆï¼")
        
# ---------------------------
# å°ç»“ä¸æ“ä½œæç¤º
# ---------------------------
st.markdown("### å°ç»“ä¸æ“ä½œæç¤º")
st.markdown("""
- **ç­–ç•¥ï¼š** **å³ä¾§å¯åŠ¨/å¼ºåŠ¿è‚¡ v1.0**ã€‚
- **æ ¸å¿ƒé€»è¾‘ï¼š** é€šè¿‡ **MA å¤šå¤´** å’Œ **20 æ—¥çªç ´** ç¡®è®¤å³ä¾§è¶‹åŠ¿ï¼Œå¹¶é€šè¿‡ **MACD é‡‘å‰** å’Œ **é‡ä»·é½å‡** å¢å¼ºåŠ¨èƒ½ã€‚
- **æ“ä½œæ­¥éª¤ï¼š**
    1. **ç²˜è´´å¹¶è¿è¡Œä»£ç ã€‚**
    2. åœ¨ä¾§è¾¹æ è°ƒæ•´å‚æ•°ï¼Œå°¤å…¶æ˜¯ **æœ€ä½æ¢æ‰‹ç‡** å’Œ **æœ€ä½é‡æ¯”é˜ˆå€¼**ã€‚
    3. ç‚¹å‡» **â€œğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡â€** æŸ¥çœ‹ç»“æœã€‚
    4. å‹¾é€‰ **â€œâœ… è¿è¡Œå†å²å›æµ‹â€** éªŒè¯ç­–ç•¥è¡¨ç°ã€‚
""")
