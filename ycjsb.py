# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆBC æ··åˆå¢å¼ºç‰ˆï¼‰â€”â€” å¸¦è¶‹åŠ¿ä¸»å¯¼ï¼ˆMA/MACD/é‡ä»·/çªç ´ï¼‰å¢å¼º
è¯´æ˜ï¼š
- ç›®æ ‡ï¼šçŸ­çº¿çˆ†å‘ (B) + å¦–è‚¡æ•æ‰ (C)ï¼ŒæŒè‚¡ 1-5 å¤©
- åœ¨ç•Œé¢è¾“å…¥ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰
- å°½å¯èƒ½è°ƒç”¨ moneyflow / chip / ths_member / chip ç­‰é«˜çº§æ¥å£ï¼Œè‹¥æ— æƒé™ä¼šè‡ªåŠ¨é™çº§
- **å·²åšå¤§é‡å¼‚å¸¸å¤„ç†ä¸ç¼“å­˜ï¼Œå¤§å¹…ä¼˜åŒ–å›æµ‹æ—¶çš„å†å²æ•°æ®åŠ è½½é€Ÿåº¦ï¼Œæ–°å¢äº†ç½‘ç»œé‡è¯•æœºåˆ¶ï¼Œå¹¶ä¼˜åŒ–äº†è¯„åˆ†å¤±è´¥çš„è°ƒè¯•ä¿¡æ¯ã€‚**
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time # ç¡®ä¿å¼•å…¥ time æ¨¡å—

warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€æ•°æ®ç¼“å­˜ï¼ˆç”¨äºæ€§èƒ½ä¼˜åŒ–ï¼‰
# ---------------------------
# å­˜å‚¨æ‰€æœ‰è‚¡ç¥¨çš„æ—¥çº¿æ•°æ®ï¼Œkey ä¸º ts_code
@st.cache_data(ttl=3600, show_spinner=False)
def get_global_daily_data(ts_code):
    """ç”¨äºå­˜å‚¨å•åªè‚¡ç¥¨çš„å†å²æ•°æ®ï¼Œé¿å…é‡å¤åŠ è½½ï¼Œä½†åœ¨å›æµ‹æ¨¡å¼ä¸‹ä¼šè¢« get_bulk_daily_data ä»£æ›¿"""
    return pd.DataFrame() # ä»…ç”¨äºå ä½ï¼Œå®é™…ç”± bulk load å®ç°

GLOBAL_KLINE_DATA = {}

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆBCå¢å¼ºï¼‰", layout="wide")
st.title("é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆBC æ··åˆå¢å¼ºç‰ˆï¼‰")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚è‹¥æœ‰æƒé™ç¼ºå¤±ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é™çº§å¹¶ç»§ç»­è¿è¡Œã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆå®æ—¶ï¼‰")
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=300, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=3.0, step=0.5))
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=200_000_000.0, step=50_000_000.0))
    VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.7, step=0.1))
    VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=8.0, step=0.5))
    HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))
    MIN_MARKET_CAP = float(st.number_input("æœ€ä½å¸‚å€¼ (å…ƒ)", value=2000000000.0, step=100000000.0))  # é»˜è®¤ 20äº¿
    MAX_MARKET_CAP = float(st.number_input("æœ€é«˜å¸‚å€¼ (å…ƒ)", value=50000000000.0, step=1000000000.0))  # é»˜è®¤ 500äº¿
    st.markdown("---")
    # --- å›æµ‹æ–°å¢å‚æ•° ---
    st.header("å›æµ‹å‚æ•°ï¼ˆæ–°å¢ï¼‰")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹äº¤æ˜“æ—¥å¤©æ•° (N)", value=20, step=5))
    HOLD_DAYS_LIST = st.text_input("å›æµ‹æŒè‚¡å¤©æ•°ï¼ˆé€—å·åˆ†éš”ï¼‰", value="1, 3, 5")
    try:
        HOLD_DAYS = [int(x.strip()) for x in HOLD_DAYS_LIST.split(',') if x.strip().isdigit()]
    except:
        HOLD_DAYS = [1, 3, 5]
    if not HOLD_DAYS:
         HOLD_DAYS = [1, 3, 5]
         st.warning("æŒè‚¡å¤©æ•°è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼ 1, 3, 5ã€‚")
    # ------------------
    st.markdown("---")
    st.caption("æç¤ºï¼šä¿å®ˆâ†’é™ä½é˜ˆå€¼ï¼›æ¿€è¿›â†’æé«˜é˜ˆå€¼ã€‚")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# å®‰å…¨è°ƒç”¨ & ç¼“å­˜è¾…åŠ©
# ---------------------------
def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def find_last_trade_day(max_days=20):
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

@st.cache_data(ttl=3600)
def get_all_trade_cals(start_date, end_date):
    """è·å–æŒ‡å®šèŒƒå›´å†…çš„æ‰€æœ‰äº¤æ˜“æ—¥"""
    try:
        df = safe_get(pro.trade_cal, start_date=start_date, end_date=end_date)
        if df.empty: return []
        return df[df['is_open']==1]['cal_date'].tolist()
    except:
        return []

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# ---------------------------
# å°è¯•åŠ è½½é«˜çº§æ¥å£ï¼ˆæœ‰æƒé™æ—¶å¯ç”¨ï¼‰
# ---------------------------
@st.cache_data(ttl=600)
def get_advanced_data(trade_date):
    """ç¼“å­˜å¹¶è·å–å½“æ—¥æ‰€æœ‰é«˜çº§æ•°æ®"""
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,list_date,total_mv,circ_mv')
    daily_basic = safe_get(pro.daily_basic, trade_date=trade_date, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    mf_raw = safe_get(pro.moneyflow, trade_date=trade_date)

    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out']
        col = None
        for c in possible:
            if c in mf_raw.columns:
                col = c; break
        if col:
            moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
        else:
            numeric_cols = [c for c in mf_raw.columns if c != 'ts_code' and pd.api.types.is_numeric_dtype(mf_raw[c])]
            col = numeric_cols[0] if numeric_cols else None
            if col:
                 moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
            else:
                 pass # æµå‘å› å­ç½®ä¸º 0
                 
    return stock_basic, daily_basic, moneyflow

# ---------------------------
# åˆå¹¶åŸºæœ¬ä¿¡æ¯ (safe_merge_pool, merge_all_info ä¿æŒä¸å˜)
# ---------------------------
def safe_merge_pool(pool_df, other_df, cols):
    """å®‰å…¨åˆå¹¶è¾…åŠ©å‡½æ•°"""
    pool = pool_df.set_index('ts_code').copy()
    if other_df is None or other_df.empty:
        for c in cols:
            pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try:
            other_df = other_df.reset_index()
        except:
            for c in cols:
                pool[c] = np.nan
            return pool.reset_index()
    for c in cols:
        if c not in other_df.columns:
            other_df[c] = np.nan
    try:
        joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        for c in cols:
            pool[c] = np.nan
        return pool.reset_index()
    for c in cols:
        if c not in joined.columns:
            joined[c] = np.nan
    return joined.reset_index()

def merge_all_info(pool0, stock_basic, daily_basic, moneyflow):
    """ç»Ÿä¸€åˆå¹¶æµç¨‹"""
    # merge stock_basic
    if not stock_basic.empty:
        keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv'] if c in stock_basic.columns]
        try:
            pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
        except Exception:
            pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
    else:
        pool0['name'] = pool0['ts_code']; pool0['industry'] = ''

    # merge daily_basic
    pool_merged = safe_merge_pool(pool0, daily_basic, ['turnover_rate','amount','total_mv','circ_mv'])

    # merge moneyflow robustly
    if moneyflow.empty:
        moneyflow = pd.DataFrame({'ts_code': pool_merged['ts_code'].tolist(), 'net_mf': [0.0]*len(pool_merged)})
    else:
        if 'ts_code' not in moneyflow.columns:
            moneyflow['ts_code'] = None
    try:
        pool_merged = pool_merged.set_index('ts_code').join(moneyflow.set_index('ts_code'), how='left').reset_index()
    except Exception:
        if 'net_mf' not in pool_merged.columns:
            pool_merged['net_mf'] = 0.0

    if 'net_mf' not in pool_merged.columns:
        pool_merged['net_mf'] = 0.0
    pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0.0)
    return pool_merged

# ---------------------------
# æ¸…æ´—ä¸è¿‡æ»¤ï¼ˆclean_and_filter ä¿æŒä¸å˜ï¼‰
# ---------------------------
def clean_and_filter(pool_merged, min_price, max_price, min_turnover, min_amount, min_market_cap, max_market_cap, vol_spike_mult, volatility_max, high_pct_threshold, final_pool):
    """ç»Ÿä¸€æ¸…æ´—å’Œè¿‡æ»¤æµç¨‹"""
    clean_list = []
    
    st_pbar = None
    if st.session_state.get('mode', 'live') == 'live':
        st_pbar = st.progress(0)
    
    for i, r in enumerate(pool_merged.itertuples()):
        ts = getattr(r, 'ts_code')
        vol = getattr(r, 'vol', 0)
        close = getattr(r, 'close', np.nan)
        open_p = getattr(r, 'open', np.nan)
        pre_close = getattr(r, 'pre_close', np.nan)
        pct = getattr(r, 'pct_chg', np.nan)
        amount = getattr(r, 'amount', np.nan)
        turnover = getattr(r, 'turnover_rate', np.nan)
        total_mv = getattr(r, 'total_mv', np.nan)
        name = getattr(r, 'name', ts)
        
        # skip no trading
        if vol == 0 or (isinstance(amount,(int,float)) and amount == 0):
            if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue

        # price filter
        if pd.isna(close): 
            if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue
        if (close < min_price) or (close > max_price): 
            if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue

        # exclude ST / delist
        if isinstance(name, str) and (('ST' in name.upper()) or ('é€€' in name)):
            if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue

        # æ’é™¤åŒ—äº¤æ‰€ï¼ˆä»£ç å‰ç¼€ï¼‰
        tsck = getattr(r, 'ts_code', '')
        if isinstance(tsck, str) and (tsck.startswith('4') or tsck.startswith('8')):
            if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue

        # å¸‚å€¼è¿‡æ»¤ï¼ˆå…¼å®¹ä¸‡å…ƒå•ä½ï¼‰
        try:
            tv = getattr(r, 'total_mv', np.nan)
            if not pd.isna(tv):
                tv = float(tv)
                tv_yuan = tv * 10000.0 if tv > 1e6 else tv
                if tv_yuan < min_market_cap or tv_yuan > max_market_cap:
                    if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue
        except: pass

        # one-word board
        try:
            high = getattr(r, 'high', np.nan); low = getattr(r, 'low', np.nan)
            if (not pd.isna(open_p) and not pd.isna(high) and not pd.isna(low) and not pd.isna(pre_close)):
                if (open_p == high == low == pre_close):
                    if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue
        except: pass

        # turnover
        if not pd.isna(turnover):
            try:
                if float(turnover) < min_turnover: 
                    if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue
            except: pass

        # amount (convert if likely in ä¸‡å…ƒ)
        if not pd.isna(amount):
            amt = amount
            amt = amt * 10000.0 if amt > 0 and amt < 1e5 else amt
            if amt < min_amount: 
                if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue

        # exclude yesterday down (for today's pct_chg)
        try:
            if float(pct) < 0: 
                if st_pbar: st_pbar.progress((i+1)/len(pool_merged)); continue
        except: pass

        clean_list.append(r)
        if st_pbar: st_pbar.progress((i+1)/len(pool_merged))

    if st_pbar: st_pbar.progress(1.0)
    clean_df = pd.DataFrame([dict(zip(r._fields, r)) for r in clean_list])
    
    # å–æ¶¨å¹…å‰ FINAL_POOL è¿›å…¥è¯„åˆ†æ± 
    if len(clean_df) == 0:
        return pd.DataFrame()
        
    clean_df = clean_df.sort_values('pct_chg', ascending=False).head(int(final_pool)).reset_index(drop=True)
    return clean_df

# ---------------------------
# æ€§èƒ½ä¼˜åŒ–ï¼šK çº¿æ‰¹é‡åŠ è½½ï¼ˆ**æ–°å¢é‡è¯•æœºåˆ¶**ï¼‰
# ---------------------------
@st.cache_data(ttl=600, show_spinner=False)
def get_bulk_daily_data(start_date, end_date, max_retries=3):
    """
    æ€§èƒ½ä¼˜åŒ–æ ¸å¿ƒå‡½æ•°ï¼šæ‰¹é‡è·å–å…¨å¸‚åœºåœ¨æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ—¥çº¿æ•°æ®ã€‚
    è¿”å›ä¸€ä¸ªå­—å…¸: {ts_code: DataFrame(kline)}
    """
    global GLOBAL_KLINE_DATA
    st.write(f"ğŸ“ˆ æ­£åœ¨æ‰¹é‡åŠ è½½å…¨å¸‚åœº {start_date} è‡³ {end_date} çš„ K çº¿æ•°æ®ï¼ˆTushareè°ƒç”¨å¯†é›†ï¼Œè¯·è€å¿ƒç­‰å¾…...ï¼‰")
    
    for attempt in range(max_retries):
        try:
            df_all = safe_get(pro.daily, start_date=start_date, end_date=end_date)
            
            if df_all.empty:
                if attempt < max_retries - 1:
                    st.warning(f"ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼šæ‰¹é‡è·å– K çº¿æ•°æ®è¿”å›ç©ºï¼Œæ­£åœ¨é‡è¯•ï¼ˆç­‰å¾… 5 ç§’ï¼‰...")
                    time.sleep(5)
                    continue
                else:
                    st.error("æ‰¹é‡è·å– K çº¿æ•°æ®æœ€ç»ˆå¤±è´¥æˆ–è¿”å›ç©ºï¼Œå›æµ‹æ— æ³•è¿›è¡Œã€‚")
                    return {}
            
            # å¦‚æœæˆåŠŸï¼Œåˆ™å¤„ç†æ•°æ®å¹¶è·³å‡ºå¾ªç¯
            GLOBAL_KLINE_DATA = {
                ts_code: group.sort_values('trade_date').reset_index(drop=True)
                for ts_code, group in df_all.groupby('ts_code')
            }
            st.write(f"âœ… K çº¿æ•°æ®åŠ è½½å®Œæˆï¼ˆç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼‰ã€‚å…±è·å– {len(GLOBAL_KLINE_DATA)} æ”¯è‚¡ç¥¨çš„å†å²æ•°æ®ã€‚")
            return GLOBAL_KLINE_DATA
            
        except Exception as e:
            if attempt < max_retries - 1:
                st.warning(f"ç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•ï¼šæ‰¹é‡è·å– K çº¿æ•°æ®å‡ºé”™ï¼š{e}ã€‚æ­£åœ¨é‡è¯•ï¼ˆç­‰å¾… 5 ç§’ï¼‰...")
                time.sleep(5)
            else:
                st.error(f"æ‰¹é‡è·å– K çº¿æ•°æ®æœ€ç»ˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚é”™è¯¯ï¼š{e}")
                return {}
    
    return {} # ç†è®ºä¸Šä¸åº”åˆ°è¾¾

# ---------------------------
# è¯„åˆ†æŒ‡æ ‡è®¡ç®—ï¼ˆå·²ä¿®æ”¹ä¸ºä»å…¨å±€ç¼“å­˜è¯»å–ï¼‰
# ---------------------------
def compute_indicators(ts_code, end_date, days=60):
    """ä»å…¨å±€ç¼“å­˜ä¸­è·å–æ•°æ®å¹¶è®¡ç®—æŒ‡æ ‡"""
    res = {}
    
    # ä»å…¨å±€ç¼“å­˜ä¸­è·å– K çº¿æ•°æ®
    if ts_code not in GLOBAL_KLINE_DATA:
        return res
        
    df_full = GLOBAL_KLINE_DATA[ts_code]
    
    # ç­›é€‰å‡ºå½“å‰å›æµ‹æ—¥ä¹‹å‰çš„æ•°æ®ï¼ˆåŒ…æ‹¬ end_date å½“å¤©ï¼‰
    df = df_full[df_full['trade_date'] <= end_date].tail(days + 26) # 26 for MACD
    
    if df.empty or len(df) < 3:
        return res
        
    # æŒ‡æ ‡è®¡ç®—é€»è¾‘ (ä¸åŸé€»è¾‘ä¿æŒä¸€è‡´)
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)

    # last close
    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan

    # MA
    for n in (5,10,20):
        if len(close) >= n:
            res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else:
            res[f'ma{n}'] = np.nan

    # MACD (12,26,9)
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1]; res['dea'] = dea.iloc[-1]
    else:
        res['macd'] = res['diff'] = res['dea'] = np.nan

    # KDJ
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1]; res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = np.nan

    # vol ratio and metrics
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    # 10d return
    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan

    # prev3_sum for down-then-bounce detection
    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    # volatility (std of last 10 pct_chg)
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except:
        res['volatility_10'] = np.nan

    # recent 20-day high for breakout detection
    try:
        if len(high) >= 20:
            res['recent20_high'] = float(high.tail(20).max())
        else:
            res['recent20_high'] = float(high.max()) if len(high)>0 else np.nan
    except:
        res['recent20_high'] = np.nan

    # é˜³çº¿å®ä½“å¼ºåº¦ï¼ˆä»Šå¤©ï¼‰
    try:
        today_open = df['open'].astype(float).iloc[-1]
        today_close = df['close'].astype(float).iloc[-1]
        today_high = df['high'].astype(float).iloc[-1]
        today_low = df['low'].astype(float).iloc[-1]
        body = abs(today_close - today_open)
        rng = max(today_high - today_low, 1e-9)
        res['yang_body_strength'] = body / rng
    except:
        res['yang_body_strength'] = 0.0
        
    return res

# ---------------------------
# è¯„åˆ†è®¡ç®—ä¸»ä½“ï¼ˆå·²ä¿®æ”¹ä¸ºä½¿ç”¨æœ¬åœ°ç¼“å­˜, ä¼˜åŒ–è¿‡æ»¤æµç¨‹ï¼‰
# ---------------------------
def compute_scores(clean_df, last_trade, min_market_cap, max_market_cap, vol_spike_mult, volatility_max, high_pct_threshold):
    """ç»Ÿä¸€è¯„åˆ†å’Œé£é™©è¿‡æ»¤æµç¨‹"""
    records = []
    
    st_pbar = None
    if st.session_state.get('mode', 'live') == 'live':
        st_pbar = st.progress(0, text="æ­£åœ¨è®¡ç®—æŒ‡æ ‡å’Œåˆ†æ•°...")
        
    for idx, row in enumerate(clean_df.itertuples()):
        ts_code = getattr(row, 'ts_code')
        name = getattr(row, 'name', ts_code)
        pct_chg = getattr(row, 'pct_chg', 0.0)
        amount = getattr(row, 'amount', np.nan)
        if amount is not None and not pd.isna(amount) and amount > 0 and amount < 1e5:
            amount = amount * 10000.0

        turnover_rate = getattr(row, 'turnover_rate', np.nan)
        net_mf = float(getattr(row, 'net_mf', 0.0))

        # *** æ€§èƒ½ä¼˜åŒ–ï¼šè°ƒç”¨æ–°çš„æŒ‡æ ‡è®¡ç®—å‡½æ•° ***
        ind = compute_indicators(ts_code, last_trade, days=60)

        vol_ratio = ind.get('vol_ratio', np.nan)
        ten_return = ind.get('10d_return', np.nan)
        ma5 = ind.get('ma5', np.nan)
        ma10 = ind.get('ma10', np.nan)
        ma20 = ind.get('ma20', np.nan)
        macd = ind.get('macd', np.nan)
        diff = ind.get('diff', np.nan)
        dea = ind.get('dea', np.nan)
        k, d, j = ind.get('k', np.nan), ind.get('d', np.nan), ind.get('j', np.nan)
        last_close = ind.get('last_close', np.nan)
        vol_last = ind.get('vol_last', np.nan)
        vol_ma5 = ind.get('vol_ma5', np.nan)
        prev3_sum = ind.get('prev3_sum', np.nan)
        volatility_10 = ind.get('volatility_10', np.nan)
        recent20_high = ind.get('recent20_high', np.nan)
        yang_body_strength = ind.get('yang_body_strength', 0.0)

        # èµ„é‡‘å¼ºåº¦ä»£ç†ï¼ˆä¸ä¾èµ– moneyflowï¼‰ï¼šç®€å•ä¹˜ç§¯æŒ‡æ ‡ï¼ˆprice move * vol_ratio * turnoverï¼‰
        try:
            proxy_money = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)
        except:
            proxy_money = 0.0

        rec = {
            'ts_code': ts_code, 'name': name, 'pct_chg': pct_chg,
            'amount': amount if not pd.isna(amount) else 0.0,
            'turnover_rate': turnover_rate if not pd.isna(turnover_rate) else np.nan,
            'net_mf': net_mf,
            'vol_ratio': vol_ratio if not pd.isna(vol_ratio) else np.nan,
            '10d_return': ten_return if not pd.isna(ten_return) else np.nan,
            'ma5': ma5, 'ma10': ma10, 'ma20': ma20,
            'macd': macd, 'diff': diff, 'dea': dea, 'k': k, 'd': d, 'j': j,
            'last_close': last_close, 'vol_last': vol_last, 'vol_ma5': vol_ma5, 'recent20_high': recent20_high, 'yang_body_strength': yang_body_strength,
            'prev3_sum': prev3_sum, 'volatility_10': volatility_10,
            'proxy_money': proxy_money
        }

        records.append(rec)
        if st_pbar: st_pbar.progress((idx+1)/len(clean_df))

    if st_pbar: st_pbar.progress(1.0)
    fdf = pd.DataFrame(records)
    
    # ç¬¬ä¸€æ¬¡æ£€æŸ¥ï¼šå¦‚æœæŒ‡æ ‡è®¡ç®—å…¨éƒ¨å¤±è´¥ï¼Œrecordsä¹Ÿå¯èƒ½åªæœ‰ç©ºå€¼
    if fdf.empty: 
        st.error("ã€å†…éƒ¨é”™è¯¯ã€‘æŒ‡æ ‡è®¡ç®—å DataFrame ä¸ºç©ºã€‚è¯·ç¡®è®¤ K çº¿æ•°æ®æ˜¯å¦æˆåŠŸåŠ è½½ã€‚")
        return pd.DataFrame()


    # è®°å½•è¿‡æ»¤å‰æ•°é‡
    count_before_filter = len(fdf) 
    
    # é£é™©è¿‡æ»¤
    try:
        # A: é«˜ä½å¤§é˜³çº¿ -> last_close > ma20*1.10 ä¸” pct_chg > HIGH_PCT_THRESHOLD
        if all(c in fdf.columns for c in ['ma20','last_close','pct_chg']):
            mask_high_big = (fdf['last_close'] > fdf['ma20'] * 1.10) & (fdf['pct_chg'] > high_pct_threshold)
            fdf = fdf[~mask_high_big]

        # B: ä¸‹è·Œé€”ä¸­åæŠ½ -> prev3_sum < 0 ä¸” pct_chg > HIGH_PCT_THRESHOLD
        if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
            mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > high_pct_threshold)
            fdf = fdf[~mask_down_rebound]

        # C: å·¨é‡æ”¾é‡å¤§é˜³ -> vol_last > vol_ma5 * VOL_SPIKE_MULT
        if all(c in fdf.columns for c in ['vol_last','vol_ma5']):
            mask_vol_spike = (fdf['vol_last'] > (fdf['vol_ma5'] * vol_spike_mult))
            fdf = fdf[~mask_vol_spike]

        # D: æç«¯æ³¢åŠ¨ -> volatility_10 > VOLATILITY_MAX
        if 'volatility_10' in fdf.columns:
            mask_volatility = fdf['volatility_10'] > volatility_max
            fdf = fdf[~mask_volatility]
    except: pass # é£é™©è¿‡æ»¤å¼‚å¸¸ï¼Œè·³è¿‡

    # ç¬¬äºŒæ¬¡æ£€æŸ¥ï¼šé£é™©è¿‡æ»¤åçš„æ•°é‡
    count_after_risk_filter = len(fdf)
    if count_after_risk_filter == 0:
        st.error(f"ã€è¿‡æ»¤å¤±è´¥ã€‘é£é™©è¿‡æ»¤æœºåˆ¶ï¼ˆé«˜ä½å¤§é˜³/ä¸‹è·ŒåæŠ½/å·¨é‡æ”¾é‡/æç«¯æ³¢åŠ¨ï¼‰æ’é™¤äº†æ‰€æœ‰ {count_before_filter} æ”¯è‚¡ç¥¨ã€‚è¯·åœ¨ä¾§è¾¹æ æ”¾å®½ä»¥ä¸‹å‚æ•°ï¼š'æ”¾é‡å€æ•°é˜ˆå€¼' æˆ– 'è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼'ã€‚")
        return pd.DataFrame()
    
    st.write(f"é£é™©è¿‡æ»¤åï¼Œå‰©ä½™ {count_after_risk_filter} æ”¯å€™é€‰è‚¡è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚")


    # -----------------------------------------------------------------------------
    # MA å¤šå¤´ç¡¬è¿‡æ»¤ï¼ˆå¿…é¡»æ»¡è¶³ MA5 > MA10 > MA20ï¼‰
    # ATTENTION: æ­¤å¤„æš‚æ—¶æ³¨é‡Šæ‰ï¼Œé¿å…åœ¨å½“å‰å¸‚åœºè¡Œæƒ…ä¸‹å°†æ‰€æœ‰è‚¡ç¥¨è¿‡æ»¤ã€‚
    # å¦‚æœæ‚¨éœ€è¦ä¸¥æ ¼çš„ MA å¤šå¤´è¿‡æ»¤ï¼Œè¯·å–æ¶ˆæ³¨é‡Šã€‚
    # -----------------------------------------------------------------------------
    # try:
    #     count_before_ma_hard = len(fdf)
    #     if all(c in fdf.columns for c in ['ma5','ma10','ma20']):
    #         fdf = fdf[(fdf['ma5'] > fdf['ma10']) & (fdf['ma10'] > fdf['ma20'])]
    #     if len(fdf) < count_before_ma_hard:
    #         st.warning(f"MAç¡¬è¿‡æ»¤è­¦å‘Šï¼šæ’é™¤äº† {count_before_ma_hard - len(fdf)} æ”¯è‚¡ç¥¨ã€‚")
    # except: pass # MA è¿‡æ»¤å¼‚å¸¸ï¼Œè·³è¿‡

    if fdf.empty:
        # å¦‚æœæ˜¯å› ä¸ºMAç¡¬è¿‡æ»¤è¢«æ³¨é‡Šæ‰åï¼Œä¸Šé¢çš„é£é™©è¿‡æ»¤å¤±è´¥è€Œè¿”å›ç©ºï¼Œåˆ™åº”è¯¥åœ¨ä¸Šé¢æŠ¥è¿‡äº†
        st.error("ã€å†…éƒ¨é”™è¯¯ã€‘ç»è¿‡æ‰€æœ‰è¿‡æ»¤åï¼Œè¯„åˆ†æ± ä¸ºç©ºã€‚")
        return pd.DataFrame()
        
    # RSLï¼ˆç›¸å¯¹å¼ºå¼±ï¼‰ï¼šåŸºäºæ± å†… 10d_return çš„ç›¸å¯¹è¡¨ç°
    if '10d_return' in fdf.columns:
        try:
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            if np.isnan(market_mean_10d) or abs(market_mean_10d) < 1e-9:
                market_mean_10d = 1e-9
            fdf['rsl'] = fdf['10d_return'] / market_mean_10d
        except:
            fdf['rsl'] = 1.0
    else:
        fdf['rsl'] = 1.0
        
    # å­æŒ‡æ ‡å½’ä¸€åŒ–
    def norm_col(s):
        s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
        mn = s.min(); mx = s.max()
        if mx - mn < 1e-9:
            return pd.Series([0.5]*len(s), index=s.index)
        return (s - mn) / (mx - mn)

    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    if 'net_mf' in fdf.columns and fdf['net_mf'].abs().sum() > 0:
        fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf))))
    else:
        fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
    fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_macd'] = norm_col(fdf.get('macd', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

    # è¶‹åŠ¿å› å­ä¸å¼ºåŒ–è¯„åˆ†
    fdf['ma_trend_flag'] = ((fdf.get('ma5', pd.Series([])) > fdf.get('ma10', pd.Series([]))) & (fdf.get('ma10', pd.Series([])) > fdf.get('ma20', pd.Series([])))).fillna(False)
    fdf['macd_golden_flag'] = (fdf.get('diff', 0) > fdf.get('dea', 0)).fillna(False)
    fdf['vol_price_up_flag'] = (fdf.get('vol_last', 0) > fdf.get('vol_ma5', 0)).fillna(False)
    fdf['break_high_flag'] = (fdf.get('last_close', 0) > fdf.get('recent20_high', 0)).fillna(False)
    fdf['yang_body_strength'] = fdf.get('yang_body_strength', 0.0).fillna(0.0)

    fdf['trend_score_raw'] = (
        fdf['ma_trend_flag'].astype(float) * 1.0 +
        fdf['macd_golden_flag'].astype(float) * 1.3 +
        fdf['vol_price_up_flag'].astype(float) * 1.0 +
        fdf['break_high_flag'].astype(float) * 1.3 +
        fdf['yang_body_strength'].astype(float) * 0.8
    )

    fdf['trend_score'] = norm_col(fdf['trend_score_raw'])

    # æœ€ç»ˆç»¼åˆè¯„åˆ†
    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['trend_score'] * 0.40 +
        fdf.get('s_10d', 0)*0.12 +
        fdf.get('s_rsl', 0)*0.08 +
        fdf.get('s_volratio', 0)*0.10 +
        fdf.get('s_turn', 0)*0.05 +
        fdf.get('s_money', 0)*0.10 +
        fdf.get('s_pct', 0)*0.10 +
        fdf.get('s_volatility', 0)*0.05
    )
    
    return fdf

# ---------------------------
# å›æµ‹ä¸»æ¨¡å—ï¼ˆå·²ä¿®æ”¹ä¸ºä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼‰
# ---------------------------
def run_backtest(trade_dates, hold_days, top_k):
    """
    è¿è¡Œå›æµ‹ã€‚
    trade_dates: éœ€è¦å›æµ‹çš„äº¤æ˜“æ—¥åˆ—è¡¨ (å³ä¹°å…¥æ—¥)
    hold_days: æŒæœ‰å¤©æ•°åˆ—è¡¨ [1, 3, 5]
    top_k: æ¯å¤©é€‰è‚¡ Top K
    """
    global GLOBAL_KLINE_DATA # å£°æ˜ä½¿ç”¨å…¨å±€å˜é‡
    
    # æ­¥éª¤ 0ï¼šæ€§èƒ½ä¼˜åŒ–æ ¸å¿ƒ - é¢„åŠ è½½ K çº¿æ•°æ®
    # è®¡ç®—éœ€è¦é¢„åŠ è½½çš„æ—¥æœŸèŒƒå›´
    if not trade_dates:
        st.warning("å›æµ‹æ—¥æœŸåˆ—è¡¨ä¸ºç©ºï¼Œå›æµ‹ç»ˆæ­¢ã€‚")
        return pd.DataFrame()
        
    start_buy_date = trade_dates[0]
    # æŒ‡æ ‡è®¡ç®—éœ€è¦ 60 å¤©å†å²æ•°æ®ï¼ŒMACDéœ€è¦ 26 å¤©ï¼Œæˆ‘ä»¬å– 60 å¤© Lookback
    lookback_days = 60 * 2 # ç²—ç•¥ä¼°è®¡
    start_kline_date = (datetime.strptime(start_buy_date, "%Y%m%d") - timedelta(days=lookback_days)).strftime("%Y%m%d")
    
    # è·å–æ•°æ®ï¼Œè¿™ä¸€æ­¥è°ƒç”¨äº†å¸¦é‡è¯•æœºåˆ¶çš„å‡½æ•°
    # è¿™ä¸€æ­¥å°†æ•°æ®å¡«å……åˆ° GLOBAL_KLINE_DATA
    get_bulk_daily_data(start_kline_date, last_trade)
    
    if not GLOBAL_KLINE_DATA:
        return pd.DataFrame()


    st.info(f"å¼€å§‹å›æµ‹ï¼š{trade_dates[0]} åˆ° {trade_dates[-1]}ï¼ŒæŒè‚¡ {hold_days} å¤©ï¼Œæ¯æ—¥é€‰æ‹© Top {top_k}ã€‚")
    
    results = {h: {'returns': [], 'wins': 0, 'total': 0} for h in hold_days}
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œç”¨äºè®¡ç®—å–å‡ºæ—¥æœŸ
    today_date_str = datetime.now().strftime("%Y%m%m")
    max_lookback = BACKTEST_DAYS + max(HOLD_DAYS) + 30
    start_lookback = (datetime.strptime(trade_dates[0], "%Y%m%d") - timedelta(days=max_lookback)).strftime("%Y%m%d")
    all_trade_cals = get_all_trade_cals(start_lookback, last_trade) # ä»…è·å–åˆ°æœ€è¿‘äº¤æ˜“æ—¥

    if len(all_trade_cals) == 0:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œå›æµ‹å¤±è´¥ã€‚")
        return pd.DataFrame()

    pbar = st.progress(0, text=f"å›æµ‹è¿›åº¦ï¼š0 / {len(trade_dates)} å¤©")

    for i, buy_date in enumerate(trade_dates):
        
        # 1. è·å–å½“æ—¥æ•°æ® (æ­¤å¤„ä»éœ€ API è°ƒç”¨ï¼Œå› ä¸ºéœ€è¦å½“æ—¥çš„æ¶¨å¹…æ¦œå’Œé«˜çº§æ•°æ®)
        try:
            daily_all = safe_get(pro.daily, trade_date=buy_date)
            if daily_all.empty: continue
            daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
        except:
            continue
            
        pool0 = daily_all.head(INITIAL_TOP_N).copy().reset_index(drop=True)
        
        # 2. è·å–é«˜çº§æ¥å£æ•°æ® (å·²ç¼“å­˜)
        stock_basic, daily_basic, moneyflow = get_advanced_data(buy_date)
        
        # 3. åˆå¹¶ä¿¡æ¯
        pool_merged = merge_all_info(pool0, stock_basic, daily_basic, moneyflow)

        # 4. æ¸…æ´—å’Œè¿‡æ»¤
        clean_df = clean_and_filter(pool_merged, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_MARKET_CAP, MAX_MARKET_CAP, VOL_SPIKE_MULT, VOLATILITY_MAX, HIGH_PCT_THRESHOLD, FINAL_POOL)
        if clean_df.empty: continue

        # 5. è¯„åˆ† (***æ€§èƒ½æå‡ç‚¹ï¼šæŒ‡æ ‡è®¡ç®—ç°åœ¨è¯»å–æœ¬åœ°ç¼“å­˜***)
        fdf_scored = compute_scores(clean_df, buy_date, MIN_MARKET_CAP, MAX_MARKET_CAP, VOL_SPIKE_MULT, VOLATILITY_MAX, HIGH_PCT_THRESHOLD)
        if fdf_scored.empty: continue
        
        fdf_scored = fdf_scored.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).head(top_k)
        
        # 6. è®¡ç®—æ”¶ç›Š (ä¹°å…¥ä»·: buy_date çš„æ”¶ç›˜ä»·)
        try:
            buy_date_cal_idx = all_trade_cals.index(buy_date)
        except ValueError:
            continue
        
        for _, row in fdf_scored.iterrows():
            ts_code = row['ts_code']
            buy_close = row['last_close'] 

            for h in hold_days:
                try:
                    sell_cal_idx = buy_date_cal_idx + h
                    
                    if sell_cal_idx >= len(all_trade_cals): continue 
                    
                    sell_date = all_trade_cals[sell_cal_idx]
                    
                    # è·å–å–å‡ºæ—¥æ•°æ® (ä»é¢„åŠ è½½çš„å…¨é‡ K çº¿æ•°æ®ä¸­æŸ¥è¯¢ï¼Œé¿å… API è°ƒç”¨)
                    if ts_code not in GLOBAL_KLINE_DATA: continue
                    
                    sell_data_row = GLOBAL_KLINE_DATA[ts_code]
                    sell_close_df = sell_data_row[sell_data_row['trade_date'] == sell_date]['close']
                    
                    if sell_close_df.empty: continue
                    sell_close = sell_close_df.iloc[0]
                    
                    # æ”¶ç›Šç‡
                    ret = (sell_close / buy_close) - 1.0
                    results[h]['returns'].append(ret)
                    results[h]['total'] += 1
                    if ret > 0:
                        results[h]['wins'] += 1
                except Exception:
                    continue
        
        pbar.progress((i + 1) / len(trade_dates), text=f"å›æµ‹è¿›åº¦ï¼š{i+1} / {len(trade_dates)} å¤©")

    pbar.empty() 
    
    # 7. æ•´ç†ç»“æœ
    final_results = []
    for h in hold_days:
        r = results[h]
        avg_ret = np.mean(r['returns']) * 100 if r['returns'] else 0.0
        win_rate = (r['wins'] / r['total']) * 100 if r['total'] > 0 else 0.0
        
        final_results.append({
            'æŒè‚¡å¤©æ•°': f'{h} å¤©',
            'å¹³å‡æ”¶ç›Šç‡ (%)': f'{avg_ret:.2f}',
            'èƒœç‡ (%)': f'{win_rate:.2f}',
            'æ€»äº¤æ˜“æ¬¡æ•°': r['total']
        })
        
    return pd.DataFrame(final_results)


# ---------------------------
# å®æ—¶é€‰è‚¡ä¸»æµç¨‹ 
# ---------------------------
def live_stock_pick():
    global GLOBAL_KLINE_DATA # å®æ—¶é€‰è‚¡ä¹Ÿåˆ©ç”¨ K çº¿ç¼“å­˜
    st.session_state['mode'] = 'live'
    
    # é¢„åŠ è½½ K çº¿æ•°æ®ï¼ˆä»…å½“æ—¥é€‰è‚¡æ‰€éœ€ï¼Œstart_date å¯ä»¥è®¾ç½®ä¸ºæœ€è¿‘ 90 å¤©ï¼‰
    start_date_90 = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=90)).strftime("%Y%m%d")
    get_bulk_daily_data(start_date_90, last_trade)
    
    # 1. æ‹‰å½“æ—¥æ¶¨å¹…æ¦œåˆç­›
    st.write("æ­£åœ¨æ‹‰å–å½“æ—¥ dailyï¼ˆæ¶¨å¹…æ¦œï¼‰ä½œä¸ºåˆç­›...")
    daily_all = safe_get(pro.daily, trade_date=last_trade)
    if daily_all.empty:
        st.error("æ— æ³•è·å–å½“æ—¥ daily æ•°æ®ï¼ˆTushare è¿”å›ç©ºï¼‰ã€‚è¯·ç¡®è®¤ Token æƒé™ã€‚")
        st.stop()

    daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
    st.write(f"å½“æ—¥è®°å½•ï¼š{len(daily_all)}ï¼Œå–æ¶¨å¹…å‰ {INITIAL_TOP_N} ä½œä¸ºåˆç­›ã€‚")
    pool0 = daily_all.head(int(INITIAL_TOP_N)).copy().reset_index(drop=True)

    # 2. å°è¯•åŠ è½½é«˜çº§æ¥å£
    stock_basic, daily_basic, moneyflow = get_advanced_data(last_trade)
    
    # 3. åˆå¹¶åŸºæœ¬ä¿¡æ¯
    pool_merged = merge_all_info(pool0, stock_basic, daily_basic, moneyflow)

    # 4. åŸºæœ¬æ¸…æ´—
    st.write("å¯¹åˆç­›æ± è¿›è¡Œæ¸…æ´—ï¼ˆST/åœç‰Œ/ä»·æ ¼/ä¸€å­—æ¿/æ¢æ‰‹/æˆäº¤é¢ç­‰ï¼‰...")
    clean_df = clean_and_filter(pool_merged, MIN_PRICE, MAX_PRICE, MIN_TURNOVER, MIN_AMOUNT, MIN_MARKET_CAP, MAX_MARKET_CAP, VOL_SPIKE_MULT, VOLATILITY_MAX, HIGH_PCT_THRESHOLD, FINAL_POOL)

    if clean_df.empty:
        st.error("æ¸…æ´—åæ²¡æœ‰å€™é€‰ï¼Œå»ºè®®æ”¾å®½æ¡ä»¶æˆ–æ£€æŸ¥æ¥å£æƒé™ã€‚")
        st.stop()
    
    st.write(f"æ¸…æ´—åå€™é€‰æ•°é‡ï¼š{len(clean_df)} ï¼ˆå°†ä»ä¸­å–æ¶¨å¹…å‰ {FINAL_POOL} è¿›å…¥è¯„åˆ†é˜¶æ®µï¼‰")
    st.write(f"ç”¨äºè¯„åˆ†çš„æ± å­å¤§å°ï¼š{len(clean_df)}")
    
    # 5. è¯„åˆ†è®¡ç®—
    st.write("ä¸ºè¯„åˆ†æ± é€ç¥¨è®¡ç®—æŒ‡æ ‡ï¼ˆæœ¬æ¬¡å·²ä¼˜åŒ–ï¼šä»æœ¬åœ°ç¼“å­˜è¯»å– K çº¿æ•°æ®ï¼‰...")
    fdf = compute_scores(clean_df, last_trade, MIN_MARKET_CAP, MAX_MARKET_CAP, VOL_SPIKE_MULT, VOLATILITY_MAX, HIGH_PCT_THRESHOLD)

    # **è¿™é‡Œæ˜¯å…³é”®çš„æ£€æŸ¥ç‚¹ï¼Œå¦‚æœè¿‡æ»¤å¤ªä¸¥ï¼Œfdfä¼šæ˜¯ç©ºçš„**
    if fdf.empty:
        st.error("è¯„åˆ†è®¡ç®—å¤±è´¥æˆ–æ— æ•°æ®ï¼Œè¯·æ£€æŸ¥ä¸Šé¢æ˜¯å¦æœ‰ã€è¿‡æ»¤å¤±è´¥ã€‘çš„è­¦å‘Šï¼Œå¹¶æ”¾å®½ä¾§è¾¹æ å‚æ•°ã€‚")
        st.stop()

    # 6. æœ€ç»ˆæ’åºä¸å±•ç¤º
    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index = fdf.index + 1

    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(TOP_DISPLAY, len(fdf))}ã€‚")
    display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','vol_ratio','turnover_rate','net_mf','proxy_money','amount','10d_return','macd','diff','dea','k','d','j','rsl','volatility_10']
    
    for c in display_cols:
        if c not in fdf.columns:
            fdf[c] = np.nan

    st.dataframe(fdf[display_cols].head(TOP_DISPLAY), use_container_width=True)

    # ä¸‹è½½ï¼ˆä»…å¯¼å‡ºå‰200é¿å…è¿‡å¤§ï¼‰
    out_csv = fdf[display_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}.csv", mime="text/csv")
    
    return fdf


# ---------------------------
# ä¸»æµç¨‹æ§åˆ¶
# ---------------------------

# å®æ—¶é€‰è‚¡æŒ‰é’®
if st.button('ğŸŸ¢ **è¿è¡Œå½“æ—¥é€‰è‚¡**'):
    live_stock_pick()

# å›æµ‹æŒ‰é’®
if st.button('ğŸŸ  **å¯åŠ¨å›æµ‹** (N å¤©å‰ä¹°å…¥, æŒæœ‰ H å¤©, æ”¶ç›˜ä»·è®¡ç®—)'):
    st.session_state['mode'] = 'backtest'
    with st.spinner(f'æ­£åœ¨è·å–è¿‡å» {BACKTEST_DAYS} ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®å¹¶å›æµ‹... (å·²å¯ç”¨ç½‘ç»œé‡è¯•)'):
        
        # 1. è·å–å›æµ‹äº¤æ˜“æ—¥åˆ—è¡¨ (å³ä¹°å…¥æ—¥)
        today = datetime.strptime(last_trade, "%Y%m%d")
        start_date = (today - timedelta(days=BACKTEST_DAYS * 3)).strftime("%Y%m%d")
        
        all_trade_cals = get_all_trade_cals(start_date, last_trade)
        
        if len(all_trade_cals) < BACKTEST_DAYS + 1:
            st.error(f"äº¤æ˜“æ—¥å†ä¸è¶³ {BACKTEST_DAYS} å¤©ï¼Œè¯·æ£€æŸ¥ Token æƒé™æˆ–é™ä½å›æµ‹å¤©æ•°ã€‚")
        else:
            # æ‰¾åˆ°æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥ï¼ˆlast_tradeï¼‰çš„ç´¢å¼•
            try:
                last_trade_idx = all_trade_cals.index(last_trade)
            except ValueError:
                st.error(f"æœ€è¿‘äº¤æ˜“æ—¥ {last_trade} ä¸åœ¨äº¤æ˜“æ—¥å†ä¸­ã€‚")
                st.stop()
                
            start_idx = last_trade_idx - BACKTEST_DAYS
            end_idx = last_trade_idx 
            
            backtest_dates = all_trade_cals[start_idx:end_idx]
            
            # 2. è¿è¡Œå›æµ‹
            results_df = run_backtest(backtest_dates, HOLD_DAYS, TOP_DISPLAY)
            
            # 3. å±•ç¤ºå›æµ‹ç»“æœ
            if not results_df.empty:
                st.subheader("ğŸ“Š å†å²å›æµ‹ç»“æœ (ä¹°å…¥æ”¶ç›˜ä»· / å–å‡ºæ”¶ç›˜ä»·)")
                st.dataframe(results_df, use_container_width=True)
                st.success("å›æµ‹å®Œæˆï¼")
            else:
                st.warning("å›æµ‹æœªäº§ç”Ÿæœ‰æ•ˆç»“æœï¼Œå¯èƒ½æ˜¯æ•°æ®ç¼ºå¤±æˆ–ç­›é€‰è¿‡äºä¸¥æ ¼ã€‚")


# ---------------------------
# å°ç»“ä¸å»ºè®®ï¼ˆç®€æ´ï¼‰
# ---------------------------
st.markdown("---")
st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆç®€æ´ï¼‰")
st.markdown("""
- **å½“æ—¥é€‰è‚¡**ï¼šç‚¹å‡» **ğŸŸ¢ è¿è¡Œå½“æ—¥é€‰è‚¡**ï¼Œæ‰§è¡ŒåŸæœ‰çš„é€‰è‚¡é€»è¾‘ã€‚
- **å›æµ‹**ï¼šç‚¹å‡» **ğŸŸ  å¯åŠ¨å›æµ‹**ï¼Œè½¯ä»¶å°†å‘åè¿½æº¯ N ä¸ªäº¤æ˜“æ—¥ï¼Œæ¯æ—¥ä½¿ç”¨æ‚¨çš„é€‰è‚¡å‚æ•°é€‰æ‹© Top K è‚¡ç¥¨ï¼Œå¹¶è®¡ç®—æŒæœ‰ H å¤©çš„å¹³å‡æ”¶ç›Šç‡å’Œèƒœç‡ï¼ˆæŒ‰æ”¶ç›˜ä»·ä¹°å–ï¼‰ã€‚
- **å›æµ‹é€Ÿåº¦/ç¨³å®šæ€§**ï¼š**æœ¬æ¬¡å·²åŠ å…¥ç½‘ç»œé‡è¯•æœºåˆ¶**ã€‚å¦‚æœç¬¬ä¸€æ¬¡åŠ è½½å…¨é‡ K çº¿å¤±è´¥ï¼Œç¨‹åºä¼šç­‰å¾… 5 ç§’å¹¶è‡ªåŠ¨é‡è¯• 2 æ¬¡ã€‚ä¸€æ—¦æ•°æ®ç¼“å­˜æˆåŠŸï¼Œåç»­è¿è¡Œé€Ÿåº¦ä¼šå¤§å¹…æå‡ã€‚
- **æ•…éšœæ’é™¤**ï¼šå¦‚æœå†æ¬¡å¤±è´¥ï¼Œè¯·è§‚å¯Ÿæ˜¯å¦æœ‰**ã€è¿‡æ»¤å¤±è´¥ã€‘**çš„çº¢è‰²è­¦å‘Šã€‚è‹¥æœ‰ï¼Œè¯·å°è¯•æ”¾å®½ä¾§è¾¹æ çš„å‚æ•°ï¼Œä¾‹å¦‚ï¼š**`æ”¾é‡å€æ•°é˜ˆå€¼`** æˆ– **`è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)`**ã€‚
""")
