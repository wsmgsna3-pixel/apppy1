import streamlit as st
import tushare as ts
import pandas as pd
import datetime
import os
import time
from tenacity import retry, stop_after_attempt, wait_fixed

# ================= 1. é¡µé¢é…ç½® =================
st.set_page_config(page_title="å®Œç¾çªç ´ç­–ç•¥", page_icon="ğŸ’", layout="wide")

st.title("ğŸ’ Aè‚¡å®Œç¾çªç ´ç³»ç»Ÿ (Perfect Breakout)")
st.markdown("### æ ¸å¿ƒå‡çº§ï¼šå‰”é™¤å¤©é‡/ä¸Šå½±çº¿ + é”å®šå®ä½“å¤§é˜³ + é»„é‡‘é‡æ¯”")

# æ–‡ä»¶è·¯å¾„
CACHE_FILE = "scan_result_perfect.csv"
HISTORY_FILE = "scan_history_perfect.txt"

# ================= 2. ä¸»ç•Œé¢ï¼šTokenè¾“å…¥ =================
st.info("ğŸ‘‡ è¯·åœ¨ä¸‹æ–¹è¾“å…¥æ‚¨çš„ Tushare Token")
my_token = st.text_input("Tushare Token", type="password", key="token_main", placeholder="åœ¨æ­¤ç²˜è´´ Token...")

# ================= 3. ä¾§è¾¹æ ï¼šå‚æ•°è®¾ç½® =================
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°æ§åˆ¶å°")
    
    st.divider()
    st.subheader("ğŸ—“ï¸ æ¨¡å¼é€‰æ‹©")
    mode = st.radio("è¿è¡Œæ¨¡å¼", ["å•æ—¥æ‰«æ", "åŒºé—´å›æµ‹"], index=0)
    
    if mode == "å•æ—¥æ‰«æ":
        default_date = datetime.date.today() - datetime.timedelta(days=1)
        if datetime.date.today().weekday() == 0:
            default_date = datetime.date.today() - datetime.timedelta(days=3)
        selected_date = st.date_input("é€‰æ‹©æ—¥æœŸ", default_date)
        start_date_str = selected_date.strftime('%Y%m%d')
        end_date_str = start_date_str
    else:
        default_start = datetime.date(2025, 9, 1)
        c1, c2 = st.columns(2)
        with c1: d1 = st.date_input("å¼€å§‹", default_start)
        with c2: d2 = st.date_input("ç»“æŸ", datetime.date.today())
        start_date_str = d1.strftime('%Y%m%d')
        end_date_str = d2.strftime('%Y%m%d')

    st.divider()
    st.subheader("ğŸ¯ ç­›é€‰æ ‡å‡†")
    
    scan_limit = st.slider("åˆç­›æ´»è·ƒè‚¡æ•°é‡", 200, 5000, 1000, step=50)
    
    col_p1, col_p2 = st.columns(2)
    with col_p1:
        min_p = st.number_input("æœ€ä½ä»·(å…ƒ)", value=8.0)
        min_mv = st.number_input("æœ€å°å¸‚å€¼(äº¿)", value=30.0)
    with col_p2:
        max_p = st.number_input("æœ€é«˜ä»·(å…ƒ)", value=300.0)
        max_mv = st.number_input("æœ€å¤§å¸‚å€¼(äº¿)", value=2000.0)

    st.divider()
    if st.button("ğŸ—‘ï¸ å½»åº•æ¸…é™¤æ‰€æœ‰ç¼“å­˜"):
        if os.path.exists(CACHE_FILE): os.remove(CACHE_FILE)
        if os.path.exists(HISTORY_FILE): os.remove(HISTORY_FILE)
        st.toast("ç¼“å­˜å·²æ¸…ç©ºï¼Œä¸€åˆ‡é‡æ–°å¼€å§‹ï¼")

# ================= 4. æ ¸å¿ƒå·¥å…·å‡½æ•° =================

def get_trade_cal(pro, start, end):
    df = pro.trade_cal(exchange='', start_date=start, end_date=end, is_open='1')
    return df['cal_date'].tolist()

@retry(stop=stop_after_attempt(3), wait=wait_fixed(0.5))
def fetch_chips_safe(pro, ts_code, trade_date):
    return pro.cyq_perf(ts_code=ts_code, start_date=trade_date, end_date=trade_date)

def save_result_to_csv(item_list):
    if not item_list: return
    df = pd.DataFrame(item_list)
    if not os.path.exists(CACHE_FILE):
        df.to_csv(CACHE_FILE, index=False, encoding='utf-8-sig')
    else:
        df.to_csv(CACHE_FILE, mode='a', header=False, index=False, encoding='utf-8-sig')

def mark_date_as_scanned(date_str):
    with open(HISTORY_FILE, 'a') as f:
        f.write(date_str + "\n")

def is_date_scanned(date_str):
    if os.path.exists(CACHE_FILE):
        try:
            df = pd.read_csv(CACHE_FILE)
            if str(date_str) in df['æ—¥æœŸ'].astype(str).values:
                return True
        except:
            pass
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r') as f:
            scanned_dates = f.read().splitlines()
            if str(date_str) in scanned_dates:
                return True
    return False

# --- æ‰¹é‡è·å– ---
def batch_get_daily(pro, codes, trade_date):
    try:
        chunk_size = 50
        all_df = []
        start_dt = pd.to_datetime(trade_date) - pd.Timedelta(days=130)
        start_date_fmt = start_dt.strftime('%Y%m%d')
        for i in range(0, len(codes), chunk_size):
            chunk = codes[i:i+chunk_size]
            codes_str = ",".join(chunk)
            df = pro.daily(ts_code=codes_str, start_date=start_date_fmt, end_date=trade_date)
            if not df.empty: all_df.append(df)
            time.sleep(0.1)
        if not all_df: return pd.DataFrame()
        return pd.concat(all_df)
    except:
        return pd.DataFrame()

# ================= 5. å®Œç¾çªç ´é€»è¾‘ (Perfect Breakout) =================

def filter_perfect_batch(df_daily_all, trade_date):
    """
    é€»è¾‘å‡çº§ï¼š
    1. è¶‹åŠ¿ï¼šClose > MA60
    2. çœŸçªç ´ï¼šåˆ›60æ—¥æ–°é«˜ + é‡æ¯”(2.0-5.0) + æ¶¨å¹…>4%
    3. å½¢æ€ï¼šå®ä½“é¥±æ»¡ (æ”¶ç›˜ä»·æ¥è¿‘æœ€é«˜ä»·ï¼Œæ‹’ç»é•¿ä¸Šå½±)
    """
    results = {}
    if df_daily_all.empty: return {}
    
    grouped = df_daily_all.groupby('ts_code')
    
    for code, group in grouped:
        group = group.sort_values('trade_date')
        if group.iloc[-1]['trade_date'] != trade_date: continue
        
        if len(group) < 60: continue
        
        recent_60 = group.tail(60)
        today = recent_60.iloc[-1]
        past_59 = recent_60.iloc[:-1]
        if past_59.empty: continue
        
        # 1. è¶‹åŠ¿éªŒè¯
        ma60 = recent_60['close'].mean()
        if today['close'] < ma60: continue
        
        # 2. çªç ´éªŒè¯ (æ–°é«˜)
        max_past_close = past_59['close'].max()
        if today['close'] <= max_past_close: continue
        
        # 3. çˆ†å‘åŠ› (æ¶¨å¹…)
        # æ¶¨å¹… > 4.5% (åŠ›åº¦è¦å¤Ÿ)
        if not (4.5 < today['pct_chg'] < 10.5): continue
        
        # 4. å½¢æ€éªŒè¯ (æ‹’ç»é¿é›·é’ˆ)
        # æ”¶ç›˜ä»·å¿…é¡»å¤„äºå½“æ—¥æŒ¯å¹…çš„é¡¶ç«¯ 80% åŒºåŸŸ
        # é€»è¾‘ï¼š(Close - Low) / (High - Low) > 0.8
        high = today['high']
        low = today['low']
        close = today['close']
        
        if high != low:
            pos_in_candle = (close - low) / (high - low)
            if pos_in_candle < 0.8: continue # ä¸Šå½±çº¿å¤ªé•¿ï¼ŒæŠ›å‹å¤§ï¼Œä¸è¦
        
        # 5. é‡èƒ½éªŒè¯ (æ‹’ç»å¤©é‡)
        v_ma5 = past_59['vol'].tail(5).mean()
        if v_ma5 == 0: continue
        vol_ratio = today['vol'] / v_ma5
        
        if vol_ratio < 2.0: continue # é‡ä¸å¤Ÿ
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¸ç›´æ¥è¿‡æ»¤å¤§å€é‡ï¼Œè€Œæ˜¯åœ¨æ‰“åˆ†æ—¶æƒ©ç½š
        
        # è®¡ç®—æ½œä¼æœŸæ¶¨å¹…
        start_price = past_59.iloc[0]['close']
        end_price = past_59.iloc[-1]['close']
        period_chg = (end_price - start_price) / start_price
        
        if not (0 < period_chg < 0.40): continue
        
        results[code] = {
            'vol_ratio': round(vol_ratio, 2), 
            'pct_chg': today['pct_chg'],
            'period_chg': round(period_chg * 100, 1),
            'close': close
        }
            
    return results

def get_sorted_pool(_pro, trade_date, _min_p, _max_p, _min_mv, _max_mv):
    try:
        # åŸºç¡€è¿‡æ»¤
        df_basic = _pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,list_date,market')
        df_basic = df_basic[~df_basic['name'].str.contains('ST|é€€')]
        df_basic = df_basic[~df_basic['ts_code'].str.contains('\.BJ')]
        limit_date = pd.to_datetime(trade_date) - pd.Timedelta(days=180)
        df_basic = df_basic[pd.to_datetime(df_basic['list_date']) < limit_date]
        
        # æˆäº¤é¢åˆç­›
        df_daily = _pro.daily(trade_date=trade_date, fields='ts_code,amount')
        df_basic_daily = _pro.daily_basic(trade_date=trade_date, fields='ts_code,circ_mv')
        
        if df_daily.empty or df_basic_daily.empty: return pd.DataFrame()
        
        df_merge = pd.merge(df_basic, df_daily, on='ts_code')
        df_merge = pd.merge(df_merge, df_basic_daily, on='ts_code')
        
        cond = (
            (df_merge['circ_mv'] >= _min_mv * 10000) & 
            (df_merge['circ_mv'] <= _max_mv * 10000)
        )
        pool = df_merge[cond]
        pool = pool.sort_values('amount', ascending=False)
        return pool
    except:
        return pd.DataFrame()

def calc_returns(pro, ts_code, buy_date):
    res = {'T+1': None, 'T+3': None, 'T+5': None}
    try:
        start_dt = pd.to_datetime(buy_date)
        end_check = (start_dt + pd.Timedelta(days=20)).strftime('%Y%m%d')
        df = pro.daily(ts_code=ts_code, start_date=buy_date, end_date=end_check)
        if df.empty or len(df) < 2: return res
        df = df.sort_values('trade_date').reset_index(drop=True)
        base = df.iloc[0]['close']
        if len(df) > 1: res['T+1'] = round((df.iloc[1]['close'] - base)/base*100, 2)
        if len(df) > 3: res['T+3'] = round((df.iloc[3]['close'] - base)/base*100, 2)
        if len(df) > 5: res['T+5'] = round((df.iloc[5]['close'] - base)/base*100, 2)
    except:
        pass
    return res

# ================= 6. ä¸»ç¨‹åº =================

if st.button("ğŸš€ å¯åŠ¨å®Œç¾çªç ´æ‰«æ", type="primary"):
    if not my_token:
        st.error("ğŸš¨ è¯·è¾“å…¥ Tokenï¼")
        st.stop()
        
    ts.set_token(my_token)
    pro = ts.pro_api()
    trade_dates = get_trade_cal(pro, start_date_str, end_date_str)
    
    if not trade_dates:
        st.error("âŒ æ— äº¤æ˜“æ—¥")
        st.stop()
        
    dashboard_placeholder = st.empty()
    progress_bar = st.progress(0)
    status_box = st.status("æ­£åœ¨å¯»æ‰¾å®Œç¾å½¢æ€...", expanded=True)
    log_area = st.empty()

    for i, t_date in enumerate(trade_dates):
        if is_date_scanned(t_date):
            status_box.write(f"âš¡ï¸ {t_date} å·²è·³è¿‡...")
            progress_bar.progress((i+1)/len(trade_dates))
            continue
            
        status_box.write(f"ğŸ“† [{i+1}/{len(trade_dates)}] æ‰«æ {t_date} ...")
        progress_bar.progress((i)/len(trade_dates))
        
        # 1. åŸºç¡€æ± 
        pool = get_sorted_pool(pro, t_date, min_p, max_p, min_mv, max_mv)
        if pool.empty: 
            mark_date_as_scanned(t_date)
            continue
            
        target_codes = pool['ts_code'].tolist()[:scan_limit]
        
        # 2. æ‰¹é‡æ—¥çº¿
        df_daily_all = batch_get_daily(pro, target_codes, t_date)
        
        # 3. æ ¸å¿ƒç­›é€‰ï¼šPerfect Breakout
        valid_map = filter_perfect_batch(df_daily_all, t_date)
        
        survivors = list(valid_map.keys())
        daily_candidates = []
        
        for code in survivors:
            # æŸ¥ç­¹ç 
            df_chips = fetch_chips_safe(pro, code, t_date)
            win_rate = 0
            
            if df_chips is not None and not df_chips.empty:
                win_rate = df_chips.iloc[0]['winner_rate']
            
            # è·åˆ©ç›˜é—¨æ§› > 60%
            if win_rate > 60:
                vol_ratio = valid_map[code]['vol_ratio']
                period_chg = valid_map[code]['period_chg']
                
                # è·å–æ¢æ‰‹ç‡
                df_basic = pro.daily_basic(ts_code=code, trade_date=t_date, fields='turnover_rate')
                turn = 0
                if not df_basic.empty: turn = df_basic.iloc[0]['turnover_rate']
                
                # === æ ¸å¿ƒï¼šæ–°æ‰“åˆ†å…¬å¼ ===
                
                # 1. é‡æ¯”åˆ† (é»„é‡‘åŒºé—´ 2.0-4.0)
                # å¦‚æœé‡æ¯” > 5.0ï¼Œåè€Œæ‰£åˆ†ï¼(é˜²æ­¢å¤©é‡å‡çªç ´)
                if vol_ratio <= 4.0:
                    score_vol = vol_ratio * 10 # æœ€é«˜40åˆ†
                else:
                    score_vol = 40 - (vol_ratio - 4.0) * 10 # è¶…è¿‡è¶Šå¤šï¼Œæ‰£å¾—è¶Šç‹ 
                    if score_vol < 0: score_vol = 0
                
                # 2. ç­¹ç åˆ†
                score_chip = win_rate * 0.4 # æœ€é«˜40åˆ†
                
                # 3. æ¢æ‰‹åˆ† (æ´»è·ƒåº¦å¥–åŠ±)
                # æ¢æ‰‹ 5%-15% æ˜¯æœ€å¥½çš„
                score_turn = 0
                if 5 <= turn <= 15:
                    score_turn = 20
                elif turn > 15:
                    score_turn = 10
                
                total_score = round(score_vol + score_chip + score_turn, 1)
                
                # è·å–åç§°
                row = pool[pool['ts_code']==code].iloc[0]
                
                daily_candidates.append({
                    "æ—¥æœŸ": t_date,
                    "ä»£ç ": code,
                    "åç§°": row['name'],
                    "ç»¼åˆå¾—åˆ†": total_score,
                    "é‡æ¯”": vol_ratio,
                    "è·åˆ©ç›˜%": round(win_rate, 1),
                    "æ¢æ‰‹ç‡%": turn,
                    "ts_code": code
                })
        
        # 5. Top 5
        if daily_candidates:
            daily_candidates.sort(key=lambda x: x["ç»¼åˆå¾—åˆ†"], reverse=True)
            top_5_today = daily_candidates[:5]
            
            for item in top_5_today:
                ret = calc_returns(pro, item['ts_code'], t_date)
                item['T+1'] = ret['T+1']
                item['T+3'] = ret['T+3']
                item['T+5'] = ret['T+5']
                del item['ts_code']
                
                log_area.text(f"ğŸ’ {t_date} æ“’é¾™: {item['åç§°']} (å¾—åˆ†{item['ç»¼åˆå¾—åˆ†']} é‡æ¯”{item['é‡æ¯”']})")
            
            save_result_to_csv(top_5_today)
        
        mark_date_as_scanned(t_date)

    progress_bar.progress(100)
    status_box.update(label="æ‰«æå®Œæˆï¼", state="complete", expanded=False)
    
    # ================= 7. ä»ªè¡¨ç›˜ =================
    if os.path.exists(CACHE_FILE):
        try:
            df_all = pd.read_csv(CACHE_FILE)
            
            if mode == "å•æ—¥æ‰«æ":
                df_all = df_all[df_all['æ—¥æœŸ'].astype(str) == start_date_str]
                if df_all.empty:
                    st.warning(f"{start_date_str} æœªå‘ç°å®Œç¾çªç ´è‚¡ã€‚")
                    st.stop()
            
            df_sorted = df_all.sort_values("ç»¼åˆå¾—åˆ†", ascending=False)
            
            # åªçœ‹Top 1
            top_1 = df_sorted.groupby('æ—¥æœŸ').head(1)
            
            def get_metrics(df, col):
                valid_df = df.dropna(subset=[col])
                if valid_df.empty: return 0.0, 0.0
                avg = valid_df[col].mean()
                win = (len(valid_df[valid_df[col] > 0]) / len(valid_df) * 100)
                return avg, win

            t1_avg, t1_win = get_metrics(top_1, 'T+1')
            t3_avg, t3_win = get_metrics(top_1, 'T+3')
            t5_avg, t5_win = get_metrics(top_1, 'T+5')
            
            with dashboard_placeholder.container():
                st.divider()
                st.markdown(f"## ğŸ’ å®Œç¾çªç ´æˆ˜æŠ¥ (æ—¥æœŸ: {start_date_str})")
                st.caption("ç»Ÿè®¡å£å¾„ï¼šä»…ç»Ÿè®¡æ¯æ—¥å¾—åˆ†ç¬¬ä¸€å (Top 1)")
                
                k1, k2, k3 = st.columns(3)
                k1.metric("Top1 T+1 æ”¶ç›Š", f"{t1_avg:.2f}%", f"èƒœç‡ {t1_win:.1f}%")
                k2.metric("Top1 T+3 æ”¶ç›Š", f"{t3_avg:.2f}%", f"èƒœç‡ {t3_win:.1f}%", delta_color="normal")
                k3.metric("Top1 T+5 æ”¶ç›Š", f"{t5_avg:.2f}%", f"èƒœç‡ {t5_win:.1f}%")
                
                st.markdown("### ğŸ† æ¯æ—¥å† å†› (Top 1)")
                st.dataframe(top_1.sort_values('æ—¥æœŸ', ascending=False).head(10), use_container_width=True)
                
                with open(CACHE_FILE, "rb") as f:
                    st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´CSV", f, "perfect_result.csv")
        except Exception as e:
            st.error(f"è¯»å–ç»“æœå‡ºé”™: {e}")
