# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V35.0 æé€Ÿè°ƒå‚ç‰ˆ (ç®—åˆ†ä¸ç­›é€‰åˆ†ç¦»)
è§£å†³ç—›ç‚¹ï¼š
1. è°ƒæ•´å‚æ•°(å¸‚å€¼/æ¶¨å¹…)æ— éœ€æ¸…é™¤ç¼“å­˜ï¼Œç§’çº§å“åº”ã€‚
2. å³ä½¿å´©æºƒï¼Œé‡å¯åå¯ç›´æ¥åˆ©ç”¨å·²ç®—å¥½çš„åˆ†æ•°æ•°æ®ï¼Œä¸æµªè´¹æ—¶é—´ã€‚
3. æ¶æ„ï¼šå…ˆå»ºç«‹ã€å…¨é‡åˆ†æ•°åº“ã€‘ï¼Œå†è¿›è¡Œã€åŠ¨æ€ç­–ç•¥ç­›é€‰ã€‘ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import os
import gc

# ---------------------------
# é¡µé¢é…ç½®
# ---------------------------
st.set_page_config(page_title="V35.0 æé€Ÿè°ƒå‚å°", layout="wide")
st.title("âš¡ V35.0 æé€Ÿè°ƒå‚ç›‘æ§å° (ä¸€æ¬¡ç®—åˆ†ï¼Œæ— é™è°ƒå‚)")

# ---------------------------
# å…¨å±€è®¾ç½®ä¸æ–‡ä»¶è·¯å¾„
# ---------------------------
SCORE_DB_FILE = "v35_score_database.csv" # å­˜æ”¾å…¨é‡ç®—åˆ†æ•°æ®çš„"å¤§æ•°æ®åº“"
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 
GLOBAL_CALENDAR = [] 

@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    start_search = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=max(num_days * 5, 120))).strftime("%Y%m%d")
    end_search = (datetime.strptime(end_date_str, "%Y%m%d") + timedelta(days=60)).strftime("%Y%m%d")
    
    cal = safe_get('trade_cal', start_date=start_search, end_date=end_search)
    if cal.empty or 'is_open' not in cal.columns: return []
    
    global GLOBAL_CALENDAR
    open_cal = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=True)
    GLOBAL_CALENDAR = open_cal['cal_date'].tolist()
    
    past_days = open_cal[open_cal['cal_date'] <= end_date_str]['cal_date'].tolist()
    return past_days[-num_days:]

# ----------------------------------------------------------------------
# æ•°æ®ä¸‹è½½
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    # åŸºç¡€è¡Œæƒ…
    daily_df = safe_get('daily', trade_date=date)
    # å¤æƒå› å­
    adj_df = safe_get('adj_factor', trade_date=date)
    # æ¯æ—¥æŒ‡æ ‡ (å¸‚å€¼ circ_mv, æ¢æ‰‹ç‡ç­‰)
    basic_df = safe_get('daily_basic', trade_date=date, fields='ts_code,circ_mv')
    # è‚¡ç¥¨åç§°
    name_df = safe_get('stock_basic', fields='ts_code,name')
    
    if not daily_df.empty:
        # ä»…ä¿ç•™åŒåˆ› (30/688)
        daily_df = daily_df[daily_df['ts_code'].str.startswith(('30', '688'))]
        
        # åˆå¹¶å¸‚å€¼ (æ³¨æ„: circ_mv å•ä½æ˜¯ä¸‡å…ƒ)
        if not basic_df.empty:
            daily_df = daily_df.merge(basic_df, on='ts_code', how='left')
        
        # åˆå¹¶åç§°
        if not name_df.empty:
            daily_df = daily_df.merge(name_df, on='ts_code', how='left')

    if not adj_df.empty:
        adj_df = adj_df[adj_df['ts_code'].str.startswith(('30', '688'))]
        
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(select_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_CALENDAR
    if not select_days_list: return False
    
    first_select_date = min(select_days_list)
    last_select_date = max(select_days_list)
    
    # é¢„åŠ è½½æ•°æ®èŒƒå›´ï¼šæœ€æ—©é€‰è‚¡æ—¥å‰150å¤© ~ æœ€æ™šé€‰è‚¡æ—¥å20å¤©
    try:
        last_idx = GLOBAL_CALENDAR.index(last_select_date)
        end_fetch_idx = min(last_idx + 20, len(GLOBAL_CALENDAR) - 1)
        end_fetch_date = GLOBAL_CALENDAR[end_fetch_idx]
    except:
        end_fetch_date = (datetime.now() + timedelta(days=20)).strftime("%Y%m%d")

    start_fetch_date = (datetime.strptime(first_select_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    
    # è·å–æ—¥æœŸåˆ—è¡¨
    cal_range = safe_get('trade_cal', start_date=start_fetch_date, end_date=end_fetch_date, is_open='1')
    all_dates = cal_range['cal_date'].tolist()
    
    st.info(f"â³ æ­£åœ¨é¢„åŠ è½½å…¨é‡è¡Œæƒ…æ•°æ® ({start_fetch_date} ~ {end_fetch_date})...")

    adj_list, daily_list = [], []
    bar = st.progress(0)
    
    total_steps = len(all_dates)
    for i, date in enumerate(all_dates):
        try:
            cached = fetch_and_cache_daily_data(date)
            if not cached['adj'].empty: adj_list.append(cached['adj'])
            if not cached['daily'].empty: daily_list.append(cached['daily'])
            if i % 20 == 0: bar.progress((i+1)/total_steps)
        except: continue 
    bar.empty()

    if not adj_list or not daily_list: return False
     
    # åˆå¹¶æ•°æ®
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    daily_raw = pd.concat(daily_list)
    cols_to_float = ['open', 'high', 'low', 'close', 'pre_close', 'vol', 'circ_mv', 'pct_chg']
    for col in cols_to_float:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])
    
    # è·å–æœ€æ–°å¤æƒå› å­
    latest_date_in_data = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_date_in_data:
        GLOBAL_QFQ_BASE_FACTORS = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_date_in_data), 'adj_factor'].droplevel(1).to_dict()
    
    return True

def get_qfq_data(ts_code, start_date, end_date):
    base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code)
    if not base_adj: return pd.DataFrame()

    try:
        daily = GLOBAL_DAILY_RAW.loc[(ts_code, slice(start_date, end_date)), :]
        adj = GLOBAL_ADJ_FACTOR.loc[(ts_code, slice(start_date, end_date)), 'adj_factor']
    except: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    
    df = daily.join(adj, how='left').dropna(subset=['adj_factor'])
    factor = df['adj_factor'] / base_adj
    
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns: df[col] = df[col] * factor
    
    df = df.reset_index()
    return df.sort_values('trade_date')

# ----------------------------------------------------------------------
# ç®—åˆ†é€»è¾‘ (è®¡ç®— MACD)
# ----------------------------------------------------------------------
def compute_score_for_stock(ts_code, current_date):
    start_date = (datetime.strptime(current_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    df = get_qfq_data(ts_code, start_date, current_date)
    
    if df.empty or len(df) < 30: return -1
    
    last_date = df.iloc[-1]['trade_date']
    last_date_str = last_date.strftime('%Y%m%d') if hasattr(last_date, 'strftime') else str(last_date)
    
    if last_date_str != current_date: return -1

    close = df['close']
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=5, adjust=False).mean()
    macd_val = (diff - dea) * 2
    
    score = (macd_val.iloc[-1] / close.iloc[-1]) * 100000
    if pd.isna(score): score = -1
    return score

# ----------------------------------------------------------------------
# é˜¶æ®µä¸€ï¼šå…¨é‡ç®—åˆ†ä¸å­˜æ¡£ (è¿™æ˜¯"è‹¦åŠ›æ´»"ï¼Œåªåšä¸€æ¬¡)
# ----------------------------------------------------------------------
def batch_compute_scores(date):
    try:
        daily_t = GLOBAL_DAILY_RAW.xs(date, level='trade_date')
    except KeyError: return []

    # 1. å®½æ³›åˆç­› (åªåšæœ€åŸºæœ¬çš„è¿‡æ»¤ï¼Œä¿ç•™å°½å¯èƒ½å¤šçš„æ•°æ®ä»¥ä¾¿åç»­è°ƒå‚)
    # åªè¦æœ‰æˆäº¤é‡ä¸”ä»·æ ¼>20å³å¯ï¼Œæš‚ä¸å¡å¸‚å€¼å’Œæ¶¨å¹…
    mask = (daily_t['vol'] > 0) & (daily_t['close'] >= 20.0) & (daily_t['close'] <= 350.0)
    pool = daily_t[mask]
    
    if pool.empty: return []

    results = []
    candidates = pool.index.tolist()
    
    # éå†è®¡ç®— MACD
    for code in candidates:
        s = compute_score_for_stock(code, date)
        if s > 0:
            # å°†åç»­è°ƒå‚éœ€è¦ç”¨åˆ°çš„å› å­å…¨éƒ¨å­˜ä¸‹æ¥
            row = pool.loc[code]
            results.append({
                'Select_Date': date,
                'Code': code,
                'Score': s,
                'Name': row['name'] if 'name' in row else code,
                'Close': float(row['close']),
                'Pct_Chg': float(row['pct_chg']) if 'pct_chg' in row else 0.0,
                'Circ_Mv': float(row['circ_mv']) if 'circ_mv' in row else 0.0 # å•ä½: ä¸‡å…ƒ
            })
    
    return results

# ----------------------------------------------------------------------
# é˜¶æ®µäºŒï¼šåŠ¨æ€ç­›é€‰ä¸å›æµ‹ (è¿™æ˜¯"æŒ‡æŒ¥å®˜"ï¼Œç§’çº§å“åº”)
# ----------------------------------------------------------------------
def apply_strategy_and_backtest(df_scores, top_n, min_mv_yi, min_pct):
    # df_scores å·²ç»æ˜¯æŸä¸€æ—¥æœŸçš„æ‰€æœ‰å¤‡é€‰è‚¡æ•°æ®äº†
    
    # 1. åŠ¨æ€è¿‡æ»¤
    # å¸‚å€¼è¿‡æ»¤: è¾“å…¥æ˜¯äº¿ï¼Œæ•°æ®æ˜¯ä¸‡å…ƒ -> min_mv_yi * 10000
    min_mv_val = min_mv_yi * 10000
    mask = (df_scores['Circ_Mv'] >= min_mv_val) & (df_scores['Pct_Chg'] >= min_pct)
    
    filtered_df = df_scores[mask].copy()
    
    if filtered_df.empty: return []
    
    # 2. æ’åºå– Top N
    filtered_df = filtered_df.sort_values('Score', ascending=False).head(top_n)
    
    # 3. å›æµ‹ T+1 è¡¨ç° (éœ€è¦æŸ¥ GLOBAL_DAILY_RAW)
    select_date = str(filtered_df.iloc[0]['Select_Date'])
    
    try:
        t_idx = GLOBAL_CALENDAR.index(select_date)
        if t_idx < len(GLOBAL_CALENDAR) - 1:
            buy_date = GLOBAL_CALENDAR[t_idx + 1]
        else:
            buy_date = None
    except: buy_date = None
    
    final_results = []
    
    for rank, (idx, row) in enumerate(filtered_df.iterrows(), 1):
        code = row['Code']
        signal = "â³ ç­‰å¾…å¼€ç›˜"
        open_pct = np.nan
        is_buy = False
        ret_d5 = np.nan
        
        if buy_date:
            try:
                # ä»å†…å­˜ä¸­çš„è¡Œæƒ…æ•°æ®æŸ¥ T+1 å¼€ç›˜
                d1_raw = GLOBAL_DAILY_RAW.loc[(code, buy_date)]
                if isinstance(d1_raw, pd.DataFrame): d1_raw = d1_raw.iloc[0]

                daily_buy_open = float(d1_raw['open'])
                daily_buy_pre = float(d1_raw['pre_close'])
                open_pct = (daily_buy_open / daily_buy_pre - 1) * 100
                
                # ä¹°å…¥é€»è¾‘ (å›ºå®šä¸å˜)
                if 2.0 <= open_pct <= 7.5:
                    is_buy = True
                    signal = "âœ… BUY"
                elif open_pct < 2.0:
                    signal = "ğŸ‘€ å¼±"
                else:
                    signal = "âš ï¸ å¼º"
                
                # è®¡ç®— D5 æ”¶ç›Š
                if is_buy:
                     future_df = get_qfq_data(code, buy_date, "20991231")
                     if not future_df.empty:
                         buy_price = future_df.iloc[0]['open']
                         # å°è¯•å– D5ï¼Œä¸å¤Ÿå°±å–æœ€æ–°çš„
                         idx_sell = 4 if len(future_df) >= 5 else -1
                         ret_d5 = (future_df.iloc[idx_sell]['close'] / buy_price - 1) * 100

            except:
                signal = "âŒ æ— æ•°æ®"
        
        final_results.append({
            'Select_Date': select_date,
            'Trade_Date': buy_date if buy_date else "-",
            'Rank': rank,
            'Code': code,
            'Name': row['Name'],
            'Signal': signal,
            'Open_Pct': open_pct,
            'Ret_D5': ret_d5,
            'Raw_Score': row['Score']
        })
        
    return final_results

# ----------------------------------------------------
# ä¾§è¾¹æ  (å‚æ•°è°ƒèŠ‚)
# ----------------------------------------------------
with st.sidebar:
    st.header("1. åŸºç¡€è®¾ç½®")
    default_date = datetime.now().date()
    end_date = st.date_input("é€‰è‚¡æˆªæ­¢æ—¥æœŸ", value=default_date)
    days_back = int(st.number_input("å›æµ‹å¤©æ•°", value=5))
    
    st.markdown("---")
    st.header("2. åŠ¨æ€è°ƒå‚ (å®æ—¶ç”Ÿæ•ˆ)")
    
    TOP_N = st.slider("Top N", 1, 5, 1)
    
    MIN_MV_YI = st.number_input(
        "æœ€ä½æµé€šå¸‚å€¼ (äº¿)", 
        min_value=10, max_value=500, value=30, step=10
    )
    
    MIN_PCT = st.number_input(
        "æœ€ä½å½“æ—¥æ¶¨å¹… (%)",
        min_value=-5, max_value=5, value=0, step=1
    )

    st.markdown("---")
    st.info("ğŸ’¡ è¯´æ˜: ç¬¬ä¸€æ¬¡è¿è¡Œéœ€è¦ç®—åˆ†(è¾ƒæ…¢)ã€‚ç®—åˆ†å®Œæˆåï¼Œè°ƒæ•´ä¸Šæ–¹å‚æ•°æ— éœ€æ¸…ç©ºç¼“å­˜ï¼Œç»“æœç§’å‡ºã€‚")
    
    # ä»…å½“æƒ³å½»åº•é‡ç½®æ‰€æœ‰ç®—åˆ†æ•°æ®æ—¶æ‰ç”¨
    if st.button("ğŸš¨ å½»åº•æ¸…ç©ºæ‰€æœ‰æ•°æ® (æ…ç‚¹)"):
        if os.path.exists(SCORE_DB_FILE):
            os.remove(SCORE_DB_FILE)
            st.toast("æ•°æ®åº“å·²åˆ é™¤ï¼Œä¸‹æ¬¡è¿è¡Œå°†é‡æ–°å…¨é‡ç®—åˆ†ã€‚", icon="ğŸ—‘ï¸")

# ---------------------------
# ä¸»ç¨‹åº
# ---------------------------
col_token, col_btn = st.columns([3, 1])
with col_token:
    TS_TOKEN = st.text_input("ğŸ”‘ Token", type="password", placeholder="è¾“å…¥ Tushare Token")
with col_btn:
    start_btn = st.button("ğŸš€ æ‰§è¡Œç­–ç•¥", type="primary", use_container_width=True)

if start_btn:
    if not TS_TOKEN: st.stop()
    ts.set_token(TS_TOKEN)
    pro = ts.pro_api()
    
    # 1. è·å–æ—¥æœŸ
    select_dates = get_trade_days(end_date.strftime("%Y%m%d"), days_back)
    if not select_dates: st.stop()
    
    # 2. é¢„åŠ è½½è¡Œæƒ…æ•°æ® (å¿…é¡»æ­¥éª¤ï¼Œç”¨äºç®—åˆ†å’ŒæŸ¥T+1)
    if not get_all_historical_data(select_dates): st.stop()

    # 3. æ£€æŸ¥/å»ºç«‹åˆ†æ•°ç»„åº“ (SCORE_DB_FILE)
    #    é€»è¾‘: çœ‹çœ‹ SCORE_DB_FILE é‡Œæœ‰å“ªäº›æ—¥æœŸå·²ç»ç®—è¿‡äº†
    existing_dates = []
    if os.path.exists(SCORE_DB_FILE):
        try:
            # åªè¯» Select_Date åˆ—ï¼ŒåŠ å¿«é€Ÿåº¦
            df_dates = pd.read_csv(SCORE_DB_FILE, usecols=['Select_Date'])
            existing_dates = df_dates['Select_Date'].astype(str).unique().tolist()
        except: pass
    
    # æ‰¾å‡ºå“ªäº›æ—¥æœŸè¿˜æ²¡ç®—åˆ†
    dates_to_compute = [d for d in select_dates if str(d) not in existing_dates]
    
    # 3.1 è¡¥å…¨ç¼ºå¤±æ—¥æœŸçš„ç®—åˆ† (è‹¦åŠ›æ´»)
    if dates_to_compute:
        st.write(f"ğŸ”„ å‘ç° {len(dates_to_compute)} ä¸ªæ–°æ—¥æœŸéœ€è¦ç®—åˆ†ï¼Œæ­£åœ¨å¤„ç†... (å®Œæˆåå°†æ°¸ä¹…ç¼“å­˜)")
        bar = st.progress(0)
        
        for i, date in enumerate(dates_to_compute):
            scores = batch_compute_scores(date)
            if scores:
                df_chunk = pd.DataFrame(scores)
                # è¿½åŠ æ¨¡å¼å†™å…¥ CSV
                need_header = not os.path.exists(SCORE_DB_FILE)
                df_chunk.to_csv(SCORE_DB_FILE, mode='a', header=need_header, index=False)
            
            # å†…å­˜æ¸…ç†ï¼Œé˜²å´©æºƒ
            if i % 5 == 0: gc.collect()
            bar.progress((i+1)/len(dates_to_compute))
        bar.empty()
    
    # 4. æ ¸å¿ƒï¼šè¯»å–å…¨é‡åˆ†æ•°åº“ï¼Œè¿›è¡ŒåŠ¨æ€ç­›é€‰ (æé€Ÿ)
    st.write("âš¡ æ­£åœ¨åº”ç”¨ç­–ç•¥å‚æ•°è¿›è¡Œæé€Ÿå›æµ‹...")
    
    # ä¸€æ¬¡æ€§è¯»å–æ‰€éœ€æ—¥æœŸçš„æ•°æ®
    if os.path.exists(SCORE_DB_FILE):
        df_all_scores = pd.read_csv(SCORE_DB_FILE)
        # è½¬æ¢æ—¥æœŸæ ¼å¼ä»¥ä¾¿ç­›é€‰
        df_all_scores['Select_Date'] = df_all_scores['Select_Date'].astype(str)
        
        final_report = []
        
        for date in select_dates:
            # ä»å†…å­˜ä¸­åˆ‡ç‰‡
            df_daily = df_all_scores[df_all_scores['Select_Date'] == str(date)]
            if df_daily.empty: continue
            
            # ä¼ å…¥å‚æ•°è¿›è¡Œç­›é€‰
            res = apply_strategy_and_backtest(df_daily, TOP_N, MIN_MV_YI, MIN_PCT)
            if res:
                final_report.extend(res)
        
        # 5. å±•ç¤ºç»“æœ
        if final_report:
            df_res = pd.DataFrame(final_report)
            
            # Dashboard
            trades = df_res[df_res['Signal'].str.contains('BUY', na=False)]
            
            st.markdown(f"### ğŸ“Š ç­–ç•¥è¡¨ç° (Top {TOP_N} | å¸‚å€¼>{MIN_MV_YI}äº¿ | æ¶¨å¹…>{MIN_PCT}%)")
            c1, c2, c3, c4 = st.columns(4)
            
            avg_ret = trades['Ret_D5'].mean()
            win_rate = (trades['Ret_D5'] > 0).mean() * 100
            
            c1.metric("æ€»å…¥å›´", f"{len(df_res)}")
            c2.metric("äº¤æ˜“æ¬¡æ•°", f"{len(trades)}")
            c3.metric("D5 å‡æ”¶", f"{avg_ret:.2f}%")
            c4.metric("D5 èƒœç‡", f"{win_rate:.1f}%")
            
            # æ ·å¼
            st.dataframe(
                df_res[['Trade_Date', 'Code', 'Name', 'Signal', 'Open_Pct', 'Rank', 'Ret_D5', 'Raw_Score']]
                .style.applymap(lambda x: 'background-color: #ff4b4b; color: white' if 'BUY' in str(x) else '', subset=['Signal'])
                .format({'Ret_D5': '{:.2f}%', 'Open_Pct': '{:.2f}%', 'Raw_Score': '{:.0f}'}),
                use_container_width=True
            )
        else:
            st.warning("âš ï¸ å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— ç¬¦åˆç»“æœï¼Œè¯·å°è¯•æ”¾å®½å‚æ•°ã€‚")
            
    else:
        st.error("âŒ æ•°æ®åº“åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥ Tushare æƒé™ã€‚")
