import streamlit as st
import tushare as ts
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import os
import time

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="ä¸‰æ—¥æˆå¦–Â·åŒæ¨¡å®æˆ˜ç³»ç»Ÿ", layout="wide")

st.title("ğŸ‰ ä¸‰æ—¥æˆå¦–Â·åŒæ¨¡å®æˆ˜ç³»ç»Ÿ (å«æ–­ç‚¹ç»­ä¼ )")

# ==========================================
# 2. ä¾§è¾¹æ è®¾ç½®
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿå‚æ•°")
    user_token = st.text_input("Tushare Token:", type="password")
    
    # --- æ¨¡å¼é€‰æ‹© ---
    mode = st.radio("è¯·é€‰æ‹©åŠŸèƒ½æ¨¡å¼", ["ğŸ“¡ å®ç›˜é€‰è‚¡ (æ‰¾æ˜å¤©ä¹°ç‚¹)", "ğŸ“Š å†å²å›æµ‹ (éªŒè¯èƒœç‡)"])
    
    st.subheader("ğŸ¯ ä¸¥é€‰æ ‡å‡†")
    vol_mul = st.slider("é‡èƒ½å€æ•° (æ½œä¼æœŸNå€)", 2.0, 5.0, 3.0, 0.5)
    
    if mode == "ğŸ“Š å†å²å›æµ‹ (éªŒè¯èƒœç‡)":
        st.subheader("ğŸ“… å›æµ‹åŒºé—´")
        # é»˜è®¤ç»“æŸæ—¥æœŸä¸ºä»Šå¤©
        default_end = datetime.now().date()
        end_date_input = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", default_end)
        days_back = st.slider("å›æµ‹è¿‡å»å¤šå°‘å¤©?", 10, 100, 30, 10)
        
        st.info("âœ… å·²å¼€å¯æ–­ç‚¹ç»­ä¼ ï¼šç»“æœå°†å®æ—¶ä¿å­˜åˆ° `backtest_results.csv`ã€‚é‡æ–°è¿è¡Œä¼šè‡ªåŠ¨è·³è¿‡å·²æµ‹æ—¥æœŸã€‚")
        
    else:
        st.subheader("ğŸ“… æ‰«æè®¾ç½®")
        scan_date_input = st.date_input("æ‰«æåŸºå‡†æ—¥ (Day 3)", datetime.now().date())
        st.caption("é€šå¸¸é€‰'ä»Šå¤©'æˆ–'æ˜¨å¤©'æ”¶ç›˜å")

    run_btn = st.button("ğŸš€ å¼€å§‹æ‰§è¡Œ")

# ==========================================
# 3. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================
@st.cache_data(persist="disk", show_spinner=False)
def get_trade_cal(token, start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†"""
    try:
        ts.set_token(token)
        pro = ts.pro_api()
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date, is_open='1')
        return df['cal_date'].tolist()
    except:
        return []

@st.cache_data(persist="disk", show_spinner=False)
def get_daily_snapshot_filtered(token, date_str):
    """è·å–æŸæ—¥å…¨å¸‚åœºã€ä¸¥é€‰æ± ã€‘è‚¡ç¥¨"""
    try:
        ts.set_token(token)
        pro = ts.pro_api()
        # è·å–è¡Œæƒ… + åŸºç¡€ä¿¡æ¯
        df_daily = pro.daily(trade_date=date_str)
        df_basic = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,market,list_date')
        
        if df_daily.empty or df_basic.empty: return pd.DataFrame()
        
        df = pd.merge(df_daily, df_basic, on='ts_code')
        
        # === ä¸¥é€‰æ¼æ–— ===
        # 1. å‰”é™¤ ST
        df = df[~df['name'].str.contains('ST')]
        # 2. å‰”é™¤ åŒ—äº¤æ‰€
        df = df[~df['ts_code'].str.contains('BJ')]
        df = df[~df['market'].str.contains('åŒ—äº¤')]
        # 3. å‰”é™¤ æ¬¡æ–° (ä¸Šå¸‚<60å¤©)
        limit_date = (datetime.strptime(date_str, '%Y%m%d') - timedelta(days=60)).strftime('%Y%m%d')
        df = df[df['list_date'] < limit_date]
        # 4. ä»·æ ¼ >= 10å…ƒ
        df = df[df['close'] >= 10.0]
        # 5. æˆäº¤é¢ > 5000ä¸‡
        df = df[df['amount'] > 50000]
        
        return df
    except:
        return pd.DataFrame()

@st.cache_data(persist="disk", show_spinner=False)
def get_history_data(token, code, end_date, lookback=80):
    """è·å–å†å²æ•°æ® (å«æ½œä¼æœŸ)"""
    try:
        ts.set_token(token)
        pro = ts.pro_api()
        start_dt = datetime.strptime(end_date, '%Y%m%d') - timedelta(days=lookback * 1.5 + 20)
        df = pro.daily(ts_code=code, start_date=start_dt.strftime('%Y%m%d'), end_date=end_date)
        return df
    except:
        return pd.DataFrame()

@st.cache_data(persist="disk", show_spinner=False)
def get_future_data(token, code, start_date, days=15):
    """è·å–æœªæ¥æ•°æ® (ç”¨äºå›æµ‹éªŒè¯)"""
    try:
        ts.set_token(token)
        pro = ts.pro_api()
        start_dt = datetime.strptime(start_date, '%Y%m%d')
        end_dt = start_dt + timedelta(days=days * 2 + 10)
        df = pro.daily(ts_code=code, start_date=start_date, end_date=end_dt.strftime('%Y%m%d'))
        return df.sort_values('trade_date').reset_index(drop=True)
    except:
        return pd.DataFrame()

# ==========================================
# 4. æ ¸å¿ƒä¿¡å·é€»è¾‘ (é€šç”¨)
# ==========================================
def check_signal_logic(df_hist, code, market_type, vol_multiplier):
    """åˆ¤æ–­æ˜¯å¦ä¸‰è¿çˆ†"""
    if len(df_hist) < 63: return False, 0.0, 0.0, 0.0
    
    # å€’åº: 0æ˜¯æœ€æ–°(ä¿¡å·æ—¥)
    df_hist = df_hist.sort_values('trade_date', ascending=False).reset_index(drop=True)
    
    df_burst = df_hist.iloc[0:3]
    df_latent = df_hist.iloc[3:63]
    
    latent_vol = df_latent['vol'].mean()
    if latent_vol == 0: return False, 0.0, 0.0, 0.0
    
    burst_vol = df_burst['vol'].mean()
    
    # 1. é‡èƒ½åˆ¤å®š
    if burst_vol < latent_vol * vol_multiplier: return False, 0.0, 0.0, 0.0
    
    # 2. æ¶¨å¹…åˆ¤å®š
    is_startup = False
    if '300' in code or '688' in code or 'åˆ›ä¸š' in str(market_type) or 'ç§‘åˆ›' in str(market_type):
        is_startup = True
    threshold = 20 if is_startup else 12
    
    p_start = df_burst.iloc[-1]['open']
    p_end = df_burst.iloc[0]['close']
    cum_rise = (p_end - p_start) / p_start * 100
    
    if cum_rise < threshold: return False, 0.0, 0.0, 0.0
    
    # 3. å½¢æ€åˆ¤å®š
    if df_burst.iloc[-1]['pct_chg'] < 5: return False, 0.0, 0.0, 0.0 # Day1å¤§é˜³
    if p_end <= df_burst.iloc[-1]['close']: return False, 0.0, 0.0, 0.0 # é‡å¿ƒä¸Šç§»
    
    # è¿”å›: ä¿¡å·æœ‰æ•ˆ, ç´¯è®¡æ¶¨å¹…, æ½œä¼å‡é‡, çˆ†å‘å‡é‡
    return True, cum_rise, latent_vol, burst_vol

# ==========================================
# 5. æ¨¡å¼ A: å®ç›˜é€‰è‚¡ (Signal Scanner)
# ==========================================
def run_signal_scanner():
    if not user_token:
        st.error("è¯·è¾“å…¥Token")
        return
        
    d_str = scan_date_input.strftime('%Y%m%d')
    st.info(f"ğŸ” æ­£åœ¨æ‰«æ {d_str} (Day 3) çš„ä¸‰è¿çˆ†ä¿¡å·...")
    st.caption("ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ï¼Œå»ºè®®æ˜æ—¥ (Day 4) å…³æ³¨ç«ä»·å¼€ç›˜æƒ…å†µã€‚")
    
    # 1. è·å–å½“æ—¥æ± 
    df_pool = get_daily_snapshot_filtered(user_token, d_str)
    if df_pool.empty:
        st.warning(f"{d_str} å½“æ—¥æ— æ•°æ® (å¯èƒ½æ˜¯éäº¤æ˜“æ—¥æˆ–æœªæ”¶ç›˜)")
        return
        
    results = []
    progress = st.progress(0)
    
    total = len(df_pool)
    for i, (_, row) in enumerate(df_pool.iterrows()):
        progress.progress((i+1)/total)
        
        code = row['ts_code']
        df_hist = get_history_data(user_token, code, d_str)
        is_valid, rise, l_vol, b_vol = check_signal_logic(df_hist, code, row['market'], vol_mul)
        
        if is_valid:
            results.append({
                'ä»£ç ': code,
                'åç§°': row['name'],
                'æ¿å—': row['market'],
                '3æ—¥æ¶¨å¹…(%)': round(rise, 2),
                'é‡èƒ½å€æ•°': round(b_vol/l_vol, 1),
                'Day3æ”¶ç›˜': row['close'],
                'å»ºè®®': 'æ˜æ—¥å…³æ³¨ä½å¸'
            })
            
    progress.empty()
    
    if results:
        st.success(f"ğŸ”¥ å‘ç° {len(results)} åªæ½œåœ¨å¦–è‚¡ï¼")
        st.dataframe(pd.DataFrame(results).sort_values('3æ—¥æ¶¨å¹…(%)', ascending=False))
    else:
        st.warning("ä»Šæ—¥æœªå‘ç°ç¬¦åˆä¸¥é€‰æ¡ä»¶çš„è‚¡ç¥¨ã€‚")

# ==========================================
# 6. æ¨¡å¼ B: æ–­ç‚¹ç»­ä¼ å›æµ‹ (Backtest)
# ==========================================
def run_backtest_resume():
    if not user_token:
        st.error("è¯·è¾“å…¥Token")
        return

    # 1. ç¡®å®šæ—¥æœŸèŒƒå›´
    end_str = end_date_input.strftime('%Y%m%d')
    start_dt_est = end_date_input - timedelta(days=days_back * 2 + 15)
    cal_dates = get_trade_cal(user_token, start_dt_est.strftime('%Y%m%d'), end_str)
    
    # ä¿¡å·æ—¥åŒºé—´ (é¢„ç•™æœ€å10å¤©ç»™ D+10)
    if len(cal_dates) < days_back + 10:
        st.error("æ—¥æœŸèŒƒå›´å¤ªçŸ­")
        return
    signal_dates = cal_dates[-(days_back + 10) : -10]
    
    # === æ–­ç‚¹ç»­ä¼ é€»è¾‘ ===
    csv_file = 'backtest_results.csv'
    processed_dates = set()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å†å²è®°å½•
    if os.path.exists(csv_file):
        try:
            df_exist = pd.read_csv(csv_file)
            if 'ä¿¡å·æ—¥' in df_exist.columns:
                # è®°å½•æ‰€æœ‰å·²ç»è·‘å‡ºç»“æœçš„æ—¥æœŸ
                # æ³¨æ„ï¼šå¦‚æœæŸå¤©è·‘äº†ä½†æ²¡ç»“æœï¼Œè¿™é‡Œå¯èƒ½æ²¡æœ‰è®°å½•ï¼Œä¼šå¯¼è‡´é‡è·‘(è¿™æ˜¯å®‰å…¨çš„)
                # ä¸ºäº†æ›´ä¸¥è°¨ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å¦ä¸€ä¸ªæ–‡ä»¶è®°å½•"å·²æ‰«ææ—¥æœŸ"ï¼Œä½†è¿™é‡Œç®€åŒ–å¤„ç†ï¼š
                # å‡è®¾åªè¦ç»“æœæ–‡ä»¶é‡Œæœ‰è¿™ä¸ªæ—¥æœŸï¼Œå°±ç®—è·‘è¿‡äº†ã€‚
                processed_dates = set(df_exist['ä¿¡å·æ—¥'].astype(str).tolist())
                st.info(f"ğŸ“‚ æ£€æµ‹åˆ°å†å²å­˜æ¡£ï¼ŒåŒ…å« {len(df_exist)} æ¡äº¤æ˜“è®°å½•ã€‚å°†è‡ªåŠ¨è·³è¿‡å·²å¤„ç†æ—¥æœŸã€‚")
        except:
            pass
            
    st.write(f"â³ è®¡åˆ’å›æµ‹åŒºé—´: {signal_dates[0]} è‡³ {signal_dates[-1]}")
    
    # 2. å¾ªç¯å›æµ‹
    progress = st.progress(0)
    status = st.empty()
    
    total_dates = len(signal_dates)
    
    for i, date in enumerate(signal_dates):
        progress.progress((i+1)/total_dates)
        
        # è·³è¿‡å·²å¤„ç†
        if str(date) in processed_dates:
            status.text(f"â­ï¸ è·³è¿‡å·²å›æµ‹æ—¥æœŸ: {date}")
            continue
            
        status.text(f"âš¡ æ­£åœ¨å›æµ‹: {date} ...")
        
        # A. è·å–å½“æ—¥æ± 
        df_day_pool = get_daily_snapshot_filtered(user_token, date)
        if df_day_pool.empty: continue
        
        daily_results = []
        
        # B. æ‰«æ
        for _, row in df_day_pool.iterrows():
            code = row['ts_code']
            df_hist = get_history_data(user_token, code, date)
            is_valid, rise, _, _ = check_signal_logic(df_hist, code, row['market'], vol_mul)
            
            if is_valid:
                # C. æ¨¡æ‹Ÿäº¤æ˜“
                try:
                    curr_idx = cal_dates.index(date)
                    d1_date = cal_dates[curr_idx + 1]
                except:
                    continue
                    
                df_future = get_future_data(user_token, code, d1_date, days=12)
                if df_future.empty: continue
                
                # æ¨æ¼”
                d1 = df_future.iloc[0]
                # é£æ§: ä½å¼€ < -5%
                open_pct = (d1['open'] - d1['pre_close']) / d1['pre_close'] * 100
                if open_pct < -5: continue 
                
                buy_price = d1['open']
                stop_price = buy_price * 0.90
                
                trade = {
                    'ä¿¡å·æ—¥': date,
                    'ä»£ç ': code,
                    'åç§°': row['name'],
                    '3æ—¥æ¶¨å¹…': round(rise, 2),
                    'ä¹°å…¥ä»·': buy_price,
                    'çŠ¶æ€': 'æŒæœ‰'
                }
                
                triggered = False
                for di in range(min(10, len(df_future))):
                    row_f = df_future.iloc[di]
                    key = f"D+{di+1}"
                    
                    if not triggered:
                        if row_f['low'] <= stop_price:
                            triggered = True
                            trade['çŠ¶æ€'] = 'æ­¢æŸ'
                            ret = -10.0
                        else:
                            ret = (row_f['close'] - buy_price) / buy_price * 100
                    else:
                        ret = -10.0
                        
                    if di+1 in [1,3,5,7,10]:
                        trade[key] = round(ret, 2)
                        
                daily_results.append(trade)
        
        # D. å®æ—¶å†™å…¥ CSV (æ–­ç‚¹ç»­ä¼ æ ¸å¿ƒ)
        if daily_results:
            df_new = pd.DataFrame(daily_results)
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™è¡¨å¤´ï¼›å¦‚æœå­˜åœ¨ï¼Œä¸å†™è¡¨å¤´ï¼Œè¿½åŠ æ¨¡å¼
            header = not os.path.exists(csv_file)
            df_new.to_csv(csv_file, mode='a', header=header, index=False, encoding='utf-8-sig')
            
            # åŒæ—¶ä¹Ÿæ·»åŠ åˆ° processed_dates é˜²æ­¢æœ¬æ¬¡è¿è¡Œé‡å¤
            processed_dates.add(str(date))
            
    progress.empty()
    status.empty()
    
    # 3. æœ€ç»ˆå±•ç¤º
    if os.path.exists(csv_file):
        df_final = pd.read_csv(csv_file)
        st.success(f"ğŸ‰ å›æµ‹å…¨éƒ¨å®Œæˆï¼æ€»è®¡äº¤æ˜“è®°å½•: {len(df_final)} æ¡")
        
        # ç»Ÿè®¡
        cols = st.columns(5)
        days = ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']
        for idx, d in enumerate(days):
            if d in df_final.columns:
                win = len(df_final[df_final[d]>0]) / len(df_final) * 100
                avg = df_final[d].mean()
                cols[idx].metric(f"{d} èƒœç‡", f"{win:.1f}%")
                cols[idx].metric(f"{d} å‡æ”¶", f"{avg:.2f}%")
                
        st.dataframe(df_final.sort_values('ä¿¡å·æ—¥', ascending=False))
    else:
        st.warning("æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„äº¤æ˜“ã€‚")

# ==========================================
# 7. å…¥å£
# ==========================================
if run_btn:
    if mode == "ğŸ“¡ å®ç›˜é€‰è‚¡ (æ‰¾æ˜å¤©ä¹°ç‚¹)":
        run_signal_scanner()
    else:
        run_backtest_resume()
