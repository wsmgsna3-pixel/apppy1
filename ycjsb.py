import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time
import warnings
import os

warnings.filterwarnings("ignore")

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="æ½œé¾™ V31Â·å…ˆçŸ¥", layout="wide")
st.title("ğŸ‰ æ½œé¾™ V31Â·å…ˆçŸ¥ (RSIä½ä½æ½œä¼+èš‚èšä¸Šæ ‘)")
st.markdown("""
**ç­–ç•¥æ ¸å¿ƒï¼šé’ˆå¯¹"æ›¿è¡¥ç­–ç•¥"çš„æ»åæ€§è¿›è¡Œé€†å‘æ”¹é€ **
1.  **RSI æŠ¢è·‘**ï¼šé”å®š **RSI 40-60** åŒºé—´ (æ‹’ç» RSI>90 çš„é±¼å°¾)ã€‚
2.  **ç­¹ç ä½ä½**ï¼šé”å®š **è·åˆ©ç›˜ 20%-60%** (ä¸»åŠ›åˆšå»ºä»“ï¼Œè¿˜æœªæ´¾å‘)ã€‚
3.  **ç»å…¸å½¢æ€**ï¼š**èš‚èšä¸Šæ ‘** (è¿ç»­3å¤©å°é˜³çº¿ï¼Œæ¸©å’Œæ”¾é‡)ã€‚
4.  **ç›®æ ‡**ï¼šåœ¨ä¸»åŠ›å¤§æ‹‰å‡å‰çš„"é™é»˜æœŸ"æå‰ 3-5 å¤©è¿›åœºã€‚
""")

DATA_FILE = "market_data_store.csv"

# ==========================================
# 2. æ ¸å¿ƒæ•°æ®å¼•æ“ (å¢é‡æ›´æ–°)
# ==========================================
def get_trade_cal(pro, start_date, end_date):
    try:
        df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open='1')
        return sorted(df['cal_date'].tolist())
    except:
        return []

def sync_market_data(token, start_date, end_date):
    if not token:
        return pd.DataFrame(), "è¯·å…ˆè¾“å…¥Token"
    ts.set_token(token)
    pro = ts.pro_api()
    target_dates = get_trade_cal(pro, start_date, end_date)
    if not target_dates: return pd.DataFrame(), "æ— æ³•è·å–äº¤æ˜“æ—¥å†"
    
    existing_dates = set()
    if os.path.exists(DATA_FILE):
        try:
            df_dates = pd.read_csv(DATA_FILE, usecols=['trade_date'], dtype={'trade_date': str})
            existing_dates = set(df_dates['trade_date'].unique())
        except: pass
            
    missing_dates = sorted(list(set(target_dates) - existing_dates))
    
    if missing_dates:
        st.info(f"å‘ç° {len(missing_dates)} ä¸ªæ–°äº¤æ˜“æ—¥ï¼Œå¢é‡æ›´æ–°ä¸­...")
        progress_bar = st.progress(0)
        new_data = []
        batch_size = 5
        for i, date in enumerate(missing_dates):
            try:
                df_daily = pro.daily(trade_date=date)
                df_basic = pro.daily_basic(trade_date=date, fields='ts_code,turnover_rate,volume_ratio,circ_mv')
                if not df_daily.empty and not df_basic.empty:
                    df_merged = pd.merge(df_daily, df_basic, on='ts_code', how='left')
                    df_merged['trade_date'] = str(date)
                    new_data.append(df_merged)
            except: time.sleep(1)
            progress_bar.progress((i + 1) / len(missing_dates))
            if len(new_data) >= batch_size or (i == len(missing_dates) - 1):
                if new_data:
                    df_batch = pd.concat(new_data)
                    mode = 'a' if os.path.exists(DATA_FILE) else 'w'
                    header = not os.path.exists(DATA_FILE)
                    df_batch.to_csv(DATA_FILE, mode=mode, header=header, index=False)
                    new_data = []
        progress_bar.empty()
        
    if os.path.exists(DATA_FILE):
        dtype_dict = {'ts_code': str, 'trade_date': str}
        df_all = pd.read_csv(DATA_FILE, dtype=dtype_dict)
        df_all = df_all[(df_all['trade_date'] >= start_date) & (df_all['trade_date'] <= end_date)]
        df_all = df_all.drop_duplicates(subset=['ts_code', 'trade_date'])
        
        @st.cache_data
        def get_stock_info():
            df = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,market,industry')
            return df[~df['name'].str.contains('ST')]
        df_info = get_stock_info()
        return df_all, df_info
    else:
        return pd.DataFrame(), "æ— æ•°æ®"

# ==========================================
# 3. ç­–ç•¥é€»è¾‘ (å…ˆçŸ¥)
# ==========================================
def calculate_strategy(df_all, df_info):
    if 'industry' not in df_all.columns:
        df = pd.merge(df_all, df_info[['ts_code', 'industry', 'name']], on='ts_code', how='left')
    else:
        df = df_all.copy()
    
    # === åŸºç¡€æŒ‡æ ‡ ===
    df['ma5'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(5).mean())
    df['ma10'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(10).mean())
    df['ma20'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(20).mean())
    
    # RSI (6æ—¥)
    def calc_rsi(x):
        delta = x.diff()
        gain = (delta.where(delta > 0, 0)).rolling(6).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(6).mean()
        rs = gain / (loss + 0.001)
        return 100 - (100 / (1 + rs))
    df['rsi_6'] = df.groupby('ts_code')['close'].transform(calc_rsi)
    
    # è·åˆ©ç›˜ä¼°ç®—
    df['low_20'] = df.groupby('ts_code')['low'].transform(lambda x: x.rolling(20).min())
    df['high_20'] = df.groupby('ts_code')['high'].transform(lambda x: x.rolling(20).max())
    df['winner_rate'] = (df['close'] - df['low_20']) / (df['high_20'] - df['low_20'] + 0.0001) * 100
    
    # è¿ç»­æ¶¨è·Œå¹… (ç”¨äºè¯†åˆ«èš‚èšä¸Šæ ‘)
    df['pct_lag1'] = df.groupby('ts_code')['pct_chg'].shift(1)
    df['pct_lag2'] = df.groupby('ts_code')['pct_chg'].shift(2)
    
    # === 1. å½¢æ€: èš‚èšä¸Šæ ‘ ===
    # è¿ç»­ 3 å¤©éƒ½æ˜¯é˜³çº¿ï¼Œä¸”æ¶¨å¹…æ¸©å’Œ (0-4%)
    # è¿™ç§å½¢æ€é€šå¸¸æ˜¯ä¸»åŠ›å¸ç­¹
    cond_ant = (df['pct_chg'] > 0) & (df['pct_chg'] < 4.0) & \
               (df['pct_lag1'] > 0) & (df['pct_lag1'] < 4.0) & \
               (df['pct_lag2'] > 0) & (df['pct_lag2'] < 4.0)
               
    # === 2. RSI é»„é‡‘èµ·æ­¥åŒº ===
    # 40-60: åˆšåˆšè„±ç¦»åº•éƒ¨ï¼Œè¿˜æ²¡åŠ é€Ÿï¼Œæ˜¯æœ€ä½³æ½œä¼åŒº
    cond_rsi = (df['rsi_6'] >= 40) & (df['rsi_6'] <= 65)
    
    # === 3. è·åˆ©ç›˜ä½ä½ ===
    # 20-60%: ä¸»åŠ›æœ‰åº•ä»“ï¼Œä½†è¿˜æ²¡åˆ°æ´¾å‘æœŸ
    cond_winner = (df['winner_rate'] >= 20) & (df['winner_rate'] <= 60)
    
    # === 4. è¶‹åŠ¿æŠ¤èˆª ===
    # è‚¡ä»·ç«™ä¸Š MA20 (ç”Ÿå‘½çº¿)
    cond_trend = df['close'] > df['ma20']
    
    # === 5. èµ„é‡‘ ===
    # é‡æ¯” > 0.8 (ä¸èƒ½å®Œå…¨æ²¡é‡)
    cond_vol = df['volume_ratio'] > 0.8
    # å¸‚å€¼è¦†ç›–
    cond_mv = (df['circ_mv'] >= 30*10000) & (df['circ_mv'] <= 800*10000)
    
    # ç»¼åˆä¿¡å·
    df['is_signal'] = cond_ant & cond_rsi & cond_winner & cond_trend & cond_vol & cond_mv
    
    # è¯„åˆ† (RSI è¶Šæ¥è¿‘ 50 è¶Šå¥½? ä¸ï¼ŒRSI è¶Šé«˜è¯´æ˜å¯åŠ¨è¶Šå¿«ï¼Œä½†ä¸èƒ½è¶…è¿‡ 65)
    # æˆ‘ä»¬æŒ‰"è·åˆ©ç›˜"æ’åºï¼Œè¶Šä½è¶Šå¥½? ä¹Ÿä¸ä¸€å®šã€‚
    # æˆ‘ä»¬æŒ‰"é‡æ¯”"æ’åºï¼Œé‡æ¯”æ”¾å¤§è¯´æ˜ä¸»åŠ›å¼€å§‹å¹²æ´»äº†ã€‚
    df['score'] = df['volume_ratio']
    
    return df

# ==========================================
# 4. å›æµ‹é€»è¾‘
# ==========================================
def run_backtest_prophet(df_signals, df_all, cal_dates):
    df_lookup = df_all.copy()
    if 'ma10' not in df_lookup.columns:
         df_lookup['ma10'] = df_lookup.groupby('ts_code')['close'].transform(lambda x: x.rolling(10).mean())
    
    price_lookup = df_lookup[['ts_code', 'trade_date', 'open', 'close', 'low', 'ma10', 'pre_close']].set_index(['ts_code', 'trade_date'])
    
    trades = []
    
    for row in df_signals.itertuples():
        signal_date = row.trade_date
        code = row.ts_code
        
        try:
            curr_idx = cal_dates.index(signal_date)
            future_dates = cal_dates[curr_idx+1 : curr_idx+11]
        except: continue
        
        if not future_dates: continue
        d1_date = future_dates[0]
        
        if (code, d1_date) not in price_lookup.index: continue
        d1_data = price_lookup.loc[(code, d1_date)]
        
        open_pct = (d1_data['open'] - d1_data['pre_close']) / d1_data['pre_close'] * 100
        if open_pct < -2.0: continue
        
        buy_price = d1_data['open']
        trade = {
            'ä¿¡å·æ—¥': signal_date, 'ä»£ç ': code, 'åç§°': row.name, 
            'è¡Œä¸š': row.industry, 'ä¹°å…¥ä»·': buy_price, 
            'RSI': f"{row.rsi_6:.1f}", 'è·åˆ©ç›˜': f"{row.winner_rate:.0f}%",
            'çŠ¶æ€': 'æŒæœ‰'
        }
        
        d1_ret = (d1_data['close'] - buy_price) / buy_price
        
        if d1_ret < -0.05:
             trade['çŠ¶æ€'] = 'D+1æ­¢æŸ'
             trade['D+1'] = round(d1_ret * 100, 2)
             for n in range(1, 10): trade[f"D+{n+1}"] = round(d1_ret * 100, 2)
        else:
            trade['D+1'] = round(d1_ret * 100, 2)
            triggered = False
            for n in range(1, 10):
                if n >= len(future_dates): break
                f_date = future_dates[n]
                if (code, f_date) not in price_lookup.index: break
                f_data = price_lookup.loc[(code, f_date)]
                day_key = f"D+{n+1}"
                
                if not triggered:
                    if f_data['close'] < f_data['ma10']:
                        triggered = True
                        trade['çŠ¶æ€'] = 'ç ´MA10æ­¢ç›ˆ'
                    curr_ret = (f_data['close'] - buy_price) / buy_price * 100
                    trade[day_key] = round(curr_ret, 2)
                else:
                    trade[day_key] = trade.get(f"D+{n}", 0)
        
        trades.append(trade)
        
    return pd.DataFrame(trades)

# ==========================================
# 5. ä¸»ç¨‹åº
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ V31 å…ˆçŸ¥")
    user_token = st.text_input("Tushare Token:", type="password")
    
    days_back = st.slider("å›æµ‹å¤©æ•°", 30, 150, 60)
    end_date_input = st.date_input("æˆªæ­¢æ—¥æœŸ", datetime.now().date())
    
    st.markdown("---")
    st.info("ğŸ”® æ½œä¼å‚æ•°")
    st.markdown("""
    * **RSI**: 40-65 (æ‹’ç»è¿‡çƒ­)
    * **è·åˆ©ç›˜**: 20-60% (æ‹’ç»é«˜ä½)
    * **å½¢æ€**: èš‚èšä¸Šæ ‘ (3è¿å°é˜³)
    """)
    top_n = st.number_input("æ¯æ—¥ä¼˜é€‰ (Top N)", 1, 10, 5)
    
    run_btn = st.button("ğŸš€ å¯åŠ¨å…ˆçŸ¥")

if run_btn:
    if not user_token:
        st.error("è¯·å…ˆè¾“å…¥ Token")
    else:
        end_str = end_date_input.strftime('%Y%m%d')
        start_dt = end_date_input - timedelta(days=days_back * 1.5 + 80)
        start_str = start_dt.strftime('%Y%m%d')
        
        res, info = sync_market_data(user_token, start_str, end_str)
        
        if isinstance(info, pd.DataFrame):
            df_info = info
            df_all = res
            st.success(f"âœ… æ•°æ®åŠ è½½: {len(df_all):,} è¡Œ")
            
            with st.spinner("å¯»æ‰¾æ½œä¼æœºä¼š..."):
                df_calc = calculate_strategy(df_all, df_info)
                
            cal_dates = sorted(df_calc['trade_date'].unique())
            valid_dates = cal_dates[-(days_back):]
            
            df_signals = df_calc[(df_calc['trade_date'].isin(valid_dates)) & (df_calc['is_signal'])].copy()
            
            # æ’åº: é‡æ¯”è¶Šå¤§è¶Šå¥½ (è¯´æ˜ä¸»åŠ›åœ¨èš‚èšä¸Šæ ‘æ—¶å·²ç»åœ¨å·å·æ”¾é‡)
            df_signals = df_signals.sort_values(['trade_date', 'volume_ratio'], ascending=[True, False])
            
            df_signals['æ’å'] = df_signals.groupby('trade_date').cumcount() + 1
            df_top = df_signals[df_signals['æ’å'] <= top_n].copy()
            
            st.write(f"âšª å…ˆçŸ¥ä¿¡å·: **{len(df_top)}** ä¸ª")
            
            if not df_top.empty:
                df_res = run_backtest_prophet(df_top, df_calc, cal_dates)
                
                if not df_res.empty:
                    st.success(f"ğŸ¯ æˆäº¤å•æ•°: **{len(df_res)}**")
                    
                    st.markdown(f"### ğŸ“Š V31 å›æµ‹ (RSIä½ä½+èš‚èšä¸Šæ ‘)")
                    cols = st.columns(5)
                    days = ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']
                    for idx, d in enumerate(days):
                         if d in df_res.columns:
                             avg = df_res[d].mean()
                             if d == 'D+1':
                                 rate = (df_res[d] > 0).mean() * 100
                                 cols[idx].metric(f"{d} èƒœç‡", f"{rate:.1f}%")
                             cols[idx].metric(f"{d} å‡æ”¶", f"{avg:.2f}%")
                    
                    st.dataframe(df_res.sort_values(['ä¿¡å·æ—¥'], ascending=False), use_container_width=True)
                else:
                    st.warning("æ— æˆäº¤ã€‚")
            else:
                st.warning("æ— ä¿¡å·ã€‚")
        else:
            st.error(info)
