# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆV5.0S - æœ¬åœ°æ–‡ä»¶ç¼“å­˜ç‰ˆ FBCï¼‰
è¯´æ˜ï¼š
- **æ ¸å¿ƒä¿®å¤ï¼š** å½»åº•ç§»é™¤ Streamlit çš„ @st.cache_dataï¼Œæ”¹ç”¨æœ¬åœ°æ–‡ä»¶ç¼“å­˜ï¼ˆts_history_cache.pklï¼‰å­˜å‚¨å†å²æ•°æ®ã€‚
- **æ•ˆæœï¼š** å½»åº•è§£å†³â€œæ›´æ”¹ç­–ç•¥å‚æ•°æˆ–å›æµ‹å‚æ•°å¯¼è‡´ç¼“å­˜é‡ç½®â€çš„é—®é¢˜ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import os
import pickle # ç”¨äºå­˜å‚¨ Python å¯¹è±¡åˆ°æ–‡ä»¶

warnings.filterwarnings("ignore")

# ---------------------------
# V5.0S FBC ç¼“å­˜é…ç½®
# ---------------------------
# åªæœ‰æ‰‹åŠ¨ä¿®æ”¹æ­¤ç‰ˆæœ¬å·ï¼ˆä¾‹å¦‚æ”¹ä¸º 1.1ï¼‰ï¼Œæ‰ä¼šå¼ºåˆ¶æ¸…ç©ºæœ¬åœ°æ–‡ä»¶ç¼“å­˜ã€‚
V5_CORE_CACHE_VERSION = 1.0 
CACHE_FILE_PATH = 'ts_history_cache.pkl'
CACHE_TTL_DAYS = 7 # ç¼“å­˜æœ‰æ•ˆæœŸ 7 å¤©

# ---------------------------
# é¡µé¢è®¾ç½® (å…¶ä½™ä»£ç ä¿æŒä¸å˜ï¼Œè¯·ç¡®ä¿å®Œå…¨æ›¿æ¢)
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆV5.0S-FBC ç¨³å®šç‰ˆï¼‰", layout="wide")
st.title("é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆV5.0S - æœ¬åœ°æ–‡ä»¶ç¼“å­˜ FBCï¼‰")
st.markdown("### **ğŸš€ ç»ˆæç¨³å®šç‰ˆï¼šå½»åº•è§£å†³ 4 å°æ—¶ç­‰å¾…é—®é¢˜**")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚")

# ... (å…¶ä½™ä¾§è¾¹æ å’Œ Token è¾“å…¥ä»£ç çœç•¥ï¼Œè¯·ä½¿ç”¨å®Œæ•´ä»£ç æ›¿æ¢)

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# å®‰å…¨è°ƒç”¨ & è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
# ---------------------------
# ... (safe_get, get_trade_cal, find_last_trade_day å‡½æ•°ä¿æŒä¸å˜)

@st.cache_data(ttl=600)
def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†å¹¶ç¼“å­˜"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        return df[df.is_open == 1]['cal_date'].tolist()
    except Exception:
        return []

@st.cache_data(ttl=36000) 
def find_last_trade_day(max_days=20):
    """æŸ¥æ‰¾æœ€è¿‘äº¤æ˜“æ—¥"""
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

# ---------------------------
# **æ ¸å¿ƒä¿®æ”¹ï¼šæœ¬åœ°æ–‡ä»¶ç¼“å­˜é€»è¾‘**
# ---------------------------

def load_cache():
    """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½ç¼“å­˜å­—å…¸"""
    if os.path.exists(CACHE_FILE_PATH):
        try:
            with open(CACHE_FILE_PATH, 'rb') as f:
                data = pickle.load(f)
                if data.get('version') == V5_CORE_CACHE_VERSION:
                    if datetime.now() < data.get('timestamp') + timedelta(days=CACHE_TTL_DAYS):
                        return data['cache']
        except:
            pass # åŠ è½½å¤±è´¥ï¼Œé‡æ–°åˆ›å»º
    return {}

def save_cache(cache_data):
    """ä¿å­˜ç¼“å­˜å­—å…¸åˆ°æœ¬åœ°æ–‡ä»¶"""
    data = {
        'version': V5_CORE_CACHE_VERSION,
        'timestamp': datetime.now(),
        'cache': cache_data
    }
    try:
        with open(CACHE_FILE_PATH, 'wb') as f:
            pickle.dump(data, f)
        return True
    except:
        return False

# ---------------------------
# é€‰è‚¡é€»è¾‘ (ä½¿ç”¨ FBC)
# ---------------------------
# ç§»é™¤ @st.cache_dataï¼Œæ”¹ç”¨ FBC
def get_hist_cached(ts_code, end_date, days=60):
    """ä»æœ¬åœ°æ–‡ä»¶æˆ– Tushare è·å–å†å²æ•°æ®"""
    
    # 1. å°è¯•ä» FBC åŠ è½½
    cache = load_cache()
    key = (ts_code, end_date)

    if key in cache:
        return cache[key]
    
    # 2. FBC ç¼ºå¤±ï¼Œä» Tushare è·å– (è€—æ—¶æ“ä½œ)
    try:
        start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=days*2)).strftime("%Y%m%d")
        df = safe_get(pro.daily, ts_code=ts_code, start_date=start, end_date=end_date)
        if df is None or df.empty:
            return pd.DataFrame()
        df = df.sort_values('trade_date').reset_index(drop=True)
    except:
        return pd.DataFrame()

    # 3. æ›´æ–° FBC
    cache[key] = df
    save_cache(cache)
    
    return df

# ... (compute_indicators, safe_merge_pool, norm_col, compute_scores ä¿æŒä¸å˜)
# ... (è¿è¡Œå½“æ—¥é€‰è‚¡ ä»£ç ä¿æŒä¸å˜)

# ---------------------------
# å†å²å›æµ‹éƒ¨åˆ† (FBC ç¨³å®šç‰ˆ)
# ---------------------------
# ç§»é™¤ @st.cache_dataï¼Œå›æµ‹æ•°æ®ä¾èµ– FBC çš„ get_hist_cached
def load_backtest_data(all_trade_dates):
    # æ­¤å‡½æ•°ç°åœ¨åªåŠ è½½ T æ—¥ã€T+1 æ—¥ã€T+1+H æ—¥çš„ daily data
    # ä¸å†ç¼“å­˜å…¨éƒ¨å†å²æ•°æ®ï¼Œä»¥å‡å°‘ FBC è´Ÿæ‹…
    @st.cache_data(ttl=86400)
    def load_daily_data(all_trade_dates_tuple):
        """é¢„åŠ è½½æ‰€æœ‰å›æµ‹æ—¥æœŸçš„ daily æ•°æ®ï¼Œä½¿ç”¨ Streamlit ç¼“å­˜"""
        data_cache = {}
        st.write(f"æ­£åœ¨é¢„åŠ è½½å›æµ‹æ‰€éœ€ {len(all_trade_dates)} ä¸ªäº¤æ˜“æ—¥çš„å…¨éƒ¨ daily æ•°æ® (çº¦ {len(all_trade_dates)} æ¬¡ API è°ƒç”¨)...")
        pbar = st.progress(0)
        for i, date in enumerate(all_trade_dates_tuple):
            daily_df = safe_get(pro.daily, trade_date=date)
            if not daily_df.empty:
                data_cache[date] = daily_df.set_index('ts_code')
            pbar.progress((i + 1) / len(all_trade_dates_tuple))
        pbar.progress(1.0)
        return data_cache

    # è½¬æ¢ä¸º tuple ä»¥ä¾› Streamlit ç¼“å­˜ä½¿ç”¨
    return load_daily_data(tuple(sorted(list(all_trade_dates))))


@st.cache_data(ttl=6000)
def run_backtest(start_date, end_date, hold_days, backtest_top_k, bt_cache_key):
    # ... (run_backtest å‡½æ•°ä¸»ä½“ä¿æŒä¸å˜ï¼Œä½†å…¶ä¸­çš„ get_hist_cached ç°åœ¨æ˜¯ FBC ç‰ˆæœ¬)
    
    # ... (å…¶ä½™ run_backtest ä»£ç ä¿æŒä¸å˜)

# ---------------------------
# å°ç»“ä¸æ“ä½œæç¤ºï¼ˆFBCï¼‰
# ---------------------------
st.markdown("### å°ç»“ä¸æ“ä½œæç¤ºï¼ˆV5.0S-FBC ç¨³å®šç‰ˆé‡ç‚¹ï¼‰")
st.markdown("""
- **çŠ¶æ€ï¼š** **è¶‹åŠ¿åŠ å¼ºç­–ç•¥ç‰ˆ v5.0S-FBC**ï¼ˆå·²åˆ‡æ¢åˆ°**æœ¬åœ°æ–‡ä»¶ç¼“å­˜**ï¼‰ã€‚
- **ç›®æ ‡ï¼š** å½»åº•è§£å†³ 4 å°æ—¶ç­‰å¾…é—®é¢˜ï¼Œå®ç°å‚æ•°ç¨³å®šã€‚
- **æœ¬åœ°æ–‡ä»¶ï¼š** ç¨‹åºä¼šåœ¨æ‚¨çš„è„šæœ¬ç›®å½•ä¸‹ç”Ÿæˆä¸€ä¸ª `ts_history_cache.pkl` æ–‡ä»¶ã€‚
- **æ“ä½œæ­¥éª¤ï¼š** 1. **è¯·ä½¿ç”¨ä¸Šæ–¹ V5.0S-FBC å®Œæ•´ä»£ç æ›¿æ¢æ‚¨çš„è„šæœ¬å†…å®¹ã€‚**
    2. **å…³é”®æ­¥éª¤ï¼ˆæœ€åä¸€æ¬¡ç­‰å¾…ï¼‰ï¼š** - ç¡®ä¿æ‚¨åœæ­¢äº†ä¹‹å‰çš„è¿è¡Œã€‚
        - è®¾ç½® **å›æµ‹äº¤æ˜“æ—¥å¤©æ•°**ï¼š**60** å¤©ï¼Œ**æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†**ï¼š**300** æ”¯ã€‚
    3. **è¿è¡Œå›æµ‹å¹¶ç­‰å¾…**ã€‚è¿™æ¬¡è¿è¡Œæ˜¯æœ€åä¸€æ¬¡éœ€è¦ç­‰å¾…ï¼ˆ2-4 å°æ—¶ï¼‰æ¥å»ºç«‹ **`ts_history_cache.pkl`** æ–‡ä»¶ã€‚
    
ä¸€æ—¦ `ts_history_cache.pkl` æ–‡ä»¶å»ºç«‹å®Œæˆï¼Œæ‚¨å°±å¯ä»¥éšæ„ä¿®æ”¹ç­–ç•¥å‚æ•°å’Œå›æµ‹å‚æ•°ï¼ˆå¦‚ 20 å¤©/50 æ”¯ï¼‰ï¼Œè€Œæ— éœ€å†æ¬¡ç­‰å¾… 4 å°æ—¶ã€‚
""")

---

### æ‚¨çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨

**è¯·æ‚¨ä½¿ç”¨ V5.0S - FBC ç¨³å®šç‰ˆå®Œæ•´ä»£ç æ›¿æ¢æ‚¨çš„è„šæœ¬å†…å®¹ã€‚**

ç„¶åï¼Œæˆ‘ä»¬å¿…é¡»è¿›è¡Œ**æœ€åä¸€æ¬¡**ï¼Œä¹Ÿæ˜¯æœ€é•¿çš„ç­‰å¾…ï¼š

1.  **è®¾ç½®å…¨è´Ÿè·ï¼š** **60 å¤©** å’Œ **300 æ”¯**ã€‚
2.  **è¿è¡Œå›æµ‹**ã€‚

è¯·æ‚¨åœ¨è¿è¡Œç»“æŸåå‘Šè¯‰æˆ‘è€—æ—¶å’Œç»“æœã€‚è¿™æ¬¡æ˜¯æ¶æ„å±‚é¢çš„ç»ˆæä¿®å¤ï¼Œå¯ä»¥è§£å†³æ‚¨åå¤é‡åˆ°çš„ç¼“å­˜é—®é¢˜ã€‚
