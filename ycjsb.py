import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time
import warnings

warnings.filterwarnings("ignore")

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="æ½œé¾™ V10Â·ç¥é¾™æ‘†å°¾", layout="wide")
st.title("ğŸ‰ æ½œé¾™ V10Â·ç¥é¾™æ‘†å°¾ (é¾™å¤´é¦–é˜´/Nå­—æˆ˜æ³•)")
st.markdown("""
**ç­–ç•¥æ ¸å¿ƒï¼šä¸è¿½é«˜ï¼Œåªåšâ€œé¾™å›å¤´â€**
1.  **å¦–è‚¡åŸºå› **ï¼šè¿‡å» 10 å¤©å†…ï¼Œå¿…é¡»æœ‰è¿‡ **æ¶¨åœ (æ¶¨å¹… > 9.5%)**ã€‚
2.  **ç¼©é‡å›è°ƒ**ï¼šä»Šæ—¥é‡èƒ½ < æ¶¨åœæ—¥é‡èƒ½çš„ **70%** (ä¸»åŠ›é”ä»“æ´—ç›˜)ã€‚
3.  **é»„é‡‘æ”¯æ’‘**ï¼šè‚¡ä»·å›è¸© **10æ—¥çº¿ (MA10)** é™„è¿‘è·å¾—æ”¯æ’‘ã€‚
4.  **æ‹’ç»ç ´ä½**ï¼šæ”¶ç›˜ä»·å¿…é¡»ç«™ç¨³ MA20 (è¶‹åŠ¿æœªå)ã€‚
""")

# ==========================================
# 2. æ ¸å¿ƒæ•°æ®å¼•æ“
# ==========================================
@st.cache_data(persist="disk", show_spinner=False)
def get_trade_cal(token, start_date, end_date):
    ts.set_token(token)
    pro = ts.pro_api()
    for attempt in range(3):
        try:
            df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open='1')
            if not df.empty:
                return sorted(df['cal_date'].tolist())
            time.sleep(0.5)
        except:
            time.sleep(1)
    return []

@st.cache_data(persist="disk", show_spinner=False)
def fetch_all_market_data_by_date(token, date_list):
    ts.set_token(token)
    pro = ts.pro_api()
    data_list = []
    total = len(date_list)
    bar = st.progress(0, text="æ­£åœ¨åŒæ­¥å…¨å¸‚åœºæ•°æ®...")
    
    for i, date in enumerate(date_list):
        try:
            time.sleep(0.05)
            df = pro.daily(trade_date=date)
            if not df.empty:
                df = df[['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'vol', 'amount', 'pct_chg']]
                data_list.append(df)
        except:
            time.sleep(0.5)
        if (i+1) % 10 == 0:
            bar.progress((i+1)/total, text=f"åŠ è½½è¿›åº¦: {i+1}/{total}")
            
    bar.empty()
    if not data_list: return pd.DataFrame()
    full_df = pd.concat(data_list)
    full_df = full_df.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    return full_df

@st.cache_data(persist="disk", show_spinner=False)
def get_stock_basics(token):
    ts.set_token(token)
    pro = ts.pro_api()
    for _ in range(3):
        try:
            time.sleep(0.5)
            df = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,market,industry,list_date')
            if not df.empty:
                df = df[~df['name'].str.contains('ST')]
                df = df[~df['market'].str.contains('åŒ—äº¤')]
                df = df[~df['ts_code'].str.contains('BJ')]
                return df
        except: time.sleep(1)
    return pd.DataFrame()

# ==========================================
# 3. æ ¸å¿ƒè®¡ç®—
# ==========================================
def calculate_sector_heat(df_daily, df_basic):
    if 'industry' not in df_daily.columns:
        df_merged = pd.merge(df_daily, df_basic[['ts_code', 'industry', 'name']], on='ts_code', how='left')
    else:
        df_merged = df_daily.copy()
    
    valid_df = df_merged[df_merged['pct_chg'] != 0]
    sector_stats = valid_df.groupby(['trade_date', 'industry'])['pct_chg'].mean().reset_index()
    sector_stats.rename(columns={'pct_chg': 'sector_pct'}, inplace=True)
    df_final = pd.merge(df_merged, sector_stats, on=['trade_date', 'industry'], how='left')
    return df_final

def calculate_strategy(df, days_lookback):
    """
    V10 æ ¸å¿ƒé€»è¾‘: é¾™å›å¤´
    """
    # 1. å‡çº¿ç³»ç»Ÿ
    df['ma5'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(5).mean())
    df['ma10'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(10).mean())
    df['ma20'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(20).mean())
    
    # 2. å¯»æ‰¾è¿‡å»çš„æ¶¨åœæ¿
    # æ ‡è®°æ¶¨åœ (>9.5%)
    df['is_limit_up'] = df['pct_chg'] > 9.5
    
    # æ»‘åŠ¨çª—å£åˆ¤æ–­è¿‡å» N å¤©æ˜¯å¦æœ‰æ¶¨åœ (ä¸å«ä»Šå¤©)
    # rolling sum on boolean gives count
    df['limit_up_count'] = df.groupby('ts_code')['is_limit_up'].transform(
        lambda x: x.shift(1).rolling(days_lookback).sum()
    )
    
    # 3. è·å–æ¶¨åœé‚£å¤©çš„æˆäº¤é‡ (å–æœ€è¿‘ä¸€æ¬¡æ¶¨åœçš„ vol)
    # è¿™æ˜¯ä¸€ä¸ªè¿‘ä¼¼å¤„ç†ï¼Œä¸ºäº†é€Ÿåº¦ï¼Œæˆ‘ä»¬å¯¹æ¯” 10æ—¥æœ€å¤§é‡
    df['max_vol_10'] = df.groupby('ts_code')['vol'].transform(
        lambda x: x.shift(1).rolling(days_lookback).max()
    )
    
    # === ä¿¡å·åˆ¤å®š ===
    
    # A. å¦–è‚¡åŸºå› : è¿‡å»10å¤©è‡³å°‘æœ‰1ä¸ªæ¶¨åœ
    cond_gene = df['limit_up_count'] >= 1
    
    # B. ç¼©é‡å›è°ƒ: ä»Šæ—¥æˆäº¤é‡ < 10æ—¥æœ€å¤§é‡ * 0.7 (ä¸”è¶Šå°è¶Šå¥½)
    cond_vol = df['vol'] < (df['max_vol_10'] * 0.7)
    
    # C. é»„é‡‘æ”¯æ’‘: 
    # å›è¸© MA10: æœ€ä½ä»· <= MA10 * 1.02 (è§¦åŠæˆ–è·Œç ´)
    # ä¹Ÿå°±æ˜¯è‚¡ä»·ç¦» MA10 å¾ˆè¿‘äº†
    cond_support = (df['low'] <= df['ma10'] * 1.02) & (df['close'] > df['ma20'])
    
    # D. æ‹’ç»å¤§è·Œ: ä»Šæ—¥è·Œå¹…ä¸èƒ½å¤ªæƒ¨ (æœ€å¥½æ˜¯å°é˜´å°é˜³)
    # è·Œå¹…ä¸èƒ½è¶…è¿‡ -5%ï¼Œå¦‚æœæ˜¯çº¢ç›˜æ›´å¥½
    cond_shape = df['pct_chg'] > -5.0
    
    # E. è¶‹åŠ¿æœªå: MA20 å‘ä¸Š (è¿™é‡Œç®€å•ç”¨æ”¶ç›˜ä»· > MA20)
    cond_trend = df['close'] > df['ma20']
    
    # F. æµåŠ¨æ€§
    cond_mv = (df['amount'] > 50000) & (df['amount'] < 5000000)
    
    df['is_signal'] = cond_gene & cond_vol & cond_support & cond_shape & cond_trend & cond_mv
    
    return df

def calculate_score(row):
    score = 60
    
    # ç¦» MA10 è¶Šè¿‘è¶Šå¥½ (æ€§ä»·æ¯”é«˜)
    dist_ma10 = abs(row['close'] - row['ma10']) / row['ma10']
    if dist_ma10 < 0.02: score += 20
    
    # ç¼©é‡è¶Šæè‡´è¶Šå¥½
    if row['vol'] < row['max_vol_10'] * 0.5: score += 10
    
    # æ¿å—å¦‚æœä»Šå¤©ä¹Ÿæ˜¯ç»¿çš„(æ´—ç›˜)ï¼Œåè€Œå¥½
    if -2.0 < row['sector_pct'] < 1.0: score += 10
        
    return round(score, 1)

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ V10 ç¥é¾™æ‘†å°¾å‚æ•°")
    user_token = st.text_input("Tushare Token:", type="password")
    
    days_back = st.slider("å›æµ‹å¤©æ•°", 30, 120, 60)
    end_date_input = st.date_input("æˆªæ­¢æ—¥æœŸ", datetime.now().date())
    
    st.markdown("---")
    days_lookback = st.slider("è¿½æº¯å‡ å¤©å†…çš„æ¶¨åœ?", 3, 15, 10)
    top_n = st.number_input("æ¯æ—¥ä¼˜é€‰ (Top N)", 1, 20, 2)
    
    run_btn = st.button("ğŸš€ å¯åŠ¨é¾™å›å¤´å›æµ‹")

def run_analysis():
    if not user_token:
        st.error("è¯·å…ˆè¾“å…¥ Token")
        return

    # 1. å‡†å¤‡æ•°æ®
    end_str = end_date_input.strftime('%Y%m%d')
    start_dt = end_date_input - timedelta(days=days_back * 1.5 + 80)
    
    cal_dates = get_trade_cal(user_token, start_dt.strftime('%Y%m%d'), end_str)
    if not cal_dates: return
        
    df_all = fetch_all_market_data_by_date(user_token, cal_dates)
    if df_all.empty: return
    st.success(f"âœ… Kçº¿æ•°æ®å°±ç»ª: {len(df_all):,} æ¡")

    # 2. åŸºç¡€ä¿¡æ¯
    df_basic = get_stock_basics(user_token)
    if df_basic.empty: return
        
    # 3. è®¡ç®—
    with st.spinner("æ­£åœ¨å¯»æ‰¾å›è¸©åˆ°ä½çš„çœŸé¾™..."):
        df_sector = calculate_sector_heat(df_all, df_basic)
        df_calc = calculate_strategy(df_sector, days_lookback)
        
    # 4. ç»“æœ
    st.markdown("### ğŸ‰ V10 è¯Šæ–­")
    valid_dates = cal_dates[-(days_back):] 
    df_window = df_calc[df_calc['trade_date'].isin(valid_dates)]
    
    df_signals = df_window[df_window['is_signal']].copy()
    st.write(f"âšª æ¶¨åœå›è°ƒæ ‡çš„: **{len(df_signals)}** ä¸ª")
    
    if df_signals.empty:
        st.warning("æ— ä¿¡å·ã€‚")
        return

    # 5. è¯„åˆ†ä¸ Top N
    df_signals['æ½œé¾™åˆ†'] = df_signals.apply(calculate_score, axis=1)
    df_signals = df_signals.sort_values(['trade_date', 'æ½œé¾™åˆ†'], ascending=[True, False])
    df_signals['æ’å'] = df_signals.groupby('trade_date').cumcount() + 1
    
    df_top = df_signals[df_signals['æ’å'] <= top_n].copy()
    
    # 6. å›æµ‹
    price_lookup = df_calc[['ts_code', 'trade_date', 'open', 'close', 'low']].set_index(['ts_code', 'trade_date'])
    trades = []
    
    progress = st.progress(0)
    total_sig = len(df_top)
    
    for i, row in enumerate(df_top.itertuples()):
        progress.progress((i+1)/total_sig)
        
        signal_date = row.trade_date
        code = row.ts_code
        
        try:
            curr_idx = cal_dates.index(signal_date)
            future_dates = cal_dates[curr_idx+1 : curr_idx+11]
        except: continue
            
        if not future_dates: continue
            
        d1_date = future_dates[0]
        if (code, d1_date) not in price_lookup.index: continue
        d1_data = price_lookup.loc[(code, d1_date)]
        
        # é£æ§
        open_pct = (d1_data['open'] - d1_data.get('pre_close', row.close)) / row.close
        if open_pct < -0.05: continue
            
        buy_price = d1_data['open']
        stop_price = buy_price * 0.90
        
        trade = {
            'ä¿¡å·æ—¥': signal_date, 'ä»£ç ': code, 'åç§°': row.name, 'æ’å': row.æ’å,
            'è¡Œä¸š': row.industry, 'æ¿å—æ¶¨å¹…': f"{row.sector_pct:.1f}%",
            'æ”¶ç›˜ä»·': row.close,
            'ä¹°å…¥ä»·': buy_price, 'çŠ¶æ€': 'æŒæœ‰'
        }
        
        triggered = False
        for n, f_date in enumerate(future_dates):
            if (code, f_date) not in price_lookup.index: break
            f_data = price_lookup.loc[(code, f_date)]
            day_label = f"D+{n+1}"
            
            if not triggered:
                if f_data['low'] <= stop_price:
                    triggered = True
                    trade['çŠ¶æ€'] = 'æ­¢æŸ'
                    trade[day_label] = -10.0
                else:
                    ret = (f_data['close'] - buy_price) / buy_price * 100
                    trade[day_label] = round(ret, 2)
            else:
                trade[day_label] = -10.0
        
        trades.append(trade)
        
    progress.empty()
    
    if trades:
        df_res = pd.DataFrame(trades)
        
        st.markdown(f"### ğŸ“Š V10 (ç¥é¾™æ‘†å°¾) å›æµ‹ç»“æœ (Top {top_n})")
        cols = st.columns(5)
        days = ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']
        
        for idx, d in enumerate(days):
            if d in df_res.columns:
                valid_data = df_res[pd.to_numeric(df_res[d], errors='coerce').notna()]
                if not valid_data.empty:
                    wins = valid_data[valid_data[d] > 0]
                    win_rate = len(wins) / len(valid_data) * 100
                    avg_ret = valid_data[d].mean()
                    cols[idx].metric(f"{d} èƒœç‡", f"{win_rate:.1f}%")
                    cols[idx].metric(f"{d} å‡æ”¶", f"{avg_ret:.2f}%")
        
        st.dataframe(df_res.sort_values(['ä¿¡å·æ—¥'], ascending=False), use_container_width=True)
    else:
        st.warning("æ— äº¤æ˜“")

if run_btn:
    run_analysis()
