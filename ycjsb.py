# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.25 æ ¸æ­¦å™¨é•¿æœŸç‰ˆ (Only STAR 688 Long-Term)
ç›®æ ‡ï¼šä»…æ‹‰å–ç§‘åˆ›æ¿æ•°æ®ï¼Œè¿›è¡Œ 2-3 å¹´çš„é•¿å‘¨æœŸå›æµ‹ã€‚
æ–°å¢åŠŸèƒ½ï¼šå†…ç½®â€œè¯„åˆ†(Score)æœ‰æ•ˆæ€§åˆ†æâ€ï¼ŒéªŒè¯é«˜åˆ†æ˜¯å¦å¯¹åº”é«˜èƒœç‡ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta

# ---------------------------
# é¡µé¢é…ç½®
# ---------------------------
st.set_page_config(page_title="V30.25 æ ¸æ­¦å™¨é•¿æœŸç‰ˆ", layout="wide")
st.title("ğŸš€ V30.25 æ ¸æ­¦å™¨é•¿æœŸç‰ˆ (Only STAR 688)")
st.markdown("""
**ğŸ¯ å›æµ‹ç›®æ ‡ï¼š**
* **èŒƒå›´ï¼š** ä»…é™ **ç§‘åˆ›æ¿ (688)**ã€‚
* **å‘¨æœŸï¼š** å»ºè®® **750å¤© (çº¦3å¹´)**ã€‚
* **æ ¸å¿ƒéªŒè¯ï¼š** åœ¨å¤§æ ·æœ¬ä¸‹ï¼ŒRank 1 çš„è¯„åˆ† (Score) æ˜¯å¦æ˜¯èƒœç‡çš„åˆ†æ°´å²­ï¼Ÿ
""")

# ---------------------------
# å…¨å±€ç¼“å­˜
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 

@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2)).strftime("%Y%m%d")
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty or 'is_open' not in cal.columns: return []
    return cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()

# ----------------------------------------------------------------------
# æé€Ÿæ•°æ®ä¸‹è½½ (Only 688)
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    
    # æ ¸å¿ƒä¼˜åŒ–ï¼šåªä¿ç•™ 688ï¼Œæå¤§å¹…åº¦å‡å°‘æ•°æ®é‡
    if not daily_df.empty:
        daily_df = daily_df[daily_df['ts_code'].str.startswith('688')]
    if not adj_df.empty:
        adj_df = adj_df[adj_df['ts_code'].str.startswith('688')]
        
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    start_date = (datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    end_date = (datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=25)).strftime("%Y%m%d") 
    
    all_dates = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')['cal_date'].tolist()
    st.info(f"â³ æ­£åœ¨æ‹‰å–ç§‘åˆ›æ¿å…¨å†å²æ•°æ® ({start_date} ~ {end_date})...")

    adj_list, daily_list = [], []
    bar = st.progress(0)
    
    for i, date in enumerate(all_dates):
        try:
            cached = fetch_and_cache_daily_data(date)
            if not cached['adj'].empty: adj_list.append(cached['adj'])
            if not cached['daily'].empty: daily_list.append(cached['daily'])
            # 688æ•°æ®é‡å°ï¼Œå¯ä»¥åˆ·æ–°å¿«ä¸€ç‚¹
            if i % 50 == 0: bar.progress((i+1)/len(all_dates))
        except: continue 
    bar.empty()

    if not adj_list or not daily_list: return False
        
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    daily_raw = pd.concat(daily_list)
    for col in ['open', 'high', 'low', 'close', 'pre_close', 'vol']:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])
    
    latest_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_date:
        GLOBAL_QFQ_BASE_FACTORS = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_date), 'adj_factor'].droplevel(1).to_dict()
    
    return True

def get_qfq_data(ts_code, start_date, end_date):
    base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code)
    if not base_adj: return pd.DataFrame()

    try:
        daily = GLOBAL_DAILY_RAW.loc[(ts_code, slice(start_date, end_date)), :]
        adj = GLOBAL_ADJ_FACTOR.loc[(ts_code, slice(start_date, end_date)), 'adj_factor']
    except: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    
    df = daily.join(adj, how='left').dropna(subset=['adj_factor'])
    factor = df['adj_factor'] / base_adj
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns: df[col] = df[col] * factor
    
    df = df.reset_index()
    df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d')
    return df.set_index('trade_date').sort_index()

# ----------------------------------------------------------------------
# è¯„åˆ†é€»è¾‘
# ----------------------------------------------------------------------
def compute_score(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    df = get_qfq_data(ts_code, start_date, end_date)
    if df.empty or len(df) < 26: return 0
    
    close = df['close']
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=5, adjust=False).mean()
    macd_val = (diff - dea) * 2
    
    score = (macd_val.iloc[-1] / close.iloc[-1]) * 100000
    if pd.isna(score): score = 0
    return score

# ----------------------------------------------------------------------
# å›æµ‹ä¸»é€»è¾‘
# ----------------------------------------------------------------------
def run_backtest_on_date(date, min_price):
    try:
        daily = GLOBAL_DAILY_RAW.xs(date, level='trade_date')
    except KeyError: return None
    if daily.empty: return None
    
    # 1. ä»·æ ¼è¿‡æ»¤
    pool = daily[daily['close'] >= min_price]
    # (æ•°æ®æºæœ¬èº«å·²æ˜¯çº¯è¡€ç§‘åˆ›ï¼Œæ— éœ€å†è¿‡æ»¤æ¿å—)
    
    if pool.empty: return None
    
    # 2. ç²—ç­›
    pool = pool[pool['pct_chg'] > 0].sort_values('pct_chg', ascending=False)
    if len(pool) > 80: pool = pool.head(80)
    
    best_score = -1
    rank1_code = None
    rank1_close = 0
    
    # 3. è®¡ç®— Rank 1
    for row in pool.itertuples():
        score = compute_score(row.Index, date)
        if score > best_score:
            best_score = score
            rank1_code = row.Index
            rank1_close = row.close
            
    if not rank1_code: return None
    
    # 4. æ¨¡æ‹Ÿäº¤æ˜“
    d0 = datetime.strptime(date, "%Y%m%d")
    start_fut = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_fut = (d0 + timedelta(days=20)).strftime("%Y%m%d")
    
    hist = get_qfq_data(rank1_code, start_fut, end_fut)
    
    ret_d1, ret_d3, ret_d5 = np.nan, np.nan, np.nan
    
    if len(hist) >= 1:
        d1_row = hist.iloc[0]
        try:
            d1_raw = GLOBAL_DAILY_RAW.loc[(rank1_code, d1_row.name.strftime("%Y%m%d"))]
            if isinstance(d1_raw, pd.Series):
                open_pct = (d1_raw['open'] / d1_raw['pre_close'] - 1) * 100
            else: open_pct = 0
        except: open_pct = 0
            
        if open_pct > 1.5:
            buy_price = d1_row['open']
            ret_d1 = (d1_row['close'] / buy_price - 1) * 100
            if len(hist) >= 3:
                ret_d3 = (hist.iloc[2]['close'] / buy_price - 1) * 100
            if len(hist) >= 5:
                ret_d5 = (hist.iloc[4]['close'] / buy_price - 1) * 100
            elif len(hist) > 0:
                ret_d5 = (hist.iloc[-1]['close'] / buy_price - 1) * 100
    
    return {
        'Trade_Date': date,
        'ts_code': rank1_code,
        'Close': rank1_close,
        'Score': best_score,
        'Return_D1': ret_d1,
        'Return_D3': ret_d3,
        'Return_D5': ret_d5
    }

# ----------------------------------------------------
# ä¾§è¾¹æ 
# ----------------------------------------------------
with st.sidebar:
    st.header("1. å›æµ‹è®¾ç½®")
    end_date = st.date_input("ç»“æŸæ—¥æœŸ", value=datetime.now().date())
    days_back = int(st.number_input("å›æµ‹å¤©æ•°", value=750, help="750å¤©çº¦ç­‰äº3å¹´")) 
    
    st.markdown("---")
    st.header("2. ç­–ç•¥å‚æ•°")
    MIN_PRICE = st.number_input("æœ€ä½è‚¡ä»· (å…ƒ)", value=20.0)
    
    st.markdown("---")
    TS_TOKEN = st.text_input("Tushare Token", type="password")

if not TS_TOKEN: st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ---------------------------
# ä¸»ç¨‹åº
# ---------------------------
if st.button("ğŸš€ å¯åŠ¨ç§‘åˆ›æ¿é•¿æœŸå‹åŠ›æµ‹è¯•"):
    dates = get_trade_days(end_date.strftime("%Y%m%d"), days_back)
    if not dates: st.stop()
    if not get_all_historical_data(dates): st.stop()
    
    st.success(f"âœ… æ•°æ®å°±ç»ªï¼šOnly 688 | å‘¨æœŸ: {len(dates)} å¤©")
    
    results = []
    bar = st.progress(0)
    
    for i, date in enumerate(dates):
        res = run_backtest_on_date(date, MIN_PRICE)
        if res:
            results.append(res)
        if i % 10 == 0: bar.progress((i+1)/len(dates))
    
    bar.empty()
    
    if not results:
        st.warning("æ— äº¤æ˜“è®°å½•ã€‚")
        st.stop()
        
    df_res = pd.DataFrame(results)
    valid_trades = df_res.dropna(subset=['Return_D1'])
    
    # ---------------------------
    # ç»“æœåˆ†æ
    # ---------------------------
    st.header("ğŸ“Š ç§‘åˆ›æ¿é•¿æœŸç”Ÿå­˜æŠ¥å‘Š (Only 688)")
    st.caption(f"å›æµ‹åŒºé—´: {dates[-1]} è‡³ {dates[0]} | äº¤æ˜“æ¬¡æ•°: {len(valid_trades)}")
    
    col1, col2, col3 = st.columns(3)
    def get_m(col):
        if valid_trades.empty: return 0, 0
        return valid_trades[col].mean(), (valid_trades[col]>0).mean()*100
    
    d1_a, d1_w = get_m('Return_D1')
    d3_a, d3_w = get_m('Return_D3')
    d5_a, d5_w = get_m('Return_D5')
    
    col1.metric("D+1 æ”¶ç›Š/èƒœç‡", f"{d1_a:.2f}% / {d1_w:.1f}%")
    col2.metric("D+3 æ”¶ç›Š/èƒœç‡", f"{d3_a:.2f}% / {d3_w:.1f}%")
    col3.metric("D+5 æ”¶ç›Š/èƒœç‡", f"{d5_a:.2f}% / {d5_w:.1f}%")
    
    # --- è¯„åˆ†æœ‰æ•ˆæ€§åˆ†æ (æ ¸å¿ƒåŠŸèƒ½) ---
    st.markdown("---")
    st.subheader("ğŸ” è¯„åˆ†(Score)æœ‰æ•ˆæ€§éªŒè¯")
    st.markdown("å°†æ‰€æœ‰äº¤æ˜“æŒ‰åˆ†æ•°åˆ†ä¸º 4 ç»„ (Q1ä½åˆ† -> Q4é«˜åˆ†)ï¼ŒæŸ¥çœ‹é«˜åˆ†æ˜¯å¦çœŸçš„å¯¹åº”é«˜èƒœç‡ï¼š")
    
    if len(valid_trades) >= 4:
        valid_trades['Score_Group'] = pd.qcut(valid_trades['Score'], 4, labels=['Q1 (ä½åˆ†åŒº)', 'Q2 (ä¸­ä½åŒº)', 'Q3 (ä¸­é«˜åŒº)', 'Q4 (é«˜åˆ†åŒº)'])
        score_stats = valid_trades.groupby('Score_Group')[['Return_D1', 'Return_D5']].agg(['count', 'mean', lambda x: (x>0).mean()*100])
        score_stats.columns = ['äº¤æ˜“æ¬¡æ•°', 'D1å¹³å‡æ”¶ç›Š', 'D1èƒœç‡', 'D5äº¤æ˜“æ¬¡æ•°', 'D5å¹³å‡æ”¶ç›Š', 'D5èƒœç‡']
        # ç®€åŒ–å±•ç¤º
        score_show = score_stats[['äº¤æ˜“æ¬¡æ•°', 'D1å¹³å‡æ”¶ç›Š', 'D1èƒœç‡', 'D5å¹³å‡æ”¶ç›Š', 'D5èƒœç‡']]
        st.dataframe(score_show.style.format("{:.2f}"))
        
        # å¯»æ‰¾æœ€ä½³é˜ˆå€¼
        median_score = valid_trades['Score'].median()
        high_score_trades = valid_trades[valid_trades['Score'] > median_score]
        high_win = (high_score_trades['Return_D1'] > 0).mean() * 100
        high_ret = high_score_trades['Return_D1'].mean()
        
        st.info(f"ğŸ’¡ **æ•°æ®æ´å¯Ÿï¼š** å¦‚æœåªåšåˆ†æ•°é«˜äºä¸­ä½æ•° ({median_score:.0f}) çš„äº¤æ˜“ï¼š\n"
                f"- D+1 èƒœç‡å°†å˜ä¸º **{high_win:.1f}%**\n"
                f"- D+1 å¹³å‡æ”¶ç›Šå°†å˜ä¸º **{high_ret:.2f}%**")
    else:
        st.warning("äº¤æ˜“æ ·æœ¬å¤ªå°‘ï¼Œæ— æ³•è¿›è¡Œåˆ†ç»„åˆ†æã€‚")
        
    st.subheader("ğŸ“‹ è¯¦ç»†äº¤æ˜“å•")
    # æ ¼å¼åŒ–
    display_df = df_res.copy()
    cols_to_round = ['Close', 'Score', 'Return_D1', 'Return_D3', 'Return_D5']
    display_df[cols_to_round] = display_df[cols_to_round].round(2)
    st.dataframe(display_df, use_container_width=True)
    
    csv = df_res.to_csv().encode('utf-8')
    st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´æ•°æ®", csv, "star_long_term_export.csv", "text/csv")
