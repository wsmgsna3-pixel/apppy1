# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆV5.0S - æ‰¹é‡æ•°æ®è·å– BDF æœ€ç»ˆç¨³å®šç‰ˆï¼‰
è¯´æ˜ï¼š
- **æ ¸å¿ƒæ¶æ„ï¼š** æ‰¹é‡æ•°æ®è·å–ï¼ˆBDFï¼‰ï¼Œå°†æ•°æ®åŠ è½½æ—¶é—´ç¼©çŸ­åˆ°åˆ†é’Ÿçº§ã€‚
- **è¯­æ³•ä¿®å¤ï¼š** ç§»é™¤äº† run_backtest å‡½æ•°ä¸­é”™è¯¯çš„ global å£°æ˜ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings("ignore")

# ---------------------------
# V5.0S BDF é…ç½®
# ---------------------------
# æ•°æ®åŠ è½½ç¼“å­˜é”®ï¼ˆç”¨äº Streamlit ç¼“å­˜æ‰¹é‡æ•°æ®ï¼‰
BDF_CACHE_KEY = 2.0 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ Â· 10000æ——èˆ°ï¼ˆV5.0S-BDF ç¨³å®šç‰ˆï¼‰", layout="wide")
st.title("é€‰è‚¡ç‹ Â· 10000 ç§¯åˆ†æ——èˆ°ï¼ˆV5.0S - æ‰¹é‡æ•°æ®è·å– BDFï¼‰")
st.markdown("### ğŸš€ ç»ˆæç¨³å®šç‰ˆï¼šæ•°æ®è·å–é€Ÿåº¦æå‡è‡³åˆ†é’Ÿçº§")
st.markdown("è¾“å…¥ä½ çš„ Tushare Tokenï¼ˆä»…æœ¬æ¬¡è¿è¡Œä½¿ç”¨ï¼‰ã€‚")

# ---------------------------
# ä¾§è¾¹æ å‚æ•°ï¼ˆå®æ—¶å¯æ”¹ï¼‰
# ---------------------------
with st.sidebar:
    st.header("å¯è°ƒå‚æ•°ï¼ˆç­–ç•¥æ ¸å¿ƒï¼‰")
    INITIAL_TOP_N = int(st.number_input("åˆç­›ï¼šæ¶¨å¹…æ¦œå–å‰ N", value=1000, step=100))
    FINAL_POOL = int(st.number_input("æ¸…æ´—åå–å‰ M è¿›å…¥è¯„åˆ†", value=300, step=50))
    TOP_DISPLAY = int(st.number_input("ç•Œé¢æ˜¾ç¤º Top K", value=30, step=5))
    MIN_PRICE = float(st.number_input("æœ€ä½ä»·æ ¼ (å…ƒ)", value=10.0, step=1.0))
    MAX_PRICE = float(st.number_input("æœ€é«˜ä»·æ ¼ (å…ƒ)", value=200.0, step=10.0))
    MIN_TURNOVER = float(st.number_input("æœ€ä½æ¢æ‰‹ç‡ (%)", value=3.0, step=0.5))
    MIN_AMOUNT = float(st.number_input("æœ€ä½æˆäº¤é¢ (å…ƒ)", value=100_000_000.0, step=50_000_000.0)) # é»˜è®¤ 1äº¿
    VOL_SPIKE_MULT = float(st.number_input("æ”¾é‡å€æ•°é˜ˆå€¼ (vol_last > vol_ma5 * x)", value=1.7, step=0.1))
    VOLATILITY_MAX = float(st.number_input("è¿‡å»10æ—¥æ³¢åŠ¨ std é˜ˆå€¼ (%)", value=12.0, step=0.5))
    HIGH_PCT_THRESHOLD = float(st.number_input("è§†ä¸ºå¤§é˜³çº¿ pct_chg (%)", value=6.0, step=0.5))
    MIN_MARKET_CAP = float(st.number_input("æœ€ä½å¸‚å€¼ (å…ƒ)", value=2000000000.0, step=100000000.0)) # é»˜è®¤ 20äº¿
    MAX_MARKET_CAP = float(st.number_input("æœ€é«˜å¸‚å€¼ (å…ƒ)", value=50000000000.0, step=1000000000.0)) # é»˜è®¤ 500äº¿
    
    st.markdown("---")
    # --- å†å²å›æµ‹å‚æ•° ---
    st.header("å†å²å›æµ‹å‚æ•°")
    BACKTEST_DAYS = int(st.number_input("å›æµ‹äº¤æ˜“æ—¥å¤©æ•°", value=60, min_value=10, max_value=250))
    BACKTEST_TOP_K = int(st.number_input("å›æµ‹æ¯æ—¥æœ€å¤šäº¤æ˜“ K æ”¯", value=3, min_value=1, max_value=10))
    HOLD_DAYS_OPTIONS = st.multiselect("å›æµ‹æŒè‚¡å¤©æ•°", options=[1, 3, 5, 10, 20], default=[1, 3, 5])
    # æ–°å¢å‚æ•°ï¼Œç”¨äºå¼ºåˆ¶å›æµ‹ç»“æœç¼“å­˜å¤±æ•ˆ
    BT_CACHE_KEY = float(st.number_input("å›æµ‹ï¼šç¼“å­˜ç ´åé”®ï¼ˆä»»æ„æ”¹åŠ¨åˆ·æ–°å›æµ‹ï¼‰", value=1.25, step=0.01))
    st.caption("æç¤ºï¼šæœ¬æ¬¡å›æµ‹ä¸º **T+1 æ—¥å¼€ç›˜ä»·ä¹°å…¥** è¶‹åŠ¿ç­–ç•¥ã€‚")

# ---------------------------
# Token è¾“å…¥ï¼ˆä¸»åŒºï¼‰
# ---------------------------
TS_TOKEN = st.text_input("Tushare Tokenï¼ˆè¾“å…¥åæŒ‰å›è½¦ï¼‰", type="password")
if not TS_TOKEN:
    st.warning("è¯·è¾“å…¥ Tushare Token æ‰èƒ½è¿è¡Œè„šæœ¬ã€‚")
    st.stop()

# åˆå§‹åŒ– tushare
ts.set_token(TS_TOKEN)
pro = ts.pro_api()

# ---------------------------
# å®‰å…¨è°ƒç”¨ & ç¼“å­˜è¾…åŠ©
# ---------------------------
def safe_get(func, **kwargs):
    """Call API and return DataFrame or empty df on any error."""
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame()
        return df
    except Exception:
        return pd.DataFrame()

@st.cache_data(ttl=600)
def get_trade_cal(start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å†å¹¶ç¼“å­˜"""
    try:
        df = pro.trade_cal(exchange='', start_date=start_date, end_date=end_date)
        return df[df.is_open == 1]['cal_date'].tolist()
    except Exception:
        return []

@st.cache_data(ttl=36000) 
def find_last_trade_day(max_days=20):
    """æŸ¥æ‰¾æœ€è¿‘äº¤æ˜“æ—¥"""
    today = datetime.now().date()
    for i in range(max_days):
        d = today - timedelta(days=i)
        ds = d.strftime("%Y%m%d")
        df = safe_get(pro.daily, trade_date=ds)
        if not df.empty:
            return ds
    return None

last_trade = find_last_trade_day()
if not last_trade:
    st.error("æ— æ³•æ‰¾åˆ°æœ€è¿‘äº¤æ˜“æ—¥ï¼Œæ£€æŸ¥ç½‘ç»œæˆ– Token æƒé™ã€‚")
    st.stop()
st.info(f"å‚è€ƒæœ€è¿‘äº¤æ˜“æ—¥ï¼š{last_trade}")

# ---------------------------
# **æ ¸å¿ƒä¿®æ”¹ï¼šæ‰¹é‡æ•°æ®è·å– (BDF)**
# ---------------------------

@st.cache_data(ttl=86400)
def bulk_fetch_daily_data(trade_dates_tuple, bdf_key):
    """
    ä¸€æ¬¡æ€§æ‰¹é‡è·å–æ‰€æœ‰å›æµ‹æ—¥æœŸå†…çš„å…¨å¸‚åœº daily æ•°æ®ã€‚
    """
    _ = bdf_key # ç”¨äºæ‰‹åŠ¨åˆ·æ–°æ•°æ®ç¼“å­˜
    data_cache = {}
    st.write(f"æ­£åœ¨æ‰¹é‡è·å– {len(trade_dates_tuple)} ä¸ªäº¤æ˜“æ—¥çš„ daily æ•°æ® (çº¦ {len(trade_dates_tuple)} æ¬¡ API è°ƒç”¨)...")
    pbar = st.progress(0)
    
    for i, date in enumerate(trade_dates_tuple):
        # æ‰¹é‡è·å– Tushare çš„ daily æ•°æ®ï¼ˆå…¨å¸‚åœºï¼‰
        daily_df = safe_get(pro.daily, trade_date=date)
        if not daily_df.empty:
            data_cache[date] = daily_df
        pbar.progress((i + 1) / len(trade_dates_tuple))
    
    pbar.progress(1.0)
    st.success("æ‰¹é‡æ•°æ®åŠ è½½å®Œæˆï¼Œè€—æ—¶åº”åœ¨åˆ†é’Ÿçº§ã€‚")
    return data_cache

# ---------------------------
# **æ ¸å¿ƒä¿®æ”¹ï¼šå†å²æ•°æ®æå– (ä½¿ç”¨ BDF ç¼“å­˜)**
# ---------------------------

# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨æ‰¹é‡æ•°æ®
ALL_DAILY_DATA_CACHE = None 

def get_hist_from_bulk(ts_code, end_date, days=60, trade_dates_list=None):
    """
    ä»å…¨å±€çš„ ALL_DAILY_DATA_CACHE ä¸­æå–å•ç¥¨å†å²æ•°æ®ã€‚
    """
    global ALL_DAILY_DATA_CACHE
    
    if ALL_DAILY_DATA_CACHE is None or not trade_dates_list:
        return pd.DataFrame()
    
    # æ‰¾åˆ°æ‰€æœ‰éœ€è¦çš„æ—¥æœŸ
    end_date_index = trade_dates_list.index(end_date)
    # ç•™è¶³å†—ä½™ï¼Œç¡®ä¿èƒ½è¦†ç›– days å‚æ•°æ‰€éœ€
    start_index = max(0, end_date_index - days * 2) 
    
    required_dates = trade_dates_list[start_index:end_date_index + 1]
    
    history_list = []
    
    for date in required_dates:
        daily_df = ALL_DAILY_DATA_CACHE.get(date)
        if daily_df is not None:
            # åœ¨å…¨å¸‚åœºæ•°æ®ä¸­æŸ¥æ‰¾è¿™åªè‚¡ç¥¨
            stock_data = daily_df[daily_df['ts_code'] == ts_code]
            if not stock_data.empty:
                history_list.append(stock_data.iloc[0])

    if not history_list:
        return pd.DataFrame()
        
    return pd.DataFrame(history_list).sort_values('trade_date').reset_index(drop=True)

# ---------------------------
# é€‰è‚¡é€»è¾‘è¾…åŠ©å‡½æ•°
# ---------------------------
def compute_indicators(df):
    """è®¡ç®— MA/MACD/KDJ/é‡æ¯”ç­‰æŒ‡æ ‡"""
    res = {}
    if df.empty or len(df) < 3:
        return res
    close = df['close'].astype(float)
    high = df['high'].astype(float)
    low = df['low'].astype(float)

    # last close
    try: res['last_close'] = close.iloc[-1]
    except: res['last_close'] = np.nan

    # MA
    for n in (5,10,20):
        if len(close) >= n:
            res[f'ma{n}'] = close.rolling(window=n).mean().iloc[-1]
        else:
            res[f'ma{n}'] = np.nan

    # MACD (12,26,9)
    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean()
        ema26 = close.ewm(span=26, adjust=False).mean()
        diff = ema12 - ema26
        dea = diff.ewm(span=9, adjust=False).mean()
        macd_val = (diff - dea) * 2
        res['macd'] = macd_val.iloc[-1]; res['diff'] = diff.iloc[-1];
        res['dea'] = dea.iloc[-1]
    else:
        res['macd'] = res['diff'] = res['dea'] = np.nan

    # KDJ
    n = 9
    if len(close) >= n:
        low_n = low.rolling(window=n).min()
        high_n = high.rolling(window=n).max()
        rsv = (close - low_n) / (high_n - low_n + 1e-9) * 100
        rsv = rsv.fillna(50)
        k = rsv.ewm(alpha=1/3, adjust=False).mean()
        d = k.ewm(alpha=1/3, adjust=False).mean()
        j = 3*k - 2*d
        res['k'] = k.iloc[-1]; res['d'] = d.iloc[-1];
        res['j'] = j.iloc[-1]
    else:
        res['k'] = res['d'] = res['j'] = np.nan

    # vol ratio and metrics
    vols = df['vol'].astype(float).tolist()
    if len(vols) >= 6:
        avg_prev5 = np.mean(vols[-6:-1])
        res['vol_ratio'] = vols[-1] / (avg_prev5 + 1e-9)
        res['vol_last'] = vols[-1]
        res['vol_ma5'] = avg_prev5
    else:
        res['vol_ratio'] = res['vol_last'] = res['vol_ma5'] = np.nan

    # 10d return
    if len(close) >= 10:
        res['10d_return'] = close.iloc[-1] / close.iloc[-10] - 1
    else:
        res['10d_return'] = np.nan

    # prev3_sum for down-then-bounce detection
    if 'pct_chg' in df.columns and len(df) >= 4:
        try:
            pct = df['pct_chg'].astype(float)
            res['prev3_sum'] = pct.iloc[-4:-1].sum()
        except:
            res['prev3_sum'] = np.nan
    else:
        res['prev3_sum'] = np.nan

    # volatility (std of last 10 pct_chg)
    try:
        if 'pct_chg' in df.columns and len(df) >= 10:
            res['volatility_10'] = df['pct_chg'].astype(float).tail(10).std()
        else:
            res['volatility_10'] = np.nan
    except:
        res['volatility_10'] = np.nan

    # recent 20-day high for breakout detection
    try:
        if len(high) >= 20:
            res['recent20_high'] = float(high.tail(20).max())
        else:
            res['recent20_high'] = float(high.max()) if len(high)>0 else np.nan
    except:
        res['recent20_high'] = np.nan

    
    # é˜³çº¿å®ä½“å¼ºåº¦ï¼ˆä»Šå¤©ï¼‰
    try:
        today_open = df['open'].astype(float).iloc[-1]
        today_close = df['close'].astype(float).iloc[-1]
        today_high = df['high'].astype(float).iloc[-1]
        today_low = df['low'].astype(float).iloc[-1]
        body = abs(today_close - today_open)
        rng = max(today_high - today_low, 1e-9)
        res['yang_body_strength'] = body / rng
    except:
        res['yang_body_strength'] = 0.0

    return res

def safe_merge_pool(pool_df, other_df, cols):
    """å®‰å…¨åˆå¹¶æ•°æ®"""
    pool = pool_df.set_index('ts_code').copy()
    
    if other_df is None or other_df.empty:
        for c in cols:
            pool[c] = np.nan
        return pool.reset_index()
    if 'ts_code' not in other_df.columns:
        try:
            other_df = other_df.reset_index()
        except:
            for c in cols:
                pool[c] = np.nan
            return pool.reset_index()
    for c in cols:
        if c not in other_df.columns:
            other_df[c] = np.nan
    try:
        joined = pool.join(other_df.set_index('ts_code')[cols], how='left')
    except Exception:
        for c in cols:
            pool[c] = np.nan
        return pool.reset_index()
    for c in cols:
        if c not in joined.columns:
            joined[c] = np.nan
    return joined.reset_index()

def norm_col(s):
    """å½’ä¸€åŒ–æ•°æ®"""
    s = s.fillna(0.0).replace([np.inf,-np.inf], np.nan).fillna(0.0)
    mn = s.min(); mx = s.max()
    if mx - mn < 1e-9:
        return pd.Series([0.5]*len(s), index=s.index)
    return (s - mn) / (mx - mn)

# ---------------------------
# é€‰è‚¡é€»è¾‘ä¸»å‡½æ•° (ä½¿ç”¨ BDF)
# ---------------------------
def compute_scores(trade_date, trade_dates_list):
    """
    è¿è¡Œ T æ—¥çš„é€‰è‚¡ã€æ¸…æ´—å’Œè¯„åˆ†é€»è¾‘ï¼Œè·å–ç»¼åˆè¯„åˆ†ã€‚
    """
    global ALL_DAILY_DATA_CACHE
    
    # ---------------------------
    # 1. æ‹‰å½“æ—¥æ¶¨å¹…æ¦œåˆç­›ï¼ˆä½¿ç”¨ BDF ç¼“å­˜ï¼‰
    # ---------------------------
    daily_all_raw = ALL_DAILY_DATA_CACHE.get(trade_date)
    if daily_all_raw is None or daily_all_raw.empty:
        # å¦‚æœå½“æ—¥æ•°æ®ç¼“å­˜ç¼ºå¤±ï¼Œå°è¯•ç›´æ¥ä» Tushare è·å–ï¼ˆä»…åœ¨å®æ—¶é€‰è‚¡æ—¶æœ‰ç”¨ï¼‰
        daily_all = safe_get(pro.daily, trade_date=trade_date)
    else:
        daily_all = daily_all_raw.copy()
        
    if daily_all.empty:
        return pd.DataFrame()

    daily_all = daily_all.sort_values("pct_chg", ascending=False).reset_index(drop=True)
    pool0 = daily_all.head(int(INITIAL_TOP_N)).copy().reset_index(drop=True)

    # ---------------------------
    # 2. å°è¯•åŠ è½½é«˜çº§æ¥å£
    # ---------------------------
    stock_basic = safe_get(pro.stock_basic, list_status='L', fields='ts_code,name,industry,list_date,total_mv,circ_mv')
    daily_basic = safe_get(pro.daily_basic, trade_date=trade_date, fields='ts_code,turnover_rate,amount,total_mv,circ_mv')
    mf_raw = safe_get(pro.moneyflow, trade_date=trade_date)
    
    # moneyflow é¢„å¤„ç†
    moneyflow = pd.DataFrame(columns=['ts_code','net_mf'])
    if not mf_raw.empty:
        possible = ['net_mf','net_mf_amount','net_mf_in','net_mf_out']
        col = None
        for c in possible:
            if c in mf_raw.columns:
                col = c; break
        if col:
            moneyflow = mf_raw[['ts_code', col]].rename(columns={col:'net_mf'}).fillna(0)
        
    # merge stock_basic
    if not stock_basic.empty:
        keep = [c for c in ['ts_code','name','industry','total_mv','circ_mv'] if c in stock_basic.columns]
        try:
            pool0 = pool0.merge(stock_basic[keep], on='ts_code', how='left')
        except Exception:
            pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
    else:
        pool0['name'] = pool0['ts_code']; pool0['industry'] = ''
        
    # merge daily_basic
    pool_merged = safe_merge_pool(pool0, daily_basic, ['turnover_rate','amount','total_mv','circ_mv'])
    pool_merged.rename(columns={'amount': 'amount_basic'}, inplace=True) # daily_basicçš„amount
    
    # merge moneyflow robustly
    if moneyflow.empty:
        moneyflow = pd.DataFrame({'ts_code': pool_merged['ts_code'].tolist(), 'net_mf': [0.0]*len(pool_merged)})
    else:
        if 'ts_code' not in moneyflow.columns:
            moneyflow['ts_code'] = None
    try:
        pool_merged = pool_merged.set_index('ts_code').join(moneyflow.set_index('ts_code'), how='left').reset_index()
    except Exception:
        if 'net_mf' not in pool_merged.columns:
            pool_merged['net_mf'] = 0.0

    if 'net_mf' not in pool_merged.columns:
        pool_merged['net_mf'] = 0.0
    pool_merged['net_mf'] = pool_merged['net_mf'].fillna(0.0)
    
    # ---------------------------
    # 3. åŸºæœ¬æ¸…æ´—
    # ---------------------------
    clean_list = []
    # ç»Ÿä¸€ä½¿ç”¨ daily é‡Œçš„ amountï¼ˆå•ä½åƒå…ƒï¼‰ å’Œ daily_basic é‡Œçš„ turnover_rateï¼ˆå•ä½ %ï¼‰
    for i, r in enumerate(pool_merged.itertuples()):
        ts = getattr(r, 'ts_code')
        vol = getattr(r, 'vol', 0)

        close = getattr(r, 'close', np.nan)
        open_p = getattr(r, 'open', np.nan)
        pre_close = getattr(r, 'pre_close', np.nan)
        pct = getattr(r, 'pct_chg', np.nan)
        amount_daily = getattr(r, 'amount', np.nan) # daily é‡Œçš„ amount
        turnover = getattr(r, 'turnover_rate', np.nan)
        name = getattr(r, 'name', ts)

    
        # 1. è¿‡æ»¤ï¼šåœç‰Œ/æ— æˆäº¤
        if vol == 0 or (isinstance(amount_daily,(int,float)) and amount_daily == 0):
            continue

        # 2. è¿‡æ»¤ï¼šä»·æ ¼åŒºé—´
        if pd.isna(close): 
            continue
        if (close < MIN_PRICE) or (close > MAX_PRICE): 
            continue

        # 3. è¿‡æ»¤ï¼šST / é€€å¸‚ / åŒ—äº¤æ‰€
        if isinstance(name, str) and (('ST' in name.upper()) or ('é€€' in name)):
            continue
        tsck = getattr(r, 'ts_code', '')
        if isinstance(tsck, str) and (tsck.startswith('4') or tsck.startswith('8')):
            continue

        # 4. è¿‡æ»¤ï¼šå¸‚å€¼ï¼ˆå…¼å®¹ä¸‡å…ƒå•ä½ï¼‰
        try:
            tv = getattr(r, 'total_mv', np.nan)
            if not pd.isna(tv):
                tv = float(tv)
                if tv > 1e6:
                    tv_yuan = tv * 10000.0
                else:
                    tv_yuan = tv
                if tv_yuan < MIN_MARKET_CAP or tv_yuan > MAX_MARKET_CAP:
                    continue
        except:
            pass # å‘ç”Ÿå¼‚å¸¸æ—¶ä¸è¿‡æ»¤

        # 5. è¿‡æ»¤ï¼šä¸€å­—æ¶¨åœæ¿
        try:
            high = getattr(r, 'high', np.nan); low = getattr(r, 'low', np.nan)
            if (not pd.isna(open_p) and not pd.isna(high) and not pd.isna(low) and not pd.isna(pre_close)):
                if (open_p == high == low == pre_close) and (pct > 9.5):
                    continue
        except:
            pass # å‘ç”Ÿå¼‚å¸¸æ—¶ä¸è¿‡æ»¤

        # 6. è¿‡æ»¤ï¼šæ¢æ‰‹ç‡
        if not pd.isna(turnover):
            try:
                if float(turnover) < MIN_TURNOVER: 
                    continue
            except:
                pass # å‘ç”Ÿå¼‚å¸¸æ—¶ä¸è¿‡æ»¤

        # 7. è¿‡æ»¤ï¼šæˆäº¤é¢ï¼ˆä¿®æ­£å•ä½ï¼šdaily amountæ˜¯åƒå…ƒï¼‰
        if not pd.isna(amount_daily):
            amt = amount_daily * 1000.0 # è½¬æ¢æˆå…ƒ
            if amt < MIN_AMOUNT: 
                continue

        # 8. è¿‡æ»¤ï¼šT æ—¥æ”¶é˜³è¿‡æ»¤
        try:
            if float(pct) < 0: 
                continue
        except:
            pass # å‘ç”Ÿå¼‚å¸¸æ—¶ä¸è¿‡æ»¤
            
        clean_list.append(r)
        
    clean_df = pd.DataFrame([dict(zip(r._fields, r)) for r in clean_list])
    if clean_df.empty:
        return pd.DataFrame()

    # ---------------------------
    # 4. è¯„åˆ†æ± é€ç¥¨è®¡ç®—å› å­
    # ---------------------------
    # ä¸ºäº†å›æµ‹æ€§èƒ½ï¼Œè¿™é‡Œåªå–å‰ FINAL_POOL è‚¡ç¥¨è®¡ç®—æŒ‡æ ‡
    clean_df = clean_df.sort_values("pct_chg", ascending=False).head(FINAL_POOL).copy()
    
    records = []
    for idx, row in enumerate(clean_df.itertuples()):
        ts_code = getattr(row, 'ts_code')
        name = getattr(row, 'name', ts_code)
        pct_chg = getattr(row, 'pct_chg', 0.0)
        
        amount_daily = getattr(row, 'amount', np.nan)
        amount = 0.0
        if amount_daily is not None and not pd.isna(amount_daily):
            amount = amount_daily * 1000.0 # è½¬æ¢æˆå…ƒ

        turnover_rate = getattr(row, 'turnover_rate', np.nan)
        net_mf = float(getattr(row, 'net_mf', 0.0))
        
        # æ ¸å¿ƒï¼šè°ƒç”¨ BDF ç‰ˆæœ¬çš„å†å²æ•°æ®æå–å‡½æ•°
        hist = get_hist_from_bulk(ts_code, trade_date, days=60, trade_dates_list=trade_dates_list)
        ind = compute_indicators(hist)

        vol_ratio = ind.get('vol_ratio', np.nan)
        ten_return = ind.get('10d_return', np.nan)
        ma5 = ind.get('ma5', np.nan)
        ma10 = ind.get('ma10', np.nan)
        ma20 = ind.get('ma20', np.nan)
        macd = ind.get('macd', np.nan)
        diff = ind.get('diff', np.nan)
        dea = ind.get('dea', np.nan)
        k, d, j = ind.get('k', np.nan), ind.get('d', np.nan), ind.get('j', np.nan)
        last_close = ind.get('last_close', np.nan)
        vol_last = ind.get('vol_last', np.nan)
        vol_ma5 = ind.get('vol_ma5', np.nan)
        prev3_sum = ind.get('prev3_sum', np.nan)
        volatility_10 = ind.get('volatility_10', np.nan)
        recent20_high = ind.get('recent20_high', np.nan)
        yang_body_strength = ind.get('yang_body_strength', 0.0)

        # èµ„é‡‘å¼ºåº¦ä»£ç†ï¼ˆä¸ä¾èµ– moneyflowï¼‰ï¼šç®€å•ä¹˜ç§¯æŒ‡æ ‡
        try:
            proxy_money = (abs(pct_chg) + 1e-9) * (vol_ratio if not pd.isna(vol_ratio) else 0.0) * (turnover_rate if not pd.isna(turnover_rate) else 0.0)
        except:
            proxy_money = 0.0

        rec = {
            'ts_code': ts_code, 'name': name, 'pct_chg': pct_chg,
            'amount': amount,
            'turnover_rate': turnover_rate if not pd.isna(turnover_rate) else np.nan,
            'net_mf': net_mf,
            'vol_ratio': vol_ratio if not pd.isna(vol_ratio) else np.nan,
            '10d_return': ten_return if not pd.isna(ten_return) else np.nan,
            'ma5': ma5, 'ma10': ma10, 'ma20': ma20,
            'macd': macd, 'diff': diff, 'dea': dea, 'k': k, 'd': d, 'j': j,
            'last_close': last_close, 'vol_last': vol_last,
            'vol_ma5': vol_ma5, 'recent20_high': recent20_high, 'yang_body_strength': yang_body_strength,
            'prev3_sum': prev3_sum, 'volatility_10': volatility_10,
            'proxy_money': proxy_money
        }

        records.append(rec)
 
    fdf = pd.DataFrame(records)
    if fdf.empty:
        return pd.DataFrame()

    # ---------------------------
    # 5. é£é™©è¿‡æ»¤ (ç­–ç•¥æ ¸å¿ƒéƒ¨åˆ†)
    # ---------------------------
    try:
        # A: é«˜ä½å¤§é˜³çº¿è¿‡æ»¤
        if all(c in fdf.columns for c in ['ma20','last_close','pct_chg']):
            mask_high_big = (fdf['last_close'] > fdf['ma20'] * 1.10) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD)
            fdf = fdf[~mask_high_big]

        # B: ä¸‹è·Œé€”ä¸­åæŠ½è¿‡æ»¤
        if all(c in fdf.columns for c in ['prev3_sum','pct_chg']):
            mask_down_rebound = (fdf['prev3_sum'] < 0) & (fdf['pct_chg'] > HIGH_PCT_THRESHOLD)
            fdf = fdf[~mask_down_rebound]

        # C: å·¨é‡æ”¾é‡å¤§é˜³è¿‡æ»¤
        if 'vol_ratio' in fdf.columns:
            mask_vol_spike = fdf['vol_ratio'] > VOL_SPIKE_MULT
            fdf = fdf[~mask_vol_spike]

        # D: æç«¯æ³¢åŠ¨è¿‡æ»¤
        if 'volatility_10' in fdf.columns:
            mask_volatility = fdf['volatility_10'] > VOLATILITY_MAX
            fdf = fdf[~mask_volatility]
    except:
        pass

    # ---------------------------
    # 7. RSLã€å½’ä¸€åŒ–ä¸è¯„åˆ†
    # ---------------------------
    if '10d_return' in fdf.columns:
        try:
            market_mean_10d = fdf['10d_return'].replace([np.inf,-np.inf], np.nan).dropna().mean()
            if np.isnan(market_mean_10d) or abs(market_mean_10d) < 1e-9:
                market_mean_10d = 1e-9
            fdf['rsl'] = fdf['10d_return'] / market_mean_10d
        except:
            fdf['rsl'] = 1.0
    else:
        fdf['rsl'] = 1.0

    fdf['s_pct'] = norm_col(fdf.get('pct_chg', pd.Series([0]*len(fdf))))
    fdf['s_volratio'] = norm_col(fdf.get('vol_ratio', pd.Series([0]*len(fdf))))
    fdf['s_turn'] = norm_col(fdf.get('turnover_rate', pd.Series([0]*len(fdf))))
    if 'net_mf' in fdf.columns and fdf['net_mf'].abs().sum() > 0:
        fdf['s_money'] = norm_col(fdf.get('net_mf', pd.Series([0]*len(fdf))))
    else:
        fdf['s_money'] = norm_col(fdf.get('proxy_money', pd.Series([0]*len(fdf))))
    fdf['s_amount'] = norm_col(fdf.get('amount', pd.Series([0]*len(fdf))))
    fdf['s_10d'] = norm_col(fdf.get('10d_return', pd.Series([0]*len(fdf))))
    fdf['s_rsl'] = norm_col(fdf.get('rsl', pd.Series([0]*len(fdf))))
    fdf['s_volatility'] = 1 - norm_col(fdf.get('volatility_10', pd.Series([0]*len(fdf))))

    # è¶‹åŠ¿å› å­ä¸å¼ºåŒ–è¯„åˆ†ï¼ˆå³ä¾§è¶‹åŠ¿ä¸»å¯¼ï¼‰
    fdf['ma_trend_flag'] = ((fdf.get('ma5', pd.Series([])) > fdf.get('ma10', pd.Series([]))) & (fdf.get('ma10', pd.Series([])) > fdf.get('ma20', pd.Series([])))).fillna(False)
    fdf['macd_golden_flag'] = (fdf.get('diff', 0) > fdf.get('dea', 0)).fillna(False)
    fdf['vol_price_up_flag'] = (fdf.get('vol_last', 0) > fdf.get('vol_ma5', 0)).fillna(False)
    fdf['break_high_flag'] = (fdf.get('last_close', 0) > fdf.get('recent20_high', 0)).fillna(False)
    fdf['yang_body_strength'] = fdf.get('yang_body_strength', 0.0).fillna(0.0)

    # ç»„åˆæˆè¶‹åŠ¿åŸå§‹åˆ†
    fdf['trend_score_raw'] = (
        fdf['ma_trend_flag'].astype(float) * 1.0 +
        fdf['macd_golden_flag'].astype(float) * 1.3 +
        fdf['vol_price_up_flag'].astype(float) * 1.0 +
        fdf['break_high_flag'].astype(float) * 1.3 +
        fdf['yang_body_strength'].astype(float) * 0.8
    )

    # å½’ä¸€åŒ–è¶‹åŠ¿åˆ†
    fdf['trend_score'] = norm_col(fdf['trend_score_raw'])

    # æœ€ç»ˆç»¼åˆè¯„åˆ†ï¼ˆè¶‹åŠ¿ä¸»å¯¼ï¼‰
    fdf['ç»¼åˆè¯„åˆ†'] = (
        fdf['trend_score'] * 0.40 +
        fdf.get('s_10d', 0)*0.12 +
        fdf.get('s_rsl', 0)*0.08 +
        fdf.get('s_volratio', 0)*0.10 +
        fdf.get('s_turn', 0)*0.05 +
        fdf.get('s_money', 0)*0.10 +
        fdf.get('s_pct', 0)*0.10 +
        fdf.get('s_volatility', 0)*0.05
    )
    
    return fdf


# ---------------------------
# è¿è¡Œå½“æ—¥é€‰è‚¡
# ---------------------------
if st.button("ğŸš€ è¿è¡Œå½“æ—¥é€‰è‚¡ï¼ˆåˆæ¬¡è¿è¡Œå¯èƒ½è¾ƒä¹…ï¼‰"):
    # å®æ—¶é€‰è‚¡ä¹Ÿéœ€è¦å†å²æ•°æ®ï¼Œé¢„åŠ è½½ 120 å¤©æ—¥å†
    temp_start = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=120)).strftime("%Y%m%d")
    temp_trade_dates = get_trade_cal(temp_start, last_trade)
    global ALL_DAILY_DATA_CACHE
    # å®æ—¶é€‰è‚¡ä¾èµ– BDFï¼Œä½†åªåŠ è½½è¿‘æœŸçš„
    ALL_DAILY_DATA_CACHE = bulk_fetch_daily_data(tuple(temp_trade_dates), BDF_CACHE_KEY) 
    
    st.write("æ­£åœ¨æ‹‰å–å½“æ—¥ daily æ•°æ®å¹¶è®¡ç®—è¯„åˆ†...")
    fdf = compute_scores(last_trade, temp_trade_dates)

    if fdf.empty:
        st.error("è¯„åˆ†è®¡ç®—å¤±è´¥æˆ–æ— æ•°æ®ï¼Œè¯·æ£€æŸ¥ Token æƒé™ä¸æ¥å£ã€‚")
        st.stop()

    fdf = fdf.sort_values('ç»¼åˆè¯„åˆ†', ascending=False).reset_index(drop=True)
    fdf.index = fdf.index + 1

    st.success(f"è¯„åˆ†å®Œæˆï¼šæ€»å€™é€‰ {len(fdf)} æ”¯ï¼Œæ˜¾ç¤º Top {min(TOP_DISPLAY, len(fdf))}ã€‚")
    display_cols = ['name','ts_code','ç»¼åˆè¯„åˆ†','pct_chg','vol_ratio','turnover_rate','net_mf','proxy_money','amount','10d_return','macd','diff','dea','k','d','j','rsl','volatility_10']
    for c in display_cols:
        if c not in fdf.columns:
            fdf[c] = np.nan

    st.dataframe(fdf[display_cols].head(TOP_DISPLAY), use_container_width=True)

    # ä¸‹è½½ï¼ˆä»…å¯¼å‡ºå‰200é¿å…è¿‡å¤§ï¼‰
    out_csv = fdf[display_cols].head(200).to_csv(index=True, encoding='utf-8-sig')
    st.download_button("ä¸‹è½½è¯„åˆ†ç»“æœï¼ˆå‰200ï¼‰CSV", data=out_csv, file_name=f"score_result_{last_trade}.csv", mime="text/csv")


# ---------------------------
# å†å²å›æµ‹éƒ¨åˆ†ï¼ˆBDF ç¨³å®šç‰ˆï¼‰
# ---------------------------
@st.cache_data(ttl=6000)
def run_backtest(start_date, end_date, hold_days, backtest_top_k, bt_cache_key):
    # è¿™éƒ¨åˆ†ä»£ç å·²ç¡®ä¿ global å£°æ˜æ­£ç¡®ï¼Œä¸ä¼šå†å‡ºç° SyntaxError
    
    _ = bt_cache_key 

    trade_dates = get_trade_cal(start_date, end_date)
    
    if not trade_dates:
        return {h: {'returns': [], 'wins': 0, 'total': 0, 'win_rate': 0.0, 'avg_return': 0.0} for h in hold_days}

    results = {h: {'returns': [], 'wins': 0, 'total': 0, 'win_rate': 0.0, 'avg_return': 0.0} for h in hold_days}
    
    bt_start = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=BACKTEST_DAYS * 2)).strftime("%Y%m%d")
    buy_dates_pool = [d for d in trade_dates if d >= bt_start and d <= end_date]
    backtest_dates = buy_dates_pool[-BACKTEST_DAYS:]
    
    if len(backtest_dates) < BACKTEST_DAYS:
        st.warning(f"ç”±äºæ•°æ®æˆ–äº¤æ˜“æ—¥é™åˆ¶ï¼Œå›æµ‹ä»…èƒ½è¦†ç›– {len(backtest_dates)} å¤©ã€‚")
    
    # ç¡®å®šå›æµ‹æ‰€éœ€çš„å…¨éƒ¨äº¤æ˜“æ—¥
    required_dates = set(backtest_dates)
    for buy_date in backtest_dates:
        try:
            current_index = trade_dates.index(buy_date)
            for h in hold_days:
                # éœ€è¦ T+1 å’Œ T+1+H çš„ daily æ•°æ®æ¥è®¡ç®—ä¹°å–ä»·
                required_dates.add(trade_dates[current_index + 1]) 
                required_dates.add(trade_dates[current_index + h + 1])
        except (ValueError, IndexError):
            continue
    
    # **æ ¸å¿ƒæ­¥éª¤ï¼šæ‰¹é‡è·å–æ‰€æœ‰å›æµ‹æ—¥æœŸçš„æ•°æ®**
    global ALL_DAILY_DATA_CACHE # å¿…é¡»æ˜¯å‡½æ•°ä¸­çš„ç¬¬ä¸€æ¡è¯­å¥
    ALL_DAILY_DATA_CACHE = bulk_fetch_daily_data(tuple(trade_dates), BDF_CACHE_KEY)

    st.write(f"æ­£åœ¨æ¨¡æ‹Ÿ {len(backtest_dates)} ä¸ªäº¤æ˜“æ—¥çš„é€‰è‚¡å›æµ‹...")
    pbar_bt = st.progress(0)
    
    for i, t_day in enumerate(backtest_dates): # T æ—¥ (é€‰è‚¡æ—¥)
        
        # 1. è¿è¡Œ T æ—¥é€‰è‚¡ä¸è¯„åˆ†é€»è¾‘ (ç°åœ¨ get_hist_from_bulk æ˜¯ç¬æ—¶å®Œæˆçš„)
        t_scores = compute_scores(t_day, trade_dates) 
        
        if t_scores.empty:
            pbar_bt.progress((i+1)/len(backtest_dates)); continue

        # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼Œé€‰æ‹© Top K
        scored_stocks = t_scores.sort_values("ç»¼åˆè¯„åˆ†", ascending=False).head(backtest_top_k).copy()
        
        # 2. ç¡®å®š T+1 ä¹°å…¥æ—¥
        try:
            t_day_index = trade_dates.index(t_day)
            t_plus_1_day = trade_dates[t_day_index + 1]
        except (ValueError, IndexError):
            pbar_bt.progress((i+1)/len(backtest_dates)); continue
        
        # è·å– T+1 æ—¥çš„ daily æ•°æ®
        t_plus_1_df_cached = ALL_DAILY_DATA_CACHE.get(t_plus_1_day)

        for _, row in scored_stocks.iterrows():
            ts_code = row['ts_code']

            # ç¡®å®šä¹°å…¥ä»· (T+1 æ—¥å¼€ç›˜ä»·)
            buy_price = np.nan
            if t_plus_1_df_cached is not None:
                stock_data = t_plus_1_df_cached[t_plus_1_df_cached['ts_code'] == ts_code]
                if not stock_data.empty:
                    buy_price = stock_data['open'].iloc[0]
            
            if pd.isna(buy_price) or buy_price <= 0: continue

            for h in hold_days:
                try:
                    # å–å‡ºæ—¥ï¼šT+1+H (å³ T+1 åçš„ç¬¬ H ä¸ªäº¤æ˜“æ—¥æ”¶ç›˜)
                    sell_date = trade_dates[t_day_index + h + 1] 
                except (ValueError, IndexError):
                    continue
        
                # ä»ç¼“å­˜ä¸­æŸ¥æ‰¾å–å‡ºä»·æ ¼ (T+1+H æ—¥æ”¶ç›˜ä»·)
                sell_df_cached = ALL_DAILY_DATA_CACHE.get(sell_date)
                sell_price = np.nan
                if sell_df_cached is not None:
                    stock_data = sell_df_cached[sell_df_cached['ts_code'] == ts_code]
                    if not stock_data.empty:
                        sell_price = stock_data['close'].iloc[0]
                
                if pd.isna(sell_price) or sell_price <= 0: continue
                
                ret = (sell_price / buy_price) - 1.0
                results[h]['total'] += 1
                results[h]['returns'].append(ret)
                if ret > 0:
                    results[h]['wins'] += 1

        pbar_bt.progress((i+1)/len(backtest_dates))

    pbar_bt.progress(1.0)
    
    final_results = {}
    for h, res in results.items():
        total = res['total']
        if total > 0:
            avg_return = np.mean(res['returns']) * 100.0
            win_rate = (res['wins'] / total) * 100.0
        else:
            avg_return = 0.0
            win_rate = 0.0
       
        final_results[h] = {
            'å¹³å‡æ”¶ç›Šç‡ (%)': f"{avg_return:.2f}",
            'èƒœç‡ (%)': f"{win_rate:.2f}",
            'æ€»äº¤æ˜“æ¬¡æ•°': total
        }
        
    return final_results

# ---------------------------
# å›æµ‹æ‰§è¡Œ
# ---------------------------
if st.checkbox("âœ… è¿è¡Œå†å²å›æµ‹", value=False):
    if not HOLD_DAYS_OPTIONS:
        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå›æµ‹æŒè‚¡å¤©æ•°ã€‚")
    else:
        st.header("ğŸ“ˆ å†å²å›æµ‹ç»“æœï¼ˆV5.0S-BDF ç¨³å®šç‰ˆ / è¶‹åŠ¿ç­–ç•¥ï¼‰")
        
        try:
            start_date_for_cal = (datetime.strptime(last_trade, "%Y%m%d") - timedelta(days=200)).strftime("%Y%m%d")
        except:
            start_date_for_cal = (datetime.now() - timedelta(days=200)).strftime("%Y%m%d")
            
        # æ³¨æ„ï¼šè¿™é‡Œçš„ backtest_top_k æ˜¯åœ¨ run_backtest ç¼“å­˜é”®ä¸­ï¼Œç¡®ä¿å‚æ•°å˜åŠ¨ä¼šåˆ·æ–°å›æµ‹ç»“æœã€‚
        backtest_result = run_backtest(
            start_date=start_date_for_cal,
            end_date=last_trade,
            hold_days=HOLD_DAYS_OPTIONS,
            backtest_top_k=BACKTEST_TOP_K,
            bt_cache_key=BT_CACHE_KEY # ä¼ å…¥å‚æ•°ç¡®ä¿å›æµ‹ç»“æœç¼“å­˜åˆ·æ–°
        )

        bt_df = pd.DataFrame(backtest_result).T
        bt_df.index.name = "æŒè‚¡å¤©æ•°"
        bt_df = bt_df.reset_index()
        bt_df['æŒè‚¡å¤©æ•°'] = bt_df['æŒè‚¡å¤©æ•°'].astype(str) + ' å¤©'
        
        st.dataframe(bt_df, use_container_width=True, hide_index=True)
        st.success("å›æµ‹å®Œæˆï¼")
        
        export_df = bt_df.copy()
        export_df.columns = ['HoldDays', 'AvgReturn', 'WinRate', 'TotalTrades']
        out_csv_bt = export_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            "ä¸‹è½½å›æµ‹ç»“æœ CSV", 
            data=out_csv_bt, 
            file_name=f"backtest_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
