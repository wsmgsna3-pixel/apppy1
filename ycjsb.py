# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V33.0 ç»ˆæå®æˆ˜ç‰ˆ
ç­–ç•¥ï¼šåŒåˆ›ç»„åˆ (688 + 300)
æ ¸å¿ƒé€»è¾‘ï¼š
1. é—¨æ§›ï¼šçº¢ç›˜(>0%) + ä»·æ ¼(20~300) + å¸‚å€¼(30äº¿~800äº¿)ã€‚
2. è¯„åˆ†ï¼šæ•æ·ç‰ˆ MACD (8,17,5) Score æ’åºã€‚
3. å†³ç­–ï¼šT+1æ—¥å¼€ç›˜é«˜å¼€ [+2.0%, +7.5%] ä¹°å…¥ã€‚
4. é£æ§ï¼šTop N ç»„åˆå›æµ‹ï¼Œåˆ†æ•£é£é™©ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import os

# ---------------------------
# é¡µé¢é…ç½®
# ---------------------------
st.set_page_config(page_title="V33.0 ç»ˆæç›‘æ§å°", layout="wide")
st.title("ğŸ›¡ï¸ V33.0 ç»ˆæé€‰è‚¡ç›‘æ§å° (å¸‚å€¼+ä»·æ ¼+çº¢ç›˜è¿‡æ»¤)")

st.markdown("""
> **ç­–ç•¥é…ç½® (V33.0 Consensus):**
> * **é€‰è‚¡æ—¶é—´:** Tæ—¥æ”¶ç›˜å (æ— æœªæ¥å‡½æ•°)ã€‚
> * **ç¡¬æ€§é—¨æ§›:** âœ… **çº¢ç›˜** (`pct_chg > 0`) | âœ… **ä»·æ ¼** 20~300å…ƒ | âœ… **æµå€¼** 30äº¿~800äº¿ã€‚
> * **æ ¸å¿ƒæ’å:** æ•æ· MACD Scoreï¼Œå– **Top N**ã€‚
> * **ä¹°å…¥æ¡ä»¶:** T+1æ—¥ ç«ä»·é«˜å¼€ **[+2.0%, +7.5%]**ã€‚
""")

# ---------------------------
# å…¨å±€ç¼“å­˜
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 
GLOBAL_CALENDAR = [] 
CHECKPOINT_FILE = "v33_checkpoint.csv" # å‡çº§å­˜æ¡£æ–‡ä»¶ï¼Œé¿å…ä¸æ—§ç‰ˆå†²çª

@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        df = func(**kwargs)
        if df is None or (isinstance(df, pd.DataFrame) and df.empty):
            return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    # ç¨å¾®å¤šå–ä¸€äº›æ—¥å­ï¼Œä¿è¯æŒ‡æ ‡è®¡ç®—
    start_search = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=max(num_days * 5, 120))).strftime("%Y%m%d")
    end_search = (datetime.strptime(end_date_str, "%Y%m%d") + timedelta(days=60)).strftime("%Y%m%d")
    
    cal = safe_get('trade_cal', start_date=start_search, end_date=end_search)
    if cal.empty or 'is_open' not in cal.columns: return []
    
    global GLOBAL_CALENDAR
    open_cal = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=True)
    GLOBAL_CALENDAR = open_cal['cal_date'].tolist()
    
    # è·å–ç”¨äº"é€‰è‚¡"çš„æ—¥å­
    past_days = open_cal[open_cal['cal_date'] <= end_date_str]['cal_date'].tolist()
    return past_days[-num_days:]

# ----------------------------------------------------------------------
# æ•°æ®ä¸‹è½½ (æ–°å¢ï¼šdaily_basic è·å–å¸‚å€¼)
# ----------------------------------------------------------------------
@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    # 1. è¡Œæƒ…æ•°æ®
    daily_df = safe_get('daily', trade_date=date)
    # 2. å¤æƒå› å­
    adj_df = safe_get('adj_factor', trade_date=date)
    # 3. æ¯æ—¥æŒ‡æ ‡ (å«æµé€šå¸‚å€¼ circ_mv, æ¢æ‰‹ç‡ç­‰)
    basic_df = safe_get('daily_basic', trade_date=date, fields='ts_code,circ_mv,turnover_rate')
    # 4. è‚¡ç¥¨åç§°
    name_df = safe_get('stock_basic', fields='ts_code,name')
    
    if not daily_df.empty:
        # ç­›é€‰åŒåˆ›
        daily_df = daily_df[daily_df['ts_code'].str.startswith(('30', '688'))]
        
        # åˆå¹¶å¸‚å€¼æ•°æ®
        if not basic_df.empty:
            daily_df = daily_df.merge(basic_df, on='ts_code', how='left')
        
        # åˆå¹¶åç§°
        if not name_df.empty:
            daily_df = daily_df.merge(name_df, on='ts_code', how='left')

    if not adj_df.empty:
        adj_df = adj_df[adj_df['ts_code'].str.startswith(('30', '688'))]
        
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(select_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS, GLOBAL_CALENDAR
    if not select_days_list: return False
    
    first_select_date = min(select_days_list)
    last_select_date = max(select_days_list)
    
    try:
        last_idx = GLOBAL_CALENDAR.index(last_select_date)
        end_fetch_idx = min(last_idx + 15, len(GLOBAL_CALENDAR) - 1)
        end_fetch_date = GLOBAL_CALENDAR[end_fetch_idx]
    except:
        end_fetch_date = (datetime.now() + timedelta(days=20)).strftime("%Y%m%d")

    # å¾€å‰å¤šæ¨150å¤©ç”¨äºè®¡ç®—MACD
    start_fetch_date = (datetime.strptime(first_select_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    
    # è¿™é‡Œçš„ trade_cal ä¸»è¦æ˜¯ä¸ºäº†æ‹¿åˆ°æ—¥æœŸåˆ—è¡¨è¿›è¡Œå¾ªç¯
    cal_range = safe_get('trade_cal', start_date=start_fetch_date, end_date=end_fetch_date, is_open='1')
    all_dates = cal_range['cal_date'].tolist()
    
    st.info(f"â³ æ­£åœ¨é¢„åŠ è½½å…¨é‡æ•°æ® (å«å¸‚å€¼/ä»·æ ¼) ({start_fetch_date} ~ {end_fetch_date})...")

    adj_list, daily_list = [], []
    bar = st.progress(0)
    
    total_steps = len(all_dates)
    for i, date in enumerate(all_dates):
        try:
            cached = fetch_and_cache_daily_data(date)
            if not cached['adj'].empty: adj_list.append(cached['adj'])
            if not cached['daily'].empty: daily_list.append(cached['daily'])
            if i % 10 == 0: bar.progress((i+1)/total_steps)
        except: continue 
    bar.empty()

    if not adj_list or not daily_list: return False
     
    adj_data = pd.concat(adj_list)
    adj_data['adj_factor'] = pd.to_numeric(adj_data['adj_factor'], errors='coerce').fillna(0)
    GLOBAL_ADJ_FACTOR = adj_data.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    daily_raw = pd.concat(daily_list)
    cols_to_float = ['open', 'high', 'low', 'close', 'pre_close', 'vol', 'circ_mv', 'pct_chg']
    for col in cols_to_float:
        if col in daily_raw.columns:
            daily_raw[col] = pd.to_numeric(daily_raw[col], errors='coerce').astype('float32')

    GLOBAL_DAILY_RAW = daily_raw.set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])
    
    latest_date_in_data = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_date_in_data:
        GLOBAL_QFQ_BASE_FACTORS = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_date_in_data), 'adj_factor'].droplevel(1).to_dict()
    
    return True

def get_qfq_data(ts_code, start_date, end_date):
    base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code)
    if not base_adj: return pd.DataFrame()

    try:
        daily = GLOBAL_DAILY_RAW.loc[(ts_code, slice(start_date, end_date)), :]
        adj = GLOBAL_ADJ_FACTOR.loc[(ts_code, slice(start_date, end_date)), 'adj_factor']
    except: return pd.DataFrame()
    
    if daily.empty or adj.empty: return pd.DataFrame()
    
    df = daily.join(adj, how='left').dropna(subset=['adj_factor'])
    factor = df['adj_factor'] / base_adj
    
    # ä»·æ ¼å¤æƒï¼Œå¸‚å€¼ä¸éœ€è¦å¤æƒ
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns: df[col] = df[col] * factor
    
    df = df.reset_index()
    return df.sort_values('trade_date')

# ----------------------------------------------------------------------
# è¯„åˆ†é€»è¾‘ (æ•æ·ç‰ˆ MACD)
# ----------------------------------------------------------------------
def compute_score(ts_code, current_date):
    start_date = (datetime.strptime(current_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    df = get_qfq_data(ts_code, start_date, current_date)
    
    if df.empty or len(df) < 30: return -1
    
    # ä¸¥æ ¼æ ¡éªŒæ—¥æœŸ
    last_date = df.iloc[-1]['trade_date']
    if hasattr(last_date, 'strftime'):
        last_date_str = last_date.strftime('%Y%m%d')
    else:
        last_date_str = str(last_date)
        
    if last_date_str != current_date: return -1

    close = df['close']
    # æ•æ·å‚æ•° (8, 17, 5)
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=5, adjust=False).mean()
    macd_val = (diff - dea) * 2
    
    # è¯„åˆ†: å•ä½ä»·æ ¼çš„åŠ¨èƒ½
    score = (macd_val.iloc[-1] / close.iloc[-1]) * 100000
    if pd.isna(score): score = -1
    return score

# ----------------------------------------------------------------------
# æ ¸å¿ƒé€»è¾‘ (å«ç­›é€‰æ¼æ–—)
# ----------------------------------------------------------------------
def run_strategy_step(select_date, top_n_limit):
    try:
        daily_t = GLOBAL_DAILY_RAW.xs(select_date, level='trade_date')
    except KeyError: return []
    
    # ---------------------------
    # 1. ç»ˆææ¼æ–—ç­›é€‰ (Filter)
    # ---------------------------
    # A. åŸºç¡€æ¡ä»¶: æœ‰æˆäº¤é‡(éåœç‰Œ)
    mask = (daily_t['vol'] > 0)
    
    # B. ä»·æ ¼åŒºé—´: 20 <= close <= 300
    mask &= (daily_t['close'] >= 20.0) & (daily_t['close'] <= 300.0)
    
    # C. å¸‚å€¼åŒºé—´: 30äº¿ <= circ_mv <= 800äº¿
    # æ³¨æ„: Tushare circ_mv å•ä½é€šå¸¸æ˜¯"ä¸‡å…ƒ"ã€‚ 30äº¿ = 300000ä¸‡å…ƒ, 800äº¿ = 8000000ä¸‡å…ƒ
    if 'circ_mv' in daily_t.columns:
        mask &= (daily_t['circ_mv'] >= 300000) & (daily_t['circ_mv'] <= 8000000)
        
    # D. è¶‹åŠ¿æ¡ä»¶: ä»Šæ—¥çº¢ç›˜ (pct_chg > 0)
    if 'pct_chg' in daily_t.columns:
        mask &= (daily_t['pct_chg'] > 0)
        
    pool = daily_t[mask]
    
    if pool.empty: return []

    # ---------------------------
    # 2. è¯„åˆ†ä¸æ’å (Ranking)
    # ---------------------------
    candidates = pool.index.tolist()
    scores = []
    
    for code in candidates:
        s = compute_score(code, select_date)
        if s > 0:
            scores.append((code, s))
            
    scores.sort(key=lambda x: x[1], reverse=True)
    
    # å– Top N
    final_candidates = scores[:top_n_limit]
    
    # ---------------------------
    # 3. ä¹°å…¥åˆ¤å®š (T+1 Open)
    # ---------------------------
    try:
        t_idx = GLOBAL_CALENDAR.index(select_date)
        if t_idx < len(GLOBAL_CALENDAR) - 1:
            buy_date = GLOBAL_CALENDAR[t_idx + 1]
        else:
            buy_date = None 
    except ValueError: buy_date = None

    results = []
    
    for rank, (code, score) in enumerate(final_candidates, 1):
        name = pool.loc[code, 'name'] if 'name' in pool.columns else code
        
        signal = "â³ ç­‰å¾…å¼€ç›˜"
        open_pct = np.nan
        is_buy = False
        
        ret_d1 = np.nan
        ret_d3 = np.nan
        ret_d5 = np.nan
        
        if buy_date:
            try:
                d1_raw = GLOBAL_DAILY_RAW.loc[(code, buy_date)]
                if isinstance(d1_raw, pd.DataFrame): d1_raw = d1_raw.iloc[0]

                daily_buy_open = float(d1_raw['open'])
                daily_buy_pre = float(d1_raw['pre_close'])
                open_pct = (daily_buy_open / daily_buy_pre - 1) * 100
                
                # ä¹°å…¥é€»è¾‘: [+2.0%, +7.5%]
                if 2.0 <= open_pct <= 7.5:
                    is_buy = True
                    signal = "âœ… BUY"
                elif open_pct < 2.0:
                    signal = "ğŸ‘€ å¼±"
                else:
                    signal = "âš ï¸ å¼º"
                    
                if is_buy:
                    future_df = get_qfq_data(code, buy_date, "20991231")
                    if not future_df.empty:
                        buy_price = future_df.iloc[0]['open']
                        
                        if len(future_df) >= 1:
                            ret_d1 = (future_df.iloc[0]['close'] / buy_price - 1) * 100
                        if len(future_df) >= 3:
                            ret_d3 = (future_df.iloc[2]['close'] / buy_price - 1) * 100
                        if len(future_df) >= 5:
                            ret_d5 = (future_df.iloc[4]['close'] / buy_price - 1) * 100

            except (KeyError, TypeError):
                signal = "âŒ åœç‰Œ/æ— æ•°æ®"

        results.append({
            'Select_Date': select_date,
            'Trade_Date': buy_date if buy_date else "æœªæ¥",
            'Rank': rank,
            'Code': code,
            'Name': name,
            'Signal': signal,
            'Open_Pct': open_pct,
            'Score': score,
            'Ret_D1': ret_d1,
            'Ret_D3': ret_d3,
            'Ret_D5': ret_d5
        })

    return results

# ----------------------------------------------------
# ä¾§è¾¹æ  (Sidebar)
# ----------------------------------------------------
with st.sidebar:
    st.header("1. å›æµ‹å‚æ•°")
    default_date = datetime.now().date()
    end_date = st.date_input("é€‰è‚¡æˆªæ­¢æ—¥æœŸ", value=default_date)
    days_back = int(st.number_input("å›æµ‹å¤©æ•°", value=5))
    
    st.markdown("---")
    st.header("2. ç­–ç•¥å¾®è°ƒ")
    # Top N æ»‘å—
    TOP_N = st.slider("æœ€å¤§æŒä»“æ•°é‡ (Top N)", min_value=1, max_value=5, value=1, help="æ¯å¤©æ‰«ææ’åå‰Nçš„è‚¡ç¥¨ã€‚è®¾ä¸º1å³åªåšé¾™å¤´ã€‚")
    
    st.info(f"å½“å‰æ¨¡å¼: æ¯å¤©ç›‘æ§ MACD å‰ {TOP_N} å")
    
    st.markdown("---")
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²ç¼“å­˜"):
        if os.path.exists(CHECKPOINT_FILE):
            os.remove(CHECKPOINT_FILE)
            st.toast("ç¼“å­˜å·²æ¸…ç©º", icon="ğŸ§¹")

# ---------------------------
# ä¸»ç•Œé¢ (Main Area)
# ---------------------------
col_token, col_btn = st.columns([3, 1])
with col_token:
    TS_TOKEN = st.text_input("ğŸ”‘ Tushare Token (åœ¨æ­¤è¾“å…¥)", type="password", placeholder="è¯·è¾“å…¥æ‚¨çš„ Token...")

with col_btn:
    st.write("") # å ä½å¯¹é½
    start_btn = st.button("ğŸš€ å¼€å§‹æ‰«æ", type="primary", use_container_width=True)

if start_btn:
    if not TS_TOKEN:
        st.error("è¯·å…ˆè¾“å…¥ Tushare Token")
        st.stop()
        
    ts.set_token(TS_TOKEN)
    pro = ts.pro_api()
    
    select_dates = get_trade_days(end_date.strftime("%Y%m%d"), days_back)
    
    if not select_dates: 
        st.error("âŒ æ—¥æœŸè·å–å¤±è´¥")
        st.stop()
        
    st.info(f"ğŸ“… æ‰«æåŒºé—´: {select_dates[0]} ~ {select_dates[-1]} | æ¨¡å¼: Top {TOP_N}")
    
    # è¯»å–æ–­ç‚¹
    processed_dates = []
    if os.path.exists(CHECKPOINT_FILE):
        try:
            cached_df = pd.read_csv(CHECKPOINT_FILE)
            if 'Select_Date' in cached_df.columns:
                processed_dates = cached_df['Select_Date'].astype(str).unique().tolist()
                st.success(f"ğŸ“‚ å·²åŠ è½½å†å²è®°å½•ï¼Œè·³è¿‡ {len(processed_dates)} å¤©")
        except: pass
    
    todo_dates = [d for d in select_dates if str(d) not in processed_dates]
    
    if todo_dates:
        if not get_all_historical_data(select_dates): st.stop()
        
        status_bar = st.progress(0)
        status_text = st.empty()
        
        for i, date in enumerate(todo_dates):
            status_text.text(f"æ­£åœ¨è®¡ç®—: {date} (Top {TOP_N} å¯»ä¼˜ä¸­...)")
            res_list = run_strategy_step(date, TOP_N)
            
            if res_list:
                df_chunk = pd.DataFrame(res_list)
                need_header = not os.path.exists(CHECKPOINT_FILE)
                df_chunk.to_csv(CHECKPOINT_FILE, mode='a', header=need_header, index=False)
            
            status_bar.progress((i+1)/len(todo_dates))
        
        status_bar.empty()
        status_text.empty()

    # ---------------------------
    # ç»“æœå±•ç¤º
    # ---------------------------
    if os.path.exists(CHECKPOINT_FILE):
        full_df = pd.read_csv(CHECKPOINT_FILE)
        mask = full_df['Select_Date'].astype(str).isin([str(d) for d in select_dates])
        # è¿˜è¦è¿‡æ»¤å‡ºæœ¬æ¬¡è¯·æ±‚çš„ Top N èŒƒå›´ (é˜²æ­¢ä¹‹å‰è·‘äº†Top5ï¼Œç°åœ¨åªè¦çœ‹Top1)
        df_show = full_df[mask].copy()
        df_show = df_show[df_show['Rank'] <= TOP_N]
        
        if df_show.empty:
            st.warning("æš‚æ— æ•°æ®")
        else:
            # Dashboard
            trades = df_show[df_show['Signal'].str.contains('BUY', na=False)]
            
            st.markdown(f"### ğŸ“Š ç­–ç•¥è¡¨ç° (Top {TOP_N} ç»„åˆ)")
            col1, col2, col3, col4 = st.columns(4)
            
            final_ret = trades['Ret_D5'].fillna(trades['Ret_D1']) # ä¼˜å…ˆçœ‹D5
            
            avg_ret = final_ret.mean()
            win_rate = (final_ret > 0).mean() * 100
            
            col1.metric("å…¥å›´è‚¡ç¥¨æ•°", f"{len(df_show)}")
            col2.metric("è§¦å‘äº¤æ˜“", f"{len(trades)}", delta=f"Rank 1-{TOP_N}")
            col3.metric("å¹³å‡æ”¶ç›Š (D5)", f"{avg_ret:.2f}%")
            col4.metric("èƒœç‡ (D5)", f"{win_rate:.1f}%")

            # Table
            st.markdown("### ğŸ“‹ æ¯æ—¥äº¤æ˜“æ˜ç»†")
            
            def color_signal(val):
                if 'BUY' in str(val): return 'background-color: #ff4b4b; color: white'
                if 'å¼±' in str(val): return 'color: #808080'
                if 'å¼º' in str(val): return 'color: #ffaa00'
                return ''
            
            def color_ret(val):
                if pd.isna(val): return ''
                if val > 0: return 'color: #d62728; font-weight: bold' # Red
                if val < 0: return 'color: #2ca02c; font-weight: bold' # Green
                return ''

            st.dataframe(
                df_show[['Trade_Date', 'Code', 'Name', 'Signal', 'Open_Pct', 'Rank', 'Ret_D1', 'Ret_D3', 'Ret_D5']]
                .style
                .map(color_signal, subset=['Signal'])
                .map(color_ret, subset=['Ret_D1', 'Ret_D3', 'Ret_D5'])
                .format({
                    'Open_Pct': '{:.2f}%',
                    'Ret_D1': '{:.2f}%',
                    'Ret_D3': '{:.2f}%',
                    'Ret_D5': '{:.2f}%'
                }),
                use_container_width=True
            )
            
            csv = df_show.to_csv().encode('utf-8')
            st.download_button("ğŸ“¥ ä¸‹è½½æŠ¥è¡¨ CSV", csv, "v33_result.csv", "text/csv")
