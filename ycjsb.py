import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time
import warnings

warnings.filterwarnings("ignore")

# ==========================================
# 1. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="æ½œé¾™ V13Â·åŠè·¯æˆªæ€", layout="wide")
st.title("ğŸ‰ æ½œé¾™ V13Â·åŠè·¯æˆªæ€ (å¼ºæ¿å—+ä¸­ä½èµ·çˆ†)")
st.markdown("""
**ç­–ç•¥æ ¸å¿ƒï¼šæ‹’ç»æ¥ç›˜ï¼ŒåŠè·¯æˆªæ€**
1.  **é¡¶çº§æˆ˜åœº**ï¼šé”å®š **æ¶¨å¹…å‰ 3 å** çš„æ¿å— (èµ„é‡‘é£å£)ã€‚
2.  **ä¸­ä½èµ·çˆ†**ï¼š**3% < æ¶¨å¹… < 8%** (ä¸è¿½æ¶¨åœï¼ŒåªæŠ“"åˆšæè£¤å­"çš„)ã€‚
3.  **èµ„é‡‘æ”»å‡»**ï¼š**é‡æ¯” > 2.0** (èµ„é‡‘æµå…¥é€Ÿåº¦æå¿«)ã€‚
4.  **å¸‚å€¼ä¼˜åŠ¿**ï¼š**å¸‚å€¼ < 150äº¿** (èˆ¹å°å¥½æ‰å¤´ï¼Œç¿»å€åŸºå› )ã€‚
""")

# ==========================================
# 2. æ ¸å¿ƒæ•°æ®å¼•æ“
# ==========================================
@st.cache_data(persist="disk", show_spinner=False)
def get_trade_cal(token, start_date, end_date):
    ts.set_token(token)
    pro = ts.pro_api()
    for attempt in range(3):
        try:
            df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open='1')
            if not df.empty:
                return sorted(df['cal_date'].tolist())
            time.sleep(0.5)
        except:
            time.sleep(1)
    return []

@st.cache_data(persist="disk", show_spinner=False)
def fetch_all_market_data_by_date(token, date_list):
    ts.set_token(token)
    pro = ts.pro_api()
    data_list = []
    total = len(date_list)
    bar = st.progress(0, text="æ­£åœ¨åŒæ­¥å…¨å¸‚åœºæ•°æ®...")
    
    for i, date in enumerate(date_list):
        try:
            time.sleep(0.05)
            # è·å–æ—¥çº¿
            df = pro.daily(trade_date=date)
            # è·å–æŒ‡æ ‡(æ¢æ‰‹ç‡ã€é‡æ¯”ã€å¸‚å€¼)
            df_basic = pro.daily_basic(trade_date=date, fields='ts_code,turnover_rate,volume_ratio,circ_mv')
            
            if not df.empty and not df_basic.empty:
                df = pd.merge(df, df_basic, on='ts_code', how='left')
                data_list.append(df)
        except:
            time.sleep(0.5)
        if (i+1) % 10 == 0:
            bar.progress((i+1)/total, text=f"åŠ è½½è¿›åº¦: {i+1}/{total}")
            
    bar.empty()
    if not data_list: return pd.DataFrame()
    full_df = pd.concat(data_list)
    full_df = full_df.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    return full_df

@st.cache_data(persist="disk", show_spinner=False)
def get_stock_basics(token):
    ts.set_token(token)
    pro = ts.pro_api()
    for _ in range(3):
        try:
            time.sleep(0.5)
            df = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,market,industry,list_date')
            if not df.empty:
                df = df[~df['name'].str.contains('ST')]
                df = df[~df['market'].str.contains('åŒ—äº¤')]
                df = df[~df['ts_code'].str.contains('BJ')]
                return df
        except: time.sleep(1)
    return pd.DataFrame()

# ==========================================
# 3. æ ¸å¿ƒè®¡ç®—
# ==========================================
def calculate_strategy(df_all, df_basic, top_k_sector):
    """
    V13 æ ¸å¿ƒé€»è¾‘: Top Sector -> Mid Stock -> High Vol
    """
    # 1. é¢„å¤„ç†
    if 'industry' not in df_all.columns:
        df_merged = pd.merge(df_all, df_basic[['ts_code', 'industry', 'name']], on='ts_code', how='left')
    else:
        df_merged = df_all.copy()
    
    # è¾…åŠ©æŒ‡æ ‡ï¼šRSI (6æ—¥)
    df_merged['up_move'] = np.where(df_merged['pct_chg'] > 0, df_merged['pct_chg'], 0)
    df_merged['down_move'] = np.where(df_merged['pct_chg'] < 0, abs(df_merged['pct_chg']), 0)
    avg_up = df_merged.groupby('ts_code')['up_move'].transform(lambda x: x.rolling(6).mean())
    avg_down = df_merged.groupby('ts_code')['down_move'].transform(lambda x: x.rolling(6).mean())
    df_merged['rsi_6'] = 100 * avg_up / (avg_up + avg_down + 0.0001)

    results = []
    dates = sorted(df_merged['trade_date'].unique())
    
    for i in range(10, len(dates)):
        curr_date = dates[i]
        daily_data = df_merged[df_merged['trade_date'] == curr_date].copy()
        
        if daily_data.empty: continue
        
        # === Step 1: å†³å‡ºæ¿å—å‰ä¸‰å ===
        sector_stats = daily_data.groupby('industry').agg({
            'pct_chg': 'mean',
            'ts_code': 'count',
            'amount': 'sum'
        }).reset_index()
        
        # è¿‡æ»¤å¾®å‹æ¿å—
        sector_stats = sector_stats[(sector_stats['ts_code'] > 5) & (sector_stats['amount'] > 100000)]
        
        # æ’åºå– Top K (Top 3)
        top_sectors = sector_stats.sort_values('pct_chg', ascending=False).head(top_k_sector)
        top_sector_names = top_sectors['industry'].tolist()
        
        if not top_sector_names: continue
        
        # === Step 2: åœ¨å¼ºæ¿å—é‡Œæ‰¾â€œåŠè·¯é¾™â€ ===
        for sec_name in top_sector_names:
            sec_data = daily_data[daily_data['industry'] == sec_name].copy()
            sec_gain = top_sectors[top_sectors['industry'] == sec_name]['pct_chg'].values[0]
            
            # æ¿å—å¿…é¡»å¤Ÿå¼º (>1.5%)
            if sec_gain < 1.5: continue
            
            # === Step 3: ä¸ªè‚¡ç­›é€‰ (ä¸­ä½èµ·çˆ†) ===
            # 1. æ¶¨å¹…åŒºé—´: 3% < x < 8% (ä¸è¿½æ¶¨åœï¼Œä¸åšå¼±åŠ¿)
            candidates = sec_data[(sec_data['pct_chg'] > 3.0) & (sec_data['pct_chg'] < 8.0)]
            
            # 2. èµ„é‡‘æ”»å‡»: é‡æ¯” > 2.0 (ä¸”æ¢æ‰‹ç‡>3%ï¼Œè¿‡æ»¤æ— é‡)
            candidates = candidates[(candidates['volume_ratio'] > 2.0) & (candidates['turnover_rate'] > 3.0)]
            
            # 3. å¸‚å€¼ç­›é€‰: æµé€šå¸‚å€¼ < 150äº¿ (æˆ–æ€»å¸‚å€¼) -> è¿™é‡Œç”¨ circ_mv (ä¸‡)
            # 150äº¿ = 1500000 ä¸‡
            # å¾ˆå¤šæ•°æ®æº circ_mv å•ä½æ˜¯ä¸‡å…ƒ
            candidates = candidates[candidates['circ_mv'] < 1500000]
            
            # 4. RSI è¾…åŠ©: è¶‹åŠ¿ä¸èƒ½å¤ªå·® (RSI > 60)
            candidates = candidates[candidates['rsi_6'] > 60]
            
            if candidates.empty: continue
            
            # ä¼˜ä¸­é€‰ä¼˜: æŒ‰é‡æ¯”æ’åºï¼Œå–å‰ 2 å
            top_picks = candidates.sort_values('volume_ratio', ascending=False).head(2)

            for _, row in top_picks.iterrows():
                results.append({
                    'ts_code': row['ts_code'],
                    'trade_date': curr_date,
                    'name': row['name'],
                    'industry': sec_name,
                    'sector_pct': sec_gain,
                    'pct_chg': row['pct_chg'],
                    'vol_ratio': row['volume_ratio'],
                    'rsi': row['rsi_6'],
                    'close': row['close'],
                    'is_signal': True
                })
            
    return pd.DataFrame(results)

def calculate_score(row):
    # è¯„åˆ†é€»è¾‘ï¼šé‡æ¯”æƒé‡æœ€å¤§ (ä»£è¡¨æ”»å‡»åŠ›åº¦)
    score = 60
    score += row['vol_ratio'] * 5
    score += row['pct_chg'] * 2
    return round(score, 1)

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ V13 åŠè·¯æˆªæ€å‚æ•°")
    user_token = st.text_input("Tushare Token:", type="password")
    
    days_back = st.slider("å›æµ‹å¤©æ•°", 30, 120, 60)
    end_date_input = st.date_input("æˆªæ­¢æ—¥æœŸ", datetime.now().date())
    
    st.markdown("---")
    st.subheader("ğŸ”¥ ç­›é€‰æ ‡å‡†")
    top_k_sector = st.number_input("é”å®šæ¿å—å‰å‡ å?", 1, 5, 3)
    
    run_btn = st.button("ğŸš€ å¯åŠ¨ V13 å›æµ‹")

def run_analysis():
    if not user_token:
        st.error("è¯·å…ˆè¾“å…¥ Token")
        return

    # 1. å‡†å¤‡æ•°æ®
    end_str = end_date_input.strftime('%Y%m%d')
    start_dt = end_date_input - timedelta(days=days_back * 1.5 + 80)
    
    cal_dates = get_trade_cal(user_token, start_dt.strftime('%Y%m%d'), end_str)
    if not cal_dates: return
        
    df_all = fetch_all_market_data_by_date(user_token, cal_dates)
    if df_all.empty: return
    st.success(f"âœ… Kçº¿æ•°æ®å°±ç»ª: {len(df_all):,} æ¡")

    # 2. åŸºç¡€ä¿¡æ¯
    df_basic = get_stock_basics(user_token)
    if df_basic.empty: return
        
    # 3. è®¡ç®—
    with st.spinner("æ­£åœ¨å¯»æ‰¾ä¸­ä½èµ·çˆ†ç‚¹..."):
        df_calc = calculate_strategy(df_all, df_basic, top_k_sector)
        
    # 4. ç»“æœ
    st.markdown("### ğŸ‰ V13 è¯Šæ–­ (å¼ºæ¿å—+ä¸­ä½èµ·çˆ†)")
    
    if df_calc.empty:
        st.warning("æ— ä¿¡å·ã€‚")
        return
        
    # è¿‡æ»¤æ—¶é—´çª—
    valid_dates = cal_dates[-(days_back):] 
    df_signals = df_calc[df_calc['trade_date'].isin(valid_dates)].copy()
    
    st.write(f"âšª æ•è·ä¸­ä½æ”»å‡»æ‰‹: **{len(df_signals)}** ä¸ª")

    # 5. è¯„åˆ†ä¸ Top N
    df_signals['æ½œé¾™åˆ†'] = df_signals.apply(calculate_score, axis=1)
    df_signals = df_signals.sort_values(['trade_date', 'vol_ratio'], ascending=[True, False])
    
    # 6. å›æµ‹
    price_lookup = df_all[['ts_code', 'trade_date', 'open', 'close', 'low', 'pre_close']].set_index(['ts_code', 'trade_date'])
    trades = []
    
    progress = st.progress(0)
    total_sig = len(df_signals)
    
    for i, row in enumerate(df_signals.itertuples()):
        progress.progress((i+1)/total_sig)
        
        signal_date = row.trade_date
        code = row.ts_code
        
        try:
            curr_idx = cal_dates.index(signal_date)
            future_dates = cal_dates[curr_idx+1 : curr_idx+11]
        except: continue
            
        if not future_dates: continue
            
        d1_date = future_dates[0]
        if (code, d1_date) not in price_lookup.index: continue
        d1_data = price_lookup.loc[(code, d1_date)]
        
        # é£æ§
        open_pct = (d1_data['open'] - d1_data.get('pre_close', row.close)) / row.close
        if open_pct < -0.05: continue
            
        buy_price = d1_data['open']
        stop_price = buy_price * 0.90
        
        trade = {
            'ä¿¡å·æ—¥': signal_date, 'ä»£ç ': code, 'åç§°': row.name, 
            'è¡Œä¸š': row.industry, 'æ¿å—æ¶¨å¹…': f"{row.sector_pct:.1f}%",
            'ä¸ªè‚¡æ¶¨å¹…': f"{row.pct_chg:.1f}%",
            'é‡æ¯”': f"{row.vol_ratio:.1f}",
            'ä¹°å…¥ä»·': buy_price, 'çŠ¶æ€': 'æŒæœ‰'
        }
        
        triggered = False
        for n, f_date in enumerate(future_dates):
            if (code, f_date) not in price_lookup.index: break
            f_data = price_lookup.loc[(code, f_date)]
            day_label = f"D+{n+1}"
            
            if not triggered:
                if f_data['low'] <= stop_price:
                    triggered = True
                    trade['çŠ¶æ€'] = 'æ­¢æŸ'
                    trade[day_label] = -10.0
                else:
                    ret = (f_data['close'] - buy_price) / buy_price * 100
                    trade[day_label] = round(ret, 2)
            else:
                trade[day_label] = -10.0
        
        trades.append(trade)
        
    progress.empty()
    
    if trades:
        df_res = pd.DataFrame(trades)
        
        st.markdown(f"### ğŸ“Š V13 (åŠè·¯æˆªæ€) å›æµ‹ç»“æœ")
        cols = st.columns(5)
        days = ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']
        
        for idx, d in enumerate(days):
            if d in df_res.columns:
                valid_data = df_res[pd.to_numeric(df_res[d], errors='coerce').notna()]
                if not valid_data.empty:
                    wins = valid_data[valid_data[d] > 0]
                    win_rate = len(wins) / len(valid_data) * 100
                    avg_ret = valid_data[d].mean()
                    cols[idx].metric(f"{d} èƒœç‡", f"{win_rate:.1f}%")
                    cols[idx].metric(f"{d} å‡æ”¶", f"{avg_ret:.2f}%")
        
        st.dataframe(df_res.sort_values(['ä¿¡å·æ—¥', 'é‡æ¯”'], ascending=[False, False]), use_container_width=True)
    else:
        st.warning("æ— äº¤æ˜“")

if run_btn:
    run_analysis()
