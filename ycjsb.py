# -*- coding: utf-8 -*-
"""
ç¬¬ä¸€å 5.1 æœ€ç»ˆä¿®å¤ç‰ˆ (è§£å†³ç©ºæ•°æ®é—®é¢˜)
-------------------------------------------------
ã€ä¿®å¤è¯´æ˜ã€‘
1. ä¿®æ­£æ•°æ®æ‹‰å–é€»è¾‘ï¼šä»â€œæ‰¹é‡æ‹‰å–â€æ”¹ä¸ºâ€œé€æ—¥æ‹‰å–â€ï¼Œè§£å†³ Tushare å•æ¬¡ 4000 è¡Œé™åˆ¶å¯¼è‡´çš„ç©ºæ•°æ®é—®é¢˜ã€‚
2. ä¿æŒé«˜ä¿çœŸå†…æ ¸ï¼šå…¨ç¨‹ Float64 ç²¾åº¦ï¼Œå®Œæ•´ OHLCV å­—æ®µã€‚
3. ç¨³å¥è¿›åº¦ï¼š20å¤©ä¸ºä¸€ä¸ªå‘¨æœŸï¼Œæ­¥æ­¥ä¸ºè¥ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import gc
import time
import os
import warnings

# ---------------------------
# 1. å…¨å±€é…ç½®
# ---------------------------
st.set_page_config(page_title="ç¬¬ä¸€å 5.1 æœ€ç»ˆä¿®å¤ç‰ˆ", layout="wide")
warnings.filterwarnings("ignore")

if 'pro' not in st.session_state:
    st.session_state.pro = None
if 'ts_token' not in st.session_state:
    st.session_state.ts_token = ""

# ---------------------------
# 2. UI ç•Œé¢
# ---------------------------
st.title("ğŸ† ç¬¬ä¸€å 5.1 æœ€ç»ˆä¿®å¤ç‰ˆ")
st.markdown("""
> **ğŸ”§ ä¿®å¤æ—¥å¿—ï¼š** å·²å°†æ•°æ®è·å–æ–¹å¼æ”¹ä¸º**é€æ—¥å¾ªç¯æ‹‰å–**ï¼Œå½»åº•è§£å†³å›  Tushare æ•°æ®é‡è¶…é™å¯¼è‡´çš„â€œæ•°æ®ä¸ºç©ºâ€é—®é¢˜ã€‚  
> **â³ é¢„è®¡è€—æ—¶ï¼š** ç”±äºéœ€è¦é€æ—¥è¯·æ±‚ï¼Œé€Ÿåº¦ä¼šæ¯”æé€Ÿç‰ˆæ…¢ï¼Œä½†**æ•°æ®ç»å¯¹å®Œæ•´å¯é **ã€‚
""")

with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        new_token = st.text_input("ğŸ’ Tushare Token", value=st.session_state.ts_token, type="password")
        if new_token:
            st.session_state.ts_token = new_token
            ts.set_token(new_token)
            st.session_state.pro = ts.pro_api()
    with col2:
        st.write("") 
        st.write("") 
        start_btn = st.button("ğŸ¢ å¯åŠ¨ä¿®å¤ç‰ˆå›æµ‹", type="primary", use_container_width=True)

with st.expander("âš™ï¸ ç­–ç•¥å‚æ•°", expanded=True):
    c1, c2, c3 = st.columns(3)
    with c1:
        backtest_days = st.number_input("å›æµ‹å¤©æ•°", value=500, step=50)
        stop_loss_pct = st.number_input("æ­¢æŸé˜ˆå€¼ (%)", value=-4.0, step=0.5)
    with c2:
        min_price = st.number_input("æœ€ä½è‚¡ä»·", value=40.0)
        max_price = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0)
    with c3:
        buy_threshold = st.number_input("ä¹°å…¥é˜ˆå€¼ (%)", value=1.5)
        top_k = st.number_input("æ¯æ—¥æŒä»“ (Top K)", value=3, min_value=1)

# ---------------------------
# 3. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ---------------------------
def get_trade_days(end_date_str, num_days):
    """è·å–ç›®æ ‡å›æµ‹çš„äº¤æ˜“æ—¥å†"""
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2 + 365)).strftime("%Y%m%d")
    if st.session_state.pro:
        try:
            cal = st.session_state.pro.trade_cal(start_date=start_date, end_date=end_date_str, is_open='1')
            return cal.sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()
        except: return []
    return []

def load_processed_dates(filepath):
    """æ–­ç‚¹ç»­ä¼ """
    if not os.path.exists(filepath): return set()
    try:
        df = pd.read_csv(filepath, usecols=['trade_date'], dtype={'trade_date': str})
        return set(df['trade_date'].unique().tolist())
    except: return set()

# ---------------------------
# 4. é«˜ä¿çœŸæ•°æ®åŠ è½½ (é€æ—¥å¾ªç¯ç‰ˆ)
# ---------------------------
def fetch_full_precision_data(target_days):
    """
    ã€ä¿®å¤ç‰ˆåŠ è½½ã€‘
    å¿…é¡»é€æ—¥æ‹‰å– (Loop by Day)ï¼Œå› ä¸º daily æ¥å£ä¸æ”¯æŒå…¨å¸‚åœºå¤šæ—¥æ‹‰å–
    """
    if not target_days: return None
    
    start_date = min(target_days)
    end_date = max(target_days)
    
    # å†å²ç¼“å†² (180å¤©) + æœªæ¥ç¼“å†² (30å¤©)
    buffer_start = (datetime.strptime(start_date, "%Y%m%d") - timedelta(days=180)).strftime("%Y%m%d")
    future_end = (datetime.strptime(end_date, "%Y%m%d") + timedelta(days=30)).strftime("%Y%m%d")
    
    st.info(f"ğŸ“¥ [é€æ—¥æ‹‰å–] æ­£åœ¨æ„å»ºæ•°æ®æ± : {buffer_start} ~ {future_end}")
    
    # è·å–æ‰€æœ‰äº¤æ˜“æ—¥
    try:
        cal = st.session_state.pro.trade_cal(start_date=buffer_start, end_date=future_end, is_open='1')
        all_cal_dates = cal['cal_date'].tolist()
    except: return None
    
    full_dfs = []
    # è¿›åº¦æ¡
    fetch_bar = st.progress(0)
    total_days = len(all_cal_dates)
    
    # --- é€æ—¥å¾ªç¯ (è¿™æ˜¯å”¯ä¸€ç¨³å¥çš„æ–¹æ³•) ---
    for i, date in enumerate(all_cal_dates):
        try:
            # å®Œæ•´å­—æ®µ
            df = st.session_state.pro.daily(trade_date=date, fields='ts_code,trade_date,open,high,low,close,pre_close,vol,amount')
            if not df.empty:
                full_dfs.append(df)
            
            # æ›´æ–°è¿›åº¦ (æ¯10å¤©æ›´æ–°ä¸€æ¬¡UIï¼Œé˜²æ­¢å¡é¡¿)
            if i % 10 == 0:
                fetch_bar.progress((i + 1) / total_days)
            
            # æçŸ­ä¼‘çœ ï¼Œé˜²æ­¢è¯·æ±‚è¿‡å¿«è¢«å° IP
            # time.sleep(0.01) 
        except:
            pass
            
    fetch_bar.empty()
    
    if not full_dfs: return None
    
    # åˆå¹¶
    df_big = pd.concat(full_dfs).sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    
    # --- é€æ—¥æ‹‰å–å¤æƒå› å­ ---
    st.caption("ğŸ”§ æ­£åœ¨æ‹‰å–å¤æƒå› å­...")
    adj_dfs = []
    
    for date in all_cal_dates:
        try:
            adj = st.session_state.pro.adj_factor(trade_date=date, fields='ts_code,trade_date,adj_factor')
            if not adj.empty:
                adj_dfs.append(adj)
        except: pass
        
    if adj_dfs:
        adj_all = pd.concat(adj_dfs)
        df_big = pd.merge(df_big, adj_all, on=['ts_code', 'trade_date'], how='left')
        df_big['adj_factor'] = df_big['adj_factor'].fillna(method='ffill').fillna(1.0)
        df_big['hfq_close'] = df_big['close'] * df_big['adj_factor']
    else:
        df_big['hfq_close'] = df_big['close']
        
    return df_big

def calculate_indicators_safe(df_big):
    """è®¡ç®—æŒ‡æ ‡"""
    st.caption("ğŸ§® æ­£åœ¨è®¡ç®—å…¨å¸‚åœºæŒ‡æ ‡...")
    df_big = df_big.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    grouped = df_big.groupby('ts_code')['hfq_close']
    
    # MACD (8, 17, 5)
    ema8 = grouped.ewm(span=8, adjust=False).mean().reset_index(level=0, drop=True)
    ema17 = grouped.ewm(span=17, adjust=False).mean().reset_index(level=0, drop=True)
    df_big['diff'] = ema8 - ema17
    df_big['dea'] = df_big.groupby('ts_code')['diff'].ewm(span=5, adjust=False).mean().reset_index(level=0, drop=True)
    df_big['macd'] = (df_big['diff'] - df_big['dea']) * 2
    
    # MA20
    df_big['ma20'] = grouped.rolling(20).mean().reset_index(level=0, drop=True)
    # MA5_Vol
    df_big['ma5_vol'] = df_big.groupby('ts_code')['vol'].rolling(5).mean().reset_index(level=0, drop=True)
    
    return df_big

def simulate_trade(ts_code, buy_date, buy_price, stop_loss_pct, df_future):
    """æ¨¡æ‹Ÿäº¤æ˜“"""
    try:
        # ç­›é€‰æœªæ¥æ•°æ®
        df_after = df_future[df_future['trade_date'] > buy_date].copy()
        if df_after.empty: return {}
        
        d1 = df_after.iloc[0]
        
        # æ ¡éªŒæ¡ä»¶
        if d1['open'] <= d1['pre_close']: return {'status': 'ä½å¼€æ”¾å¼ƒ'}
        limit_up = d1['pre_close'] * 1.095
        if d1['open'] >= limit_up and d1['low'] >= d1['open']: return {'status': 'ä¸€å­—æ¿æ”¾å¼ƒ'}
        if d1['high'] < buy_price: return {'status': 'æœªçªç ´'}
        
        res = {'status': 'æˆäº¤'}
        stop_price = buy_price * (1 + stop_loss_pct/100)
        
        for n in [1, 3, 5]:
            if len(df_after) >= n:
                triggered_stop = False
                for i in range(n):
                    if df_after.iloc[i]['low'] <= stop_price:
                        exit_price = min(stop_price, df_after.iloc[i]['open'])
                        res[f'Return_D{n} (%)'] = (exit_price / buy_price - 1) * 100
                        res[f'Stop_D{n}'] = True
                        triggered_stop = True
                        break
                if not triggered_stop:
                    close_price = df_after.iloc[n-1]['close']
                    res[f'Return_D{n} (%)'] = (close_price / buy_price - 1) * 100
                    res[f'Stop_D{n}'] = False
        return res
    except: return {}

# ---------------------------
# 5. ä¸»ç¨‹åº
# ---------------------------
if start_btn:
    if not st.session_state.ts_token:
        st.error("âŒ è¯·å…ˆè¾“å…¥ Token")
        st.stop()
        
    end_date_str = datetime.now().strftime("%Y%m%d")
    all_target_days = get_trade_days(end_date_str, backtest_days)
    all_target_days = sorted(all_target_days)
    
    # æ–­ç‚¹ç»­ä¼ 
    results_file = "rank_high_fidelity.csv"
    finished_dates = load_processed_dates(results_file)
    days_to_run = [d for d in all_target_days if d not in finished_dates]
    
    if not days_to_run:
        st.success("ğŸ‰ æ‰€æœ‰æ—¥æœŸå·²å®Œæˆï¼")
        st.stop()
        
    st.info(f"ğŸ“… æœ¬æ¬¡éœ€å›æµ‹ {len(days_to_run)} å¤©ï¼Œè‡ªåŠ¨åˆ†æ‰¹æ‰§è¡Œ...")

    # åˆ†æ‰¹æ‰§è¡Œ
    BATCH_SIZE = 20
    batches = [days_to_run[i:i + BATCH_SIZE] for i in range(0, len(days_to_run), BATCH_SIZE)]
    
    main_progress = st.progress(0)
    status_text = st.empty()
    total_trades = 0
    
    for b_i, batch_days in enumerate(batches):
        status_text.markdown(f"### ğŸ”„ å¤„ç†æ‰¹æ¬¡ {b_i+1}/{len(batches)} ({batch_days[0]} ~ {batch_days[-1]})")
        
        # A. æ‹‰å–å…¨é‡æ•°æ®
        df_big = fetch_full_precision_data(batch_days)
        if df_big is None or df_big.empty:
            st.warning(f"æ‰¹æ¬¡ {b_i+1} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
            continue
            
        # B. è®¡ç®—æŒ‡æ ‡
        df_big = calculate_indicators_safe(df_big)
        
        # C. é€æ—¥å›æµ‹
        batch_results = []
        
        for current_date in batch_days:
            try:
                today_data = df_big[df_big['trade_date'] == current_date].copy()
                if today_data.empty: continue
                
                # è·å– Basic (å¿…é¡»é€æ—¥æ‹‰å–)
                try:
                    basic = st.session_state.pro.daily_basic(trade_date=current_date, fields='ts_code,turnover_rate,volume_ratio,circ_mv')
                except: basic = pd.DataFrame()
                
                if basic.empty: continue
                
                merged = pd.merge(today_data, basic, on='ts_code', how='inner')
                
                # ç­›é€‰
                mask = (
                    (merged['hfq_close'] > merged['ma20']) &
                    (merged['vol'] > merged['ma5_vol'] * 1.2) &
                    (merged['macd'] > 0) &
                    (merged['close'] >= min_price) & 
                    (merged['close'] <= max_price) &
                    (merged['turnover_rate'] > 3.0) &
                    (merged['circ_mv'] > 200000) 
                )
                candidates = merged[mask].copy()
                
                if candidates.empty: continue
                
                # è¯„åˆ†
                candidates['base_score'] = (candidates['macd'] / candidates['hfq_close']) * 1000000
                candidates['pct_chg'] = (candidates['close'] / candidates['pre_close'] - 1) * 100
                
                candidates['bonus'] = 1.0
                candidates.loc[(candidates['volume_ratio'] > 1.5) & (candidates['volume_ratio'] < 5.0), 'bonus'] += 0.1
                candidates.loc[(candidates['turnover_rate'] > 5.0) & (candidates['turnover_rate'] < 15.0), 'bonus'] += 0.1
                candidates.loc[candidates['pct_chg'] > 9.5, 'bonus'] += 0.1
                
                candidates['final_score'] = candidates['base_score'] * candidates['bonus']
                
                # Top K
                top_selection = candidates.sort_values('final_score', ascending=False).head(top_k)
                
                # äº¤æ˜“
                for row in top_selection.itertuples():
                    buy_price = row.open * (1 + buy_threshold/100)
                    # æŸ¥æ‰¾æœªæ¥æ•°æ® (å†…å­˜ä¸­)
                    stock_future = df_big[df_big['ts_code'] == row.ts_code]
                    res = simulate_trade(row.ts_code, current_date, buy_price, stop_loss_pct, stock_future)
                    
                    if res.get('status') == 'æˆäº¤':
                        rec = {
                            'trade_date': current_date,
                            'ts_code': row.ts_code,
                            'name': 'Unknown',
                            'close': row.close,
                            'score': row.final_score
                        }
                        rec.update(res)
                        batch_results.append(rec)
            except: pass
        
        # D. å­˜ç›˜
        if batch_results:
            df_res = pd.DataFrame(batch_results)
            header = not os.path.exists(results_file)
            df_res.to_csv(results_file, mode='a', header=header, index=False, encoding='utf-8-sig')
            total_trades += len(df_res)
            st.toast(f"âœ… ä¿å­˜ {len(df_res)} æ¡ | ç´¯è®¡: {total_trades}")
        
        del df_big, batch_results
        gc.collect()
        time.sleep(1) # ä¼‘æ¯ä¸€ä¸‹
        main_progress.progress((b_i + 1) / len(batches))

    st.success("ğŸ‰ é«˜ä¿çœŸå›æµ‹å…¨éƒ¨å®Œæˆï¼")
    
    # ç»“æœ
    if os.path.exists(results_file):
        try:
            res_df = pd.read_csv(results_file)
            st.subheader("ğŸ“Š å›æµ‹æŠ¥å‘Š")
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("äº¤æ˜“æ¬¡æ•°", len(res_df))
            if 'Return_D1 (%)' in res_df.columns:
                avg = res_df['Return_D1 (%)'].mean()
                win = (res_df['Return_D1 (%)'] > 0).mean() * 100
                c2.metric("D+1 å‡æ”¶", f"{avg:.2f}%")
                c3.metric("D+1 èƒœç‡", f"{win:.1f}%")
                
                res_df = res_df.sort_values('trade_date')
                equity = res_df.groupby('trade_date')['Return_D1 (%)'].mean().cumsum()
                dd = equity.cummax() - equity
                c4.metric("æœ€å¤§å›æ’¤", f"{dd.max():.2f}")
            st.dataframe(res_df, use_container_width=True)
            with open(results_file, "rb") as f:
                st.download_button("ğŸ“¥ ä¸‹è½½ CSV", f, "high_fidelity_result.csv")
        except: pass
