# -*- coding: utf-8 -*-
"""
ç¬¬ä¸€å 2.0 ç‰ˆ (UIé‡æ„ + çœŸå®æ–­ç‚¹ç»­ä¼ )
æ ¸å¿ƒå‡çº§ï¼š
1. [UI] Tokenå’Œå¼€å§‹æŒ‰é’®ç§»è‡³ä¸»ç•Œé¢ï¼Œå‚æ•°æ”¶çº³è¿›æŠ˜å æ ã€‚
2. [ç»­ä¼ ] å¯åŠ¨å‰è‡ªåŠ¨æ‰«æå·²å®Œæˆæ—¥æœŸï¼Œå´©æºƒåé‡å¯å¯æ— ç¼ç»§ç»­ã€‚
3. [ç¨³å¥] å¼ºåŒ–å†…å­˜ç®¡ç†ï¼Œé˜²æ­¢500å¤©å›æµ‹å´©æºƒã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import gc
import time
import os
import warnings
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡ä¸Sessionç®¡ç†
# ---------------------------
if 'pro' not in st.session_state:
    st.session_state.pro = None
if 'ts_token' not in st.session_state:
    st.session_state.ts_token = ""

GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="ç¬¬ä¸€å 2.0 ç‰ˆ", layout="wide")

# ---------------------------
# UI å¸ƒå±€ (ç§»å‡ºä¾§è¾¹æ )
# ---------------------------
st.title("ğŸ† ç¬¬ä¸€å 2.0 ç‰ˆ (Rank 1 çº¯äº« + æ™ºèƒ½ç»­ä¼ )")

# ä¸»æ§åˆ¶åŒº
with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        # Token è¾“å…¥æ¡† (å¸¦è®°å¿†)
        new_token = st.text_input("ğŸ’ è¯·è¾“å…¥ Tushare Token (10000ç§¯åˆ†)", 
                                  value=st.session_state.ts_token, 
                                  type="password",
                                  help="Token å°†ä¿å­˜åœ¨æœ¬æ¬¡ä¼šè¯ä¸­")
        if new_token:
            st.session_state.ts_token = new_token
            ts.set_token(new_token)
            st.session_state.pro = ts.pro_api()

    with col2:
        # æ˜¾çœ¼çš„å¼€å§‹æŒ‰é’®
        st.write("") # å ä½å¯¹é½
        st.write("") 
        start_btn = st.button("ğŸš€ å¯åŠ¨/ç»§ç»­ å›æµ‹", type="primary", use_container_width=True)

# å‚æ•°æŠ˜å æ  (é»˜è®¤éšè—ï¼Œç‚¹å‡»å±•å¼€)
with st.expander("âš™ï¸ ç­–ç•¥å‚æ•°è®¾ç½® (å·²ä¼˜åŒ–é»˜è®¤å€¼ï¼Œæ— éœ€é¢‘ç¹è°ƒæ•´)", expanded=False):
    c1, c2, c3 = st.columns(3)
    with c1:
        backtest_days = st.number_input("å›æµ‹å¤©æ•° (N)", value=500, step=50, help="å»ºè®®è®¾ç½®ä¸º500å¤©ä»¥éªŒè¯ç©¿è¶Šç‰›ç†Šçš„èƒ½åŠ›")
        buy_threshold = st.number_input("ä¹°å…¥é˜ˆå€¼ (%)", value=1.5, step=0.1)
    with c2:
        min_price = st.number_input("æœ€ä½è‚¡ä»·", value=40.0)
        max_price = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0)
    with c3:
        top_k = st.number_input("æ¯æ—¥æŒä»“ (Top K)", value=1, disabled=True, help="æœ¬ç­–ç•¥æ ¸å¿ƒå°±æ˜¯åªåšç¬¬ä¸€å")
        
# ---------------------------
# è¾…åŠ©å‡½æ•° 
# ---------------------------
def get_trade_days(end_date_str, num_days):
    # å¢åŠ å†—ä½™å¤©æ•°ä»¥ç¡®ä¿è¦†ç›–
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3 + 200)).strftime("%Y%m%d")
    if st.session_state.pro:
        try:
            cal = st.session_state.pro.trade_cal(start_date=start_date, end_date=end_date_str)
            if cal.empty or 'is_open' not in cal.columns: return []
            return cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()
        except: return []
    return []

def load_processed_dates(filepath):
    """è¯»å–å·²å®Œæˆçš„æ—¥æœŸï¼Œå®ç°æ–­ç‚¹ç»­ä¼ """
    if not os.path.exists(filepath):
        return set()
    try:
        # åªè¯»å– trade_date åˆ—ï¼Œå‡å°‘å†…å­˜æ¶ˆè€—
        df = pd.read_csv(filepath, usecols=['trade_date'], dtype={'trade_date': str})
        return set(df['trade_date'].unique().tolist())
    except:
        return set()

# ----------------------------------------------------------------------
# æ•°æ®åŠ è½½ (åˆ†æ®µç‰ˆ + æé€ŸGC)
# ----------------------------------------------------------------------
def load_data_for_batch(batch_trade_days):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    
    if not batch_trade_days: return False
    
    latest_date = max(batch_trade_days)
    earliest_date = min(batch_trade_days)
    
    # åŠ¨æ€è®¡ç®—æ‰€éœ€æ•°æ®èŒƒå›´ (å‰æ¨150å¤©å¤Ÿç®—MACDäº†)
    data_start = (datetime.strptime(earliest_date, "%Y%m%d") - timedelta(days=160)).strftime("%Y%m%d")
    data_end = (datetime.strptime(latest_date, "%Y%m%d") + timedelta(days=25)).strftime("%Y%m%d")
    
    msg_slot = st.empty()
    msg_slot.info(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ•°æ®ç‰‡æ®µ: {data_start} ~ {data_end} ...")
    
    try:
        cal = st.session_state.pro.trade_cal(start_date=data_start, end_date=data_end, is_open='1')
        all_dates = cal['cal_date'].tolist()
    except:
        return False
    
    adj_list, daily_list = [], []
    
    # è¿›åº¦æ¡ä»…åœ¨åŠ è½½æ•°æ®æ—¶æ˜¾ç¤º
    load_bar = st.progress(0)
    total = len(all_dates)
    
    for i, date in enumerate(all_dates):
        try:
            # ä»…æ‹‰å–éœ€è¦çš„å­—æ®µï¼Œå¤§å¹…èŠ‚çœå†…å­˜
            df = st.session_state.pro.daily(trade_date=date, fields='ts_code,trade_date,open,high,low,close,pre_close,vol')
            if not df.empty:
                # å¼ºè½¬ float32
                for c in ['open', 'high', 'low', 'close', 'pre_close', 'vol']:
                    df[c] = pd.to_numeric(df[c], errors='coerce').astype('float32')
                daily_list.append(df)
            
            adj = st.session_state.pro.adj_factor(trade_date=date)
            if not adj.empty:
                adj_list.append(adj)
            
            # æ¯20å¤©æ›´æ–°ä¸€æ¬¡è¿›åº¦æ¡ï¼Œå‡å°‘åˆ·æ–°å¼€é”€
            if i % 20 == 0: load_bar.progress((i + 1) / total)
        except: continue
        
    load_bar.empty()
    msg_slot.empty()
    
    if not daily_list: return False
    
    # æ„å»º DataFrame
    GLOBAL_DAILY_RAW = pd.concat(daily_list)
    GLOBAL_DAILY_RAW = GLOBAL_DAILY_RAW.drop_duplicates(subset=['ts_code', 'trade_date'])
    # å»ºç«‹å¤šçº§ç´¢å¼•ï¼Œè¿™æ˜¯é€Ÿåº¦çš„å…³é”®
    GLOBAL_DAILY_RAW.set_index(['ts_code', 'trade_date'], inplace=True)
    GLOBAL_DAILY_RAW.sort_index(level=[0, 1], inplace=True)
    
    if adj_list:
        GLOBAL_ADJ_FACTOR = pd.concat(adj_list)
        GLOBAL_ADJ_FACTOR['adj_factor'] = pd.to_numeric(GLOBAL_ADJ_FACTOR['adj_factor'], errors='coerce').fillna(0)
        GLOBAL_ADJ_FACTOR = GLOBAL_ADJ_FACTOR.drop_duplicates(subset=['ts_code', 'trade_date'])
        GLOBAL_ADJ_FACTOR.set_index(['ts_code', 'trade_date'], inplace=True)
        GLOBAL_ADJ_FACTOR.sort_index(level=[0, 1], inplace=True)
        
        try:
            latest_adj = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj.droplevel(1).to_dict()
        except: GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True

def clear_memory():
    """å¼ºåˆ¶æ¸…ç†å…¨å±€å˜é‡"""
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR
    GLOBAL_DAILY_RAW = pd.DataFrame()
    GLOBAL_ADJ_FACTOR = pd.DataFrame()
    gc.collect()

# ----------------------------------------------------------------------
# è®¡ç®—é€»è¾‘ (ä¿æŒä¸å˜)
# ----------------------------------------------------------------------
def get_qfq_data_batch(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    try:
        # æé€Ÿåˆ‡ç‰‡
        daily = GLOBAL_DAILY_RAW.loc[(ts_code, slice(start_date, end_date)), :]
        if daily.empty: return pd.DataFrame()
        
        base_adj = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, 1.0)
        
        try:
            adj = GLOBAL_ADJ_FACTOR.loc[(ts_code, slice(start_date, end_date)), 'adj_factor']
        except:
            adj = pd.Series(index=daily.index, data=base_adj)
            
        df = daily.merge(adj.rename('adj_factor'), left_index=True, right_index=True, how='left')
        df['adj_factor'] = df['adj_factor'].fillna(method='ffill').fillna(base_adj)
        
        factor = df['adj_factor'] / base_adj
        for col in ['open', 'high', 'low', 'close', 'pre_close']:
            df[col] = df[col] * factor
            
        return df.reset_index()
    except Exception:
        return pd.DataFrame()

def compute_indicators(ts_code, current_date):
    start_date = (datetime.strptime(current_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    df = get_qfq_data_batch(ts_code, start_date, current_date)
    res = {}
    if df.empty or len(df) < 20: return res # åªè¦æœ‰20å¤©æ•°æ®å°±ç®—
    
    df = df.sort_values('trade_date')
    close = df['close']
    vol = df['vol']
    
    # æ”¹è¿›ç‰ˆ MACD (8, 17, 5)
    ema_fast = close.ewm(span=8, adjust=False).mean()
    ema_slow = close.ewm(span=17, adjust=False).mean()
    diff = ema_fast - ema_slow
    dea = diff.ewm(span=5, adjust=False).mean()
    macd_val = (diff - dea) * 2
    
    res['macd_val'] = macd_val.iloc[-1]
    res['close'] = close.iloc[-1]
    res['ma20'] = close.rolling(20).mean().iloc[-1]
    res['vol'] = vol.iloc[-1]
    res['ma5_vol'] = vol.rolling(5).mean().iloc[-1]
    res['pct_chg'] = (close.iloc[-1] / df['pre_close'].iloc[-1] - 1) * 100
    
    return res

def check_buy_and_profit(ts_code, current_date, buy_threshold):
    d0 = datetime.strptime(current_date, "%Y%m%d")
    future_start = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    future_end = (d0 + timedelta(days=20)).strftime("%Y%m%d")
    
    df = get_qfq_data_batch(ts_code, future_start, future_end)
    if df.empty: return {}
    
    df = df.sort_values('trade_date')
    d1 = df.iloc[0]
    
    res = {}
    if d1['open'] <= d1['pre_close']: return {} # å¿…é¡»é«˜å¼€
    
    limit_price = d1['pre_close'] * 1.095
    if d1['open'] >= limit_price and d1['low'] >= d1['open']: return {} # å‰”é™¤ä¸€å­—
    
    buy_price = d1['open'] * (1 + buy_threshold/100)
    if d1['high'] < buy_price: return {} # å¿…é¡»çªç ´
    
    for n in [1, 3, 5]:
        idx = n - 1
        if len(df) > idx:
            sell_price = df.iloc[idx]['close']
            res[f'Return_D{n} (%)'] = (sell_price / buy_price - 1) * 100
            
    return res

# ---------------------------
# æ‰§è¡Œé€»è¾‘
# ---------------------------
if start_btn:
    if not st.session_state.ts_token:
        st.error("âŒ è¯·å…ˆè¾“å…¥ Token")
        st.stop()
        
    st.info("â³ æ­£åœ¨åˆå§‹åŒ–...")
    
    # 1. è·å–æ‰€æœ‰è®¡åˆ’å›æµ‹çš„æ—¥æœŸ
    end_date_str = datetime.now().strftime("%Y%m%d")
    all_target_days = get_trade_days(end_date_str, backtest_days)
    if not all_target_days:
        st.error("æ— æ³•è·å–äº¤æ˜“æ—¥å†ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–Token")
        st.stop()
    all_target_days = sorted(all_target_days)
    
    # 2. [æ ¸å¿ƒ] æ£€æŸ¥æ–­ç‚¹ï¼Œå‰”é™¤å·²å®Œæˆçš„æ—¥æœŸ
    results_file = "backtest_result.csv"
    finished_dates = load_processed_dates(results_file)
    
    # è®¡ç®—è¿˜éœ€è¦è·‘çš„æ—¥æœŸ
    days_to_run = [d for d in all_target_days if d not in finished_dates]
    
    if len(finished_dates) > 0:
        st.warning(f"æ£€æµ‹åˆ°å†å²è®°å½•ï¼šå·²å®Œæˆ {len(finished_dates)} å¤©ï¼Œè‡ªåŠ¨è·³è¿‡ã€‚æœ¬æ¬¡ä»…éœ€è·‘ {len(days_to_run)} å¤©ã€‚")
    
    if not days_to_run:
        st.success("ğŸ‰ æ‰€æœ‰æ—¥æœŸå·²å…¨éƒ¨è·‘å®Œï¼è¯·ç›´æ¥ä¸‹è½½ç»“æœã€‚")
    else:
        # 3. åˆ†æ‰¹æ¬¡æ‰§è¡Œ
        BATCH_SIZE = 40 # è¿›ä¸€æ­¥å‡å°Batch Sizeé˜²æ­¢å†…å­˜æº¢å‡º
        total_batches = (len(days_to_run) + BATCH_SIZE - 1) // BATCH_SIZE
        
        status_text = st.empty()
        main_progress = st.progress(0)
        
        for batch_idx in range(total_batches):
            start_i = batch_idx * BATCH_SIZE
            end_i = min((batch_idx + 1) * BATCH_SIZE, len(days_to_run))
            batch_days = days_to_run[start_i:end_i]
            
            status_text.markdown(f"### ğŸ”„ æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {batch_idx+1}/{total_batches} ({batch_days[0]} ~ {batch_days[-1]})")
            
            # è¿™ä¸€æ­¥æœ€è€—å†…å­˜ï¼Œå¤±è´¥äº†ç›´æ¥è·³è¿‡æœ¬æ‰¹æ¬¡ï¼Œä¸å´©æºƒæ•´ä¸ªç¨‹åº
            if not load_data_for_batch(batch_days):
                st.error(f"âš ï¸ æ‰¹æ¬¡ {batch_idx+1} æ•°æ®åŠ è½½å¤±è´¥ï¼Œè·³è¿‡...")
                continue
                
            batch_results = []
            
            for d_idx, date in enumerate(batch_days):
                try:
                    # æ¯æ—¥é€‰è‚¡
                    df_basic = st.session_state.pro.daily_basic(trade_date=date, fields='ts_code,turnover_rate,volume_ratio,circ_mv,close')
                    if df_basic is None or df_basic.empty: continue
                    
                    # åˆç­›
                    pool = df_basic[
                        (df_basic['close'] >= min_price) & 
                        (df_basic['close'] <= max_price) &
                        (df_basic['circ_mv'] > 200000) & # 2äº¿å¸‚å€¼
                        (df_basic['turnover_rate'] > 3.0)
                    ]
                    
                    candidates = []
                    for row in pool.itertuples():
                        # æ ¸å¿ƒè®¡ç®—
                        ind = compute_indicators(row.ts_code, date)
                        if not ind: continue
                        
                        if ind['close'] <= ind['ma20']: continue
                        if ind['vol'] <= ind['ma5_vol'] * 1.2: continue
                        if ind['macd_val'] <= 0: continue
                        
                        macd_score = (ind['macd_val'] / ind['close']) * 1000000
                        bonus = 1.0
                        # èµ„é‡‘å…±æŒ¯åŠ åˆ†
                        if 1.5 < getattr(row, 'volume_ratio', 0) < 5.0: bonus += 0.1
                        if 5.0 < getattr(row, 'turnover_rate', 0) < 15.0: bonus += 0.1
                        if ind['pct_chg'] > 9.5: bonus += 0.1
                        
                        score = macd_score * bonus
                        
                        candidates.append({
                            'ts_code': row.ts_code,
                            'trade_date': date,
                            'score': score,
                            'close': ind['close']
                        })
                    
                    if candidates:
                        # æ’åºå– Top 1
                        day_df = pd.DataFrame(candidates).sort_values('score', ascending=False).head(1)
                        
                        # å›æµ‹ä¹°å…¥
                        for rec in day_df.itertuples():
                            ret = check_buy_and_profit(rec.ts_code, rec.trade_date, buy_threshold)
                            rec_dict = rec._asdict()
                            rec_dict.update(ret)
                            batch_results.append(rec_dict)
                            
                except Exception:
                    continue
                
                # æ›´æ–°è¿›åº¦æ¡
                current_percent = (start_i + d_idx + 1) / len(days_to_run)
                main_progress.progress(current_percent)
            
            # ä¿å­˜æœ¬æ‰¹æ¬¡ç»“æœ
            if batch_results:
                df_batch = pd.DataFrame(batch_results)
                # å®æ—¶å†™å…¥ç£ç›˜
                header = not os.path.exists(results_file)
                df_batch.to_csv(results_file, mode='a', header=header, index=False, encoding='utf-8-sig')
                st.toast(f"âœ… å·²ä¿å­˜ {len(df_batch)} æ¡æ–°è®°å½•")
            
            # å¼ºåˆ¶å†…å­˜æ¸…ç†
            clear_memory()
    
    st.success("ğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")

# ---------------------------
# ç»“æœå±•ç¤ºåŒº (å§‹ç»ˆæ˜¾ç¤º)
# ---------------------------
st.markdown("---")
if os.path.exists("backtest_result.csv"):
    try:
        final_df = pd.read_csv("backtest_result.csv")
        st.subheader("ğŸ“Š å›æµ‹ç»“æœåˆ†æ")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»äº¤æ˜“æ¬¡æ•°", len(final_df))
        
        if 'Return_D1 (%)' in final_df.columns:
            valid = final_df.dropna(subset=['Return_D1 (%)'])
            avg = valid['Return_D1 (%)'].mean()
            win = (valid['Return_D1 (%)'] > 0).mean() * 100
            with col2:
                st.metric("D+1 å¹³å‡æ”¶ç›Š", f"{avg:.2f}%")
            with col3:
                st.metric("D+1 èƒœç‡", f"{win:.1f}%")
        
        st.dataframe(final_df, width=None)
        
        with open("backtest_result.csv", "rb") as f:
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´ CSV",
                data=f,
                file_name="rank1_final_result.csv",
                mime="text/csv",
                type="primary"
            )
    except:
        st.info("æš‚æ— ç»“æœæ•°æ®")
