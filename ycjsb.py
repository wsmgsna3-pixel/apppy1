import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time
import warnings
import os

warnings.filterwarnings("ignore")

# ==========================================
# 1. é¡µé¢é…ç½® & å¸¸é‡
# ==========================================
st.set_page_config(page_title="æ½œé¾™ V20Â·æ°¸ä¸ç£¨ç­", layout="wide")
st.title("ğŸ‰ æ½œé¾™ V20Â·æ°¸ä¸ç£¨ç­ (ç‰©ç†ç¼“å­˜+å¢é‡æ›´æ–°)")
st.markdown("""
**æ¶æ„é‡æ„ï¼šå½»åº•è§£å†³é‡å¤ä¸‹è½½é—®é¢˜**
1.  **ç¡¬ç›˜çº§ç¼“å­˜**ï¼šæ•°æ®æ°¸ä¹…ä¿å­˜åœ¨ `market_data_store.csv`ï¼Œä¸æ€•ä»£ç è¦†ç›–ã€‚
2.  **æ™ºèƒ½å¢é‡**ï¼šè‡ªåŠ¨è¯†åˆ«ç¼ºå¤±æ—¥æœŸï¼Œ**åªä¸‹è½½** æ²¡ä¸‹çš„éƒ¨åˆ† (çœŸæ­£çš„æ–­ç‚¹ç»­ä¼ )ã€‚
3.  **æ ¸å¿ƒç­–ç•¥**ï¼šV19 é“é—¨æ§› (ç«ä»·è¿‡æ»¤) + V18 åŒé¾™ (æ½œä¼/è¿½å‡»)ã€‚
""")

DATA_FILE = "market_data_store.csv"

# ==========================================
# 2. æ ¸å¿ƒæ•°æ®å¼•æ“ (å¢é‡æ›´æ–°ç‰ˆ)
# ==========================================
def get_trade_cal(pro, start_date, end_date):
    try:
        df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open='1')
        return sorted(df['cal_date'].tolist())
    except:
        return []

def sync_market_data(token, start_date, end_date):
    """
    å¢é‡åŒæ­¥é€»è¾‘ï¼š
    1. è¯»å–æœ¬åœ°ç°æœ‰æ•°æ®ï¼Œè·å–å·²æœ‰çš„æ—¥æœŸé›†åˆã€‚
    2. å¯¹æ¯”ç›®æ ‡æ—¥æœŸèŒƒå›´ï¼Œæ‰¾å‡ºç¼ºå°‘çš„æ—¥æœŸã€‚
    3. åªä¸‹è½½ç¼ºå°‘çš„æ—¥æœŸï¼Œè¿½åŠ å†™å…¥æ–‡ä»¶ã€‚
    """
    if not token:
        return pd.DataFrame(), "è¯·å…ˆè¾“å…¥Token"
        
    ts.set_token(token)
    pro = ts.pro_api()
    
    # 1. è·å–ç›®æ ‡äº¤æ˜“æ—¥å†
    target_dates = get_trade_cal(pro, start_date, end_date)
    if not target_dates:
        return pd.DataFrame(), "æ— æ³•è·å–äº¤æ˜“æ—¥å†"
        
    # 2. æ£€æŸ¥æœ¬åœ°æ•°æ®
    existing_dates = set()
    if os.path.exists(DATA_FILE):
        try:
            # åªè¯»æ—¥æœŸåˆ—ï¼ŒåŠ å¿«é€Ÿåº¦
            df_dates = pd.read_csv(DATA_FILE, usecols=['trade_date'], dtype={'trade_date': str})
            existing_dates = set(df_dates['trade_date'].unique())
        except:
            pass # æ–‡ä»¶å¯èƒ½æŸåæˆ–ä¸ºç©º
            
    # 3. è®¡ç®—ç¼ºå¤±æ—¥æœŸ
    missing_dates = sorted(list(set(target_dates) - existing_dates))
    
    # 4. å¦‚æœæœ‰ç¼ºå¤±ï¼Œè¿›è¡Œå¢é‡ä¸‹è½½
    if missing_dates:
        st.info(f"å‘ç° {len(missing_dates)} ä¸ªæ–°äº¤æ˜“æ—¥ï¼Œå¼€å§‹å¢é‡æ›´æ–°...")
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        new_data = []
        
        # æ‰¹é‡ä¸‹è½½ç¼“å†² (æ¯10å¤©å­˜ä¸€æ¬¡ç›˜ï¼Œé˜²æ­¢å†…å­˜çˆ†)
        batch_size = 5
        
        for i, date in enumerate(missing_dates):
            try:
                status_text.text(f"æ­£åœ¨ä¸‹è½½: {date} ...")
                
                # ä¸‹è½½è¡Œæƒ…
                df_daily = pro.daily(trade_date=date)
                # ä¸‹è½½æŒ‡æ ‡
                df_basic = pro.daily_basic(trade_date=date, fields='ts_code,turnover_rate,volume_ratio,circ_mv')
                
                if not df_daily.empty and not df_basic.empty:
                    # åˆå¹¶
                    df_merged = pd.merge(df_daily, df_basic, on='ts_code', how='left')
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼ç»Ÿä¸€
                    df_merged['trade_date'] = str(date)
                    new_data.append(df_merged)
                
            except Exception as e:
                st.warning(f"{date} ä¸‹è½½å¤±è´¥: {e}")
                time.sleep(1)
            
            # è¿›åº¦æ¡
            progress_bar.progress((i + 1) / len(missing_dates))
            
            # æ‰¹æ¬¡å†™å…¥ (æ–­ç‚¹ç»­ä¼ çš„å…³é”®ï¼šä¸‹ä¸€ç‚¹å­˜ä¸€ç‚¹)
            if len(new_data) >= batch_size or (i == len(missing_dates) - 1):
                if new_data:
                    df_batch = pd.concat(new_data)
                    # è¿½åŠ æ¨¡å¼å†™å…¥ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åŒ…å«header
                    mode = 'a' if os.path.exists(DATA_FILE) else 'w'
                    header = not os.path.exists(DATA_FILE)
                    df_batch.to_csv(DATA_FILE, mode=mode, header=header, index=False)
                    new_data = [] # æ¸…ç©ºç¼“å†²
                    
        status_text.text("å¢é‡æ›´æ–°å®Œæˆï¼")
        progress_bar.empty()
        
    # 5. è¯»å–å…¨é‡æ•°æ® (ä¸ºäº†ç­–ç•¥è®¡ç®—)
    # æ—¢ç„¶æ˜¯å›æµ‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€æ®µè¿ç»­çš„æ•°æ®
    # è¿™é‡Œè¯»å–æ–‡ä»¶ï¼Œå¹¶æ ¹æ®æ—¥æœŸè¿‡æ»¤
    if os.path.exists(DATA_FILE):
        # æ˜¾å¼æŒ‡å®šç±»å‹ï¼Œé˜²æ­¢ pandas çŒœé”™
        dtype_dict = {'ts_code': str, 'trade_date': str}
        df_all = pd.read_csv(DATA_FILE, dtype=dtype_dict)
        
        # è¿‡æ»¤å‡ºéœ€è¦çš„æ—¥æœŸèŒƒå›´
        df_all = df_all[(df_all['trade_date'] >= start_date) & (df_all['trade_date'] <= end_date)]
        
        # å»é‡ (é˜²æ­¢é‡å¤å†™å…¥)
        df_all = df_all.drop_duplicates(subset=['ts_code', 'trade_date'])
        
        # è·å–åŸºç¡€ä¿¡æ¯ (è¡Œä¸šåç§°)
        # è¿™ä¸ªä¸ç»å¸¸å˜ï¼Œå¯ä»¥ç”¨ st.cache ç¼“å­˜ä¸€ä¸‹ API è°ƒç”¨
        @st.cache_data
        def get_stock_info():
            df = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,market,industry')
            return df[~df['name'].str.contains('ST')]
            
        df_info = get_stock_info()
        
        return df_all, df_info
    else:
        return pd.DataFrame(), "æ— æ•°æ®"

# ==========================================
# 3. ç­–ç•¥é€»è¾‘ (V18 åŒé¾™ + V19 é“é—¨æ§›)
# ==========================================
def calculate_strategy(df_all, df_info, params):
    # 1. å…³è”è¡Œä¸š
    if 'industry' not in df_all.columns:
        df = pd.merge(df_all, df_info[['ts_code', 'industry', 'name']], on='ts_code', how='left')
    else:
        df = df_all.copy()
        
    # 2. è®¡ç®—å‡çº¿
    df['ma5'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(5).mean())
    df['ma10'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(10).mean())
    df['ma20'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(20).mean())
    df['ma30'] = df.groupby('ts_code')['close'].transform(lambda x: x.rolling(30).mean())
    
    # 3. ç­–ç•¥ A: ä¸Šå¸æŒ‡çº¹ (æ½œä¼)
    df['gap1'] = df['ma5'] - df['ma10']
    df['gap2'] = df['ma10'] - df['ma20']
    df['gap3'] = df['ma20'] - df['ma30']
    df['max_gap'] = df[['gap1', 'gap2', 'gap3']].max(axis=1)
    df['min_gap'] = df[['gap1', 'gap2', 'gap3']].min(axis=1)
    
    cond_order = (df['close'] > df['ma5']) & (df['ma5'] > df['ma10']) & (df['ma10'] > df['ma20'])
    cond_spacing = (df['max_gap'] / (df['min_gap'] + 0.0001)) < params['spacing']
    cond_active = df['pct_chg'] > 2.0
    
    df['signal_A'] = cond_order & cond_spacing & cond_active
    
    # 4. ç­–ç•¥ B: è¿½å‡» (æš´åŠ›)
    cond_limit = df['pct_chg'] > 9.5
    cond_vol = df['volume_ratio'] > params['vol_ratio']
    cond_trend = df['close'] > df['ma5']
    
    df['signal_B'] = cond_limit & cond_vol & cond_trend
    
    df['is_signal'] = df['signal_A'] | df['signal_B']
    df['strategy_type'] = np.where(df['signal_B'], 'B:è¿½å‡»', np.where(df['signal_A'], 'A:æ½œä¼', ''))
    
    return df

def run_backtest_iron(df_signals, df_all, cal_dates):
    # æ„å»º Lookup
    df_lookup = df_all.copy()
    # ç¡®ä¿æœ‰ MA10 å’Œ Pre_Close
    if 'ma10' not in df_lookup.columns:
         df_lookup['ma10'] = df_lookup.groupby('ts_code')['close'].transform(lambda x: x.rolling(10).mean())
    
    price_lookup = df_lookup[['ts_code', 'trade_date', 'open', 'close', 'low', 'ma10', 'pre_close']].set_index(['ts_code', 'trade_date'])
    
    trades = []
    
    for row in df_signals.itertuples():
        signal_date = row.trade_date
        code = row.ts_code
        
        # æ‰¾æœªæ¥æ—¥æœŸ
        try:
            curr_idx = cal_dates.index(signal_date)
            future_dates = cal_dates[curr_idx+1 : curr_idx+11]
        except: continue
        
        if not future_dates: continue
        d1_date = future_dates[0]
        
        if (code, d1_date) not in price_lookup.index: continue
        d1_data = price_lookup.loc[(code, d1_date)]
        
        # === é“é—¨æ§›è¿‡æ»¤ ===
        # 1. è®¡ç®—å¼€ç›˜æ¶¨å¹…
        open_pct = (d1_data['open'] - d1_data['pre_close']) / d1_data['pre_close'] * 100
        
        # æ‹’ç»ä½å¼€ (ç»¿ç›˜)
        if open_pct < 0: continue
        # æ‹’ç»é«˜å¼€ > 7%
        if open_pct > 7.0: continue
        
        # === å¼€ä»“ ===
        buy_price = d1_data['open']
        trade = {
            'ä¿¡å·æ—¥': signal_date, 'ä»£ç ': code, 'åç§°': row.name, 'ç­–ç•¥': row.strategy_type,
            'è¡Œä¸š': row.industry, 'ä¹°å…¥ä»·': buy_price, 'å¼€ç›˜æ¶¨å¹…': f"{open_pct:.2f}%", 'çŠ¶æ€': 'æŒæœ‰'
        }
        
        # === D+1 æ­¢æŸåˆ¤å®š ===
        d1_ret = (d1_data['close'] - buy_price) / buy_price
        
        if d1_ret < 0:
            # äºæŸï¼šç¬¬äºŒå¤©è·‘è·¯ (æ”¶ç›Šé”å®šä¸º D+1)
            trade['çŠ¶æ€'] = 'D+1æ­¢æŸ'
            trade['D+1'] = round(d1_ret * 100, 2)
            for n in range(1, 10):
                 trade[f"D+{n+1}"] = round(d1_ret * 100, 2)
        else:
            # ç›ˆåˆ©ï¼šMA10 è·Ÿè¸ªæ­¢ç›ˆ
            trade['D+1'] = round(d1_ret * 100, 2)
            triggered = False
            for n in range(1, 10):
                if n >= len(future_dates): break
                f_date = future_dates[n]
                if (code, f_date) not in price_lookup.index: break
                f_data = price_lookup.loc[(code, f_date)]
                
                day_key = f"D+{n+1}"
                if not triggered:
                    if f_data['close'] < f_data['ma10']:
                        triggered = True
                        trade['çŠ¶æ€'] = 'æ­¢ç›ˆ'
                    curr_ret = (f_data['close'] - buy_price) / buy_price * 100
                    trade[day_key] = round(curr_ret, 2)
                else:
                    trade[day_key] = trade.get(f"D+{n}", 0)
        
        trades.append(trade)
        
    return pd.DataFrame(trades)

# ==========================================
# 4. ä¸»ç¨‹åº
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ V20 æ°¸ä¸ç£¨ç­ç‰ˆ")
    user_token = st.text_input("Tushare Token:", type="password")
    
    st.info("ğŸ“… æ•°æ®ç®¡ç†")
    days_back = st.slider("å›æµ‹å¤©æ•°", 30, 150, 60)
    end_date_input = st.date_input("æˆªæ­¢æ—¥æœŸ", datetime.now().date())
    
    st.markdown("---")
    st.info("ğŸ› ç­–ç•¥å‚æ•° (ä¿®æ”¹ä¸è§¦å‘ä¸‹è½½)")
    spacing = st.number_input("ç­–ç•¥A: å‡åŒ€åº¦ <", 1.0, 3.0, 1.5)
    vol_ratio = st.number_input("ç­–ç•¥B: é‡æ¯” >", 1.0, 5.0, 2.0)
    top_n = st.number_input("Top N", 1, 10, 3)
    
    if st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜æ•°æ® (æ…ç‚¹)"):
        if os.path.exists(DATA_FILE):
            os.remove(DATA_FILE)
            st.success("ç¼“å­˜å·²æ¸…é™¤ï¼Œä¸‹æ¬¡è¿è¡Œå°†å…¨é‡ä¸‹è½½ã€‚")
            
    run_btn = st.button("ğŸš€ å¯åŠ¨ç³»ç»Ÿ")

if run_btn:
    if not user_token:
        st.error("è¯·å…ˆè¾“å…¥ Token")
    else:
        # 1. å‡†å¤‡æ—¥æœŸèŒƒå›´
        end_str = end_date_input.strftime('%Y%m%d')
        start_dt = end_date_input - timedelta(days=days_back * 1.5 + 80) # å¤šä¸‹ç‚¹ç”¨äºç®—å‡çº¿
        start_str = start_dt.strftime('%Y%m%d')
        
        # 2. åŒæ­¥æ•°æ® (å¢é‡)
        res, info = sync_market_data(user_token, start_str, end_str)
        
        if isinstance(info, pd.DataFrame):
            df_info = info
            df_all = res
            
            st.success(f"âœ… æ•°æ®åŠ è½½å®Œæ¯•: {len(df_all):,} è¡Œ (æ¥è‡ª {DATA_FILE})")
            
            # 3. è®¡ç®—ç­–ç•¥
            with st.spinner("ç­–ç•¥å¼•æ“è¿è¡Œä¸­..."):
                params = {'spacing': spacing, 'vol_ratio': vol_ratio}
                df_calc = calculate_strategy(df_all, df_info, params)
                
            # 4. æå–ä¿¡å·
            cal_dates = sorted(df_calc['trade_date'].unique())
            valid_dates = cal_dates[-(days_back):]
            
            df_signals = df_calc[(df_calc['trade_date'].isin(valid_dates)) & (df_calc['is_signal'])].copy()
            df_signals = df_signals.sort_values(['trade_date', 'volume_ratio'], ascending=[True, False])
            
            # Top N
            df_signals['æ’å'] = df_signals.groupby('trade_date').cumcount() + 1
            df_top = df_signals[df_signals['æ’å'] <= top_n].copy()
            
            st.write(f"âšª åŸå§‹ä¿¡å·: **{len(df_top)}** ä¸ª")
            
            # 5. å›æµ‹ (é“é—¨æ§›)
            if not df_top.empty:
                df_res = run_backtest_iron(df_top, df_calc, cal_dates)
                
                if not df_res.empty:
                    st.success(f"ğŸ¯ é“é—¨æ§›æˆäº¤: **{len(df_res)}** å•")
                    
                    st.markdown(f"### ğŸ“Š V20 æœ€ç»ˆå›æµ‹")
                    cols = st.columns(5)
                    days = ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']
                    for idx, d in enumerate(days):
                         if d in df_res.columns:
                             avg = df_res[d].mean()
                             if d == 'D+1':
                                 rate = (df_res[d] > 0).mean() * 100
                                 cols[idx].metric(f"{d} èƒœç‡", f"{rate:.1f}%")
                             cols[idx].metric(f"{d} å‡æ”¶", f"{avg:.2f}%")
                    
                    st.dataframe(df_res.sort_values(['ä¿¡å·æ—¥'], ascending=False), use_container_width=True)
                else:
                    st.warning("æ‰€æœ‰ä¿¡å·å‡è¢«é“é—¨æ§›æ‹¦æˆªã€‚")
            else:
                st.warning("æ— ä¿¡å·ã€‚")
        else:
            st.error(info)
