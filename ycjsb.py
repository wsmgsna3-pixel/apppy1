import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import time
import warnings

warnings.filterwarnings("ignore")

# ==========================================
# 1. é¡µé¢é…ç½®ä¸å…¨å±€è®¾ç½®
# ==========================================
st.set_page_config(page_title="ä¸‰æ—¥æˆå¦–Â·è¯Šæ–­å›æµ‹ç‰ˆ", layout="wide")
st.title("ğŸ•µï¸â€â™€ï¸ ä¸‰æ—¥æˆå¦–Â·è¯Šæ–­å›æµ‹ç³»ç»Ÿ (å«æ¼æ–—åˆ†æ)")
st.markdown("""
**ä½¿ç”¨æŠ€å·§ï¼š**
1. **å…³äºç¼“å­˜**ï¼šä¿®æ”¹â€œå›æµ‹å¤©æ•°â€ä¼šå¯¼è‡´é‡æ–°ä¸‹è½½æ•°æ®ï¼ˆè¿™æ˜¯å¿…é¡»çš„ï¼‰ã€‚å»ºè®®ä¸€æ¬¡æ€§è®¾ä¸º **100å¤©**ï¼Œä¸‹è½½å®Œæˆåï¼Œå†åå¤è°ƒæ•´â€œé‡èƒ½å€æ•°â€ï¼Œæ­¤æ—¶ä¸ä¼šè§¦å‘ä¸‹è½½ï¼Œä»¥æ­¤å®ç°â€œç§’çº§è°ƒå‚â€ã€‚
2. **å…³äºè¯Šæ–­**ï¼šå‘ä¸‹æ»šåŠ¨æŸ¥çœ‹ã€ç­›é€‰æ¼æ–—è¯Šæ–­ã€‘åŒºåŸŸï¼Œè§‚å¯Ÿæ¯ä¸€æ­¥å‰”é™¤äº†å¤šå°‘è‚¡ç¥¨ã€‚
""")

# ==========================================
# 2. æ ¸å¿ƒæ•°æ®å¼•æ“ (å¸¦é‡è¯•ä¸é™æµ)
# ==========================================
@st.cache_data(persist="disk", show_spinner=False)
def get_trade_cal(token, start_date, end_date):
    """è·å–äº¤æ˜“æ—¥å† (å¸¦é‡è¯•)"""
    ts.set_token(token)
    pro = ts.pro_api()
    for attempt in range(3):
        try:
            df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open='1')
            if not df.empty:
                return df['cal_date'].tolist()
            time.sleep(0.5)
        except:
            time.sleep(1)
    return []

@st.cache_data(persist="disk", show_spinner=False)
def fetch_all_market_data_by_date(token, date_list):
    """
    æ‰¹é‡æ‹‰å–å…¨å¸‚åœºæ•°æ® (æ ¸å¿ƒåŠ é€Ÿç¯èŠ‚ + é™æµä¿æŠ¤)
    """
    ts.set_token(token)
    pro = ts.pro_api()
    
    data_list = []
    total = len(date_list)
    
    # è¿›åº¦æ¡
    bar = st.progress(0, text="æ­£åœ¨æ‰¹å‘å…¨å¸‚åœºæ•°æ® (é¦–æ¬¡è¿è¡Œéœ€ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…)...")
    
    for i, date in enumerate(date_list):
        try:
            # === æ ¸å¿ƒä¿®å¤ï¼šæ¯æ¬¡è¯·æ±‚å‰æš‚åœ 0.08 ç§’ï¼Œé˜²æ­¢ QPS è¶…é™ ===
            time.sleep(0.08)
            
            # ä¸€æ¬¡æ€§æ‹‰å–å½“å¤©æ‰€æœ‰è‚¡ç¥¨
            df = pro.daily(trade_date=date)
            
            # åªä¿ç•™æ ¸å¿ƒå­—æ®µå‡å°å†…å­˜
            if not df.empty:
                df = df[['ts_code', 'trade_date', 'open', 'high', 'low', 'close', 'pre_close', 'vol', 'amount', 'pct_chg']]
                data_list.append(df)
        except Exception as e:
            time.sleep(1)
            # print(f"æ—¥æœŸ {date} è·å–å¤±è´¥: {e}")
            
        if (i+1) % 5 == 0:
            bar.progress((i+1)/total, text=f"åŠ è½½æ•°æ®: {date} ({i+1}/{total})")
            
    bar.empty()
    
    if not data_list:
        return pd.DataFrame()
        
    # åˆå¹¶ä¸ºä¸€ä¸ªå·¨å¤§çš„ DataFrame
    full_df = pd.concat(data_list)
    # æŒ‰è‚¡ç¥¨å’Œæ—¥æœŸæ’åºï¼Œä¸º rolling è®¡ç®—åšå‡†å¤‡
    full_df = full_df.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    return full_df

@st.cache_data(persist="disk", show_spinner=False)
def get_stock_basics(token):
    """
    è·å–åŸºç¡€ä¿¡æ¯ (å¸¦é‡è¯•æœºåˆ¶ï¼Œé˜²æ­¢ API æŠ¥é”™)
    """
    ts.set_token(token)
    pro = ts.pro_api()
    
    for attempt in range(3):
        try:
            time.sleep(0.5) 
            df = pro.stock_basic(exchange='', list_status='L', fields='ts_code,name,market,list_date')
            if not df.empty:
                # å‰”é™¤ ST / åŒ—äº¤æ‰€
                df = df[~df['name'].str.contains('ST')]
                df = df[~df['market'].str.contains('åŒ—äº¤')]
                df = df[~df['ts_code'].str.contains('BJ')]
                return df
        except Exception as e:
            time.sleep(1)
            
    st.error("æ— æ³•è·å–è‚¡ç¥¨åŸºç¡€åˆ—è¡¨ã€‚å¯èƒ½æ˜¯ Tushare æ¥å£ç¹å¿™ï¼Œè¯·ç¨åå†è¯•ã€‚")
    return pd.DataFrame()

# ==========================================
# 3. å‘é‡åŒ–ä¿¡å·è®¡ç®— (å«è¯Šæ–­é€»è¾‘)
# ==========================================
def calculate_signals_vectorized(df):
    """
    åŸºç¡€æŒ‡æ ‡è®¡ç®— (ä¸åŒ…å«å‚æ•°è¿‡æ»¤ï¼Œæ–¹ä¾¿åç»­åå¤è°ƒå‚)
    """
    # 1. è®¡ç®—æ½œä¼æœŸå‡é‡ (Lag 3å¤©ï¼Œå–è¿‡å»60å¤©)
    df['latent_vol_avg'] = df.groupby('ts_code')['vol'].transform(lambda x: x.shift(3).rolling(window=60).mean())
    
    # 2. è®¡ç®—çˆ†å‘æœŸå‡é‡ (æœ€è¿‘ 3 å¤©)
    df['burst_vol_avg'] = df.groupby('ts_code')['vol'].transform(lambda x: x.rolling(window=3).mean())
    
    # 3. è®¡ç®— 3æ—¥ ç´¯è®¡æ¶¨å¹… (å¤åˆ©è®¡ç®—)
    df['daily_factor'] = 1 + df['pct_chg'] / 100
    df['cum_rise_3d'] = df.groupby('ts_code')['daily_factor'].transform(lambda x: x.rolling(window=3).apply(np.prod, raw=True))
    df['cum_rise_3d'] = (df['cum_rise_3d'] - 1) * 100
    
    # 4. è·å– Day 1 çš„æ¶¨å¹…
    df['day1_pct'] = df.groupby('ts_code')['pct_chg'].transform(lambda x: x.shift(2))
    
    # 5. è·å–é‡å¿ƒä¸Šç§»é€»è¾‘
    df['day1_close'] = df.groupby('ts_code')['close'].transform(lambda x: x.shift(2))
    
    return df

# ==========================================
# 4. ä¸»ç¨‹åºé€»è¾‘
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°è®¾ç½®")
    user_token = st.text_input("Tushare Token:", type="password")
    
    # æç¤ºç”¨æˆ·å…³äºç¼“å­˜çš„é€»è¾‘
    st.info("ğŸ’¡ æç¤ºï¼šä¿®æ”¹'å›æµ‹å¤©æ•°'æˆ–'ç»“æŸæ—¥æœŸ'ä¼šè§¦å‘é‡æ–°ä¸‹è½½æ•°æ®ã€‚ä¿®æ”¹'é‡èƒ½å€æ•°'åˆ™æ˜¯ç§’å‡ºç»“æœã€‚")
    
    days_back = st.slider("å›æµ‹å¤©æ•°", 20, 200, 50)
    end_date_input = st.date_input("ç»“æŸæ—¥æœŸ", datetime.now().date())
    
    st.markdown("---")
    vol_mul = st.slider("é‡èƒ½å€æ•°", 1.5, 5.0, 2.0, 0.1, help="å»ºè®®ä»2.0å¼€å§‹å°è¯•")
    
    run_btn = st.button("ğŸš€ å¯åŠ¨å›æµ‹ (å¸¦è¯Šæ–­)")

def run_diagnostic_backtest():
    if not user_token:
        st.error("è¯·è¾“å…¥ Token")
        return

    # 1. å‡†å¤‡æ—¥æœŸ
    end_str = end_date_input.strftime('%Y%m%d')
    start_dt = end_date_input - timedelta(days=days_back * 1.5 + 100) # å®½æ¾ç¼“å†²
    
    cal_dates = get_trade_cal(user_token, start_dt.strftime('%Y%m%d'), end_str)
    if not cal_dates:
        st.error("è·å–æ—¥å†å¤±è´¥ï¼Œè¯·æ£€æŸ¥Token")
        return

    # 2. æ•°æ®åŠ è½½ (Cached)
    # åªè¦ cal_dates ä¸å˜ï¼Œè¿™é‡Œå°±ä¼šç›´æ¥è¯»å–ç£ç›˜ç¼“å­˜ï¼Œä¸ä¼šé‡æ–°ä¸‹è½½
    df_all = fetch_all_market_data_by_date(user_token, cal_dates)
    if df_all.empty:
        st.error("æ•°æ®åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–Token")
        return
        
    st.success(f"âœ… æ•°æ®å‡†å¤‡å°±ç»ªï¼å†…å­˜ä¸­å…±æœ‰ {len(df_all):,} æ¡ Kçº¿æ•°æ®ã€‚")

    # 3. åŸºç¡€ä¿¡æ¯åŒ¹é…
    df_basic = get_stock_basics(user_token)
    if df_basic.empty:
        df_basic = pd.DataFrame(columns=['ts_code', 'name', 'market'])
    
    # åªä¿ç•™åŸºç¡€è¡¨é‡Œæœ‰çš„è‚¡ç¥¨
    df_all = df_all[df_all['ts_code'].isin(df_basic['ts_code'])]
    df_all = pd.merge(df_all, df_basic[['ts_code', 'name', 'market']], on='ts_code', how='left')

    # 4. è®¡ç®—æŒ‡æ ‡ (Vectorized)
    with st.spinner("æ­£åœ¨è®¡ç®—å…¨å¸‚åœºæŒ‡æ ‡..."):
        df_calc = calculate_signals_vectorized(df_all)
    
    # 5. åº”ç”¨æ¿å—æ¶¨å¹…é˜ˆå€¼
    is_startup = df_calc['market'].str.contains('åˆ›ä¸š|ç§‘åˆ›', na=False) | df_calc['ts_code'].str.startswith(('30', '68'))
    df_calc['rise_threshold'] = np.where(is_startup, 20.0, 12.0)
    
    # ==========================================
    # ğŸ•µï¸â€â™€ï¸ æ ¸å¿ƒè¯Šæ–­æ¼æ–— (Funnel Analysis)
    # ==========================================
    st.markdown("### ğŸ•µï¸â€â™€ï¸ ç­›é€‰æ¼æ–—è¯Šæ–­ (Diagnostic Funnel)")
    st.caption("ğŸ‘‡ è§‚å¯Ÿä¸‹æ–¹æ•°æ®ï¼Œæ‰¾å‡ºå“ªä¸€æ­¥ç­›é€‰æ¡ä»¶è¿‡äºä¸¥è‹›")
    
    # æ­¥éª¤ 1: åŸºç¡€æ± 
    # å¿…é¡»æœ‰ latent_vol_avg (è¯´æ˜æ•°æ®è¶³å¤Ÿé•¿èƒ½ç®—å‡ºå‡çº¿)
    cond_valid_data = df_calc['latent_vol_avg'].notna()
    cond_basic = (df_calc['close'] >= 10) & (df_calc['amount'] > 50000)
    
    # ä»…ç»Ÿè®¡åœ¨å›æµ‹åŒºé—´å†…çš„æ—¥æœŸ
    valid_dates = cal_dates[-(days_back + 10) : -10]
    df_in_window = df_calc[df_calc['trade_date'].isin(valid_dates)]
    
    # å®æ—¶è®¡ç®—æ¼æ–—
    step0 = len(df_in_window)
    st.write(f"âšª **åˆå§‹æ ·æœ¬**: {step0:,} æ¡ Kçº¿ (åœ¨å›æµ‹åŒºé—´å†…)")
    
    step1 = len(df_in_window[cond_basic])
    st.write(f"1ï¸âƒ£ **åŸºç¡€é—¨æ§›** (ä»·>10, é‡>5000ä¸‡): å‰©ä½™ **{step1:,}** æ¡")
    
    # æ­¥éª¤ 2: é‡èƒ½å…³
    cond_vol = df_in_window['burst_vol_avg'] > (df_in_window['latent_vol_avg'] * vol_mul)
    step2 = len(df_in_window[cond_basic & cond_vol])
    st.write(f"2ï¸âƒ£ **é‡èƒ½ç­›é€‰** (>{vol_mul}å€): å‰©ä½™ **{step2:,}** æ¡ (å…³é”®ç“¶é¢ˆ)")
    
    # æ­¥éª¤ 3: å½¢æ€å…³
    cond_shape = (df_in_window['day1_pct'] > 5) & (df_in_window['close'] > df_in_window['day1_close'])
    step3 = len(df_in_window[cond_basic & cond_vol & cond_shape])
    st.write(f"3ï¸âƒ£ **å½¢æ€ç­›é€‰** (Day1å¤§é˜³+é‡å¿ƒä¸Šç§»): å‰©ä½™ **{step3:,}** æ¡")
    
    # æ­¥éª¤ 4: æ¶¨å¹…å…³
    cond_rise = df_in_window['cum_rise_3d'] > df_in_window['rise_threshold']
    final_mask = cond_basic & cond_vol & cond_shape & cond_rise
    
    df_signals = df_in_window[final_mask].copy()
    st.write(f"4ï¸âƒ£ **æ¶¨å¹…ç­›é€‰** (ä¸»æ¿>12%/åŒåˆ›>20%): æœ€ç»ˆä¹°ç‚¹ **{len(df_signals)}** ä¸ª")

    if df_signals.empty:
        st.error("âŒ ç»“æœä¸ºç©ºï¼è¯·è°ƒä½ã€é‡èƒ½å€æ•°ã€‘é‡è¯•ï¼ˆæ— éœ€é‡æ–°ä¸‹è½½æ•°æ®ï¼‰ã€‚")
        return

    st.success(f"âš¡ å‘ç° {len(df_signals)} ä¸ªæœ‰æ•ˆäº¤æ˜“ä¿¡å·ï¼Œæ­£åœ¨è®¡ç®—æœ€ç»ˆæ”¶ç›Š...")

    # 6. æ”¶ç›Šè®¡ç®—
    trades = []
    # ä¼˜åŒ–ï¼šåªä¿ç•™éœ€è¦çš„åˆ—å»ºç«‹ç´¢å¼•
    price_lookup = df_calc[['ts_code', 'trade_date', 'open', 'close', 'low']].set_index(['ts_code', 'trade_date'])
    
    progress = st.progress(0)
    total_sig = len(df_signals)
    
    for i, row in enumerate(df_signals.itertuples()):
        progress.progress((i+1)/total_sig)
        
        signal_date = row.trade_date
        code = row.ts_code
        
        try:
            curr_idx = cal_dates.index(signal_date)
            future_dates = cal_dates[curr_idx+1 : curr_idx+11]
        except: continue
            
        if not future_dates: continue
        
        d1_date = future_dates[0]
        if (code, d1_date) not in price_lookup.index: continue
        d1_data = price_lookup.loc[(code, d1_date)]
        
        # é£æ§ï¼šD+1 ä½å¼€ < -5%
        if (d1_data['open'] - d1_data.get('pre_close', row.close)) / row.close < -0.05:
            continue
            
        buy_price = d1_data['open']
        stop_price = buy_price * 0.90
        
        trade = {
            'ä¿¡å·æ—¥': signal_date,
            'ä»£ç ': code,
            'åç§°': row.name,
            '3æ—¥æ¶¨å¹…': round(row.cum_rise_3d, 1),
            'ä¹°å…¥ä»·': buy_price,
            'çŠ¶æ€': 'æŒæœ‰'
        }
        
        triggered = False
        for n, f_date in enumerate(future_dates):
            if (code, f_date) not in price_lookup.index: break
            f_data = price_lookup.loc[(code, f_date)]
            
            if not triggered:
                if f_data['low'] <= stop_price:
                    triggered = True
                    trade['çŠ¶æ€'] = 'æ­¢æŸ'
                    ret = -10.0
                else:
                    ret = (f_data['close'] - buy_price) / buy_price * 100
            else:
                ret = -10.0
            
            day_label = f"D+{n+1}"
            if day_label in ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']:
                trade[day_label] = round(ret, 2)
        
        trades.append(trade)
        
    progress.empty()
    
    if trades:
        df_res = pd.DataFrame(trades)
        st.markdown("### ğŸ“ˆ å›æµ‹ç»“æœåˆ†æ")
        
        cols = st.columns(5)
        days = ['D+1', 'D+3', 'D+5', 'D+7', 'D+10']
        for idx, d in enumerate(days):
            if d in df_res.columns:
                win = len(df_res[df_res[d]>0]) / len(df_res) * 100
                avg = df_res[d].mean()
                cols[idx].metric(f"{d} èƒœç‡", f"{win:.1f}%")
                cols[idx].metric(f"{d} å‡æ”¶", f"{avg:.2f}%")
        
        st.dataframe(df_res.sort_values('ä¿¡å·æ—¥', ascending=False))
    else:
        st.warning("æ‰€æœ‰ä¿¡å·å‡è¢« D+1 ä½å¼€é£æ§æ‹¦æˆªï¼Œæ— å®é™…æˆäº¤ã€‚")

if run_btn:
    run_diagnostic_backtest()
