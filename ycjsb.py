# -*- coding: utf-8 -*-
"""
é€‰è‚¡ç‹ Â· V30.11.3 ç¨³å®šå›æµ‹ç‰ˆ
æ ¸å¿ƒä¿®å¤ï¼š
1. **API é™æµä¿æŠ¤**ï¼šå¢åŠ  request é—´éš”ï¼Œè§£å†³å›  Tushare é¢‘æ§å¯¼è‡´å›æµ‹å¡åœ¨ ~40 å¤©(10æœˆ23æ—¥)çš„é—®é¢˜ã€‚
2. **æ˜¾ç¤ºå¢å¼º**ï¼šæ¢å¤ D3/D5 æ”¶ç›Šç‡åœ¨è¯¦æƒ…è¡¨ä¸­çš„æ˜¾ç¤ºã€‚
3. **æ—¥å†ç®—æ³•**ï¼šä¼˜åŒ–äº¤æ˜“æ—¥è·å–é€»è¾‘ï¼Œæ”¯æŒè¶…é•¿å‘¨æœŸå›æµ‹ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import warnings
import time  # å¼•å…¥æ—¶é—´æ¨¡å—ç”¨äºé™æµ
warnings.filterwarnings("ignore")

# ---------------------------
# å…¨å±€å˜é‡åˆå§‹åŒ–
# ---------------------------
pro = None 
GLOBAL_ADJ_FACTOR = pd.DataFrame() 
GLOBAL_DAILY_RAW = pd.DataFrame() 
GLOBAL_QFQ_BASE_FACTORS = {} 

# ---------------------------
# é¡µé¢è®¾ç½®
# ---------------------------
st.set_page_config(page_title="é€‰è‚¡ç‹ V30.11ï¼šç¨³å®šç‰ˆ", layout="wide")
st.title("é€‰è‚¡ç‹ V30.11ï¼šç¨³å®šå›æµ‹ç‰ˆï¼ˆâœ… é˜²é™æµ & å…¨æ˜¾ç¤ºï¼‰")
st.markdown("""
**ç‰ˆæœ¬æ›´æ–°è¯´æ˜ (V30.11.3)ï¼š**
1. ğŸ¢ **æ™ºèƒ½é™æµ**ï¼šå·²å¢åŠ  API è°ƒç”¨é—´éš”ï¼Œé˜²æ­¢å›æµ‹ 100+ å¤©æ—¶å› è§¦å‘ Tushare é¢‘æ§è€Œä¸­æ–­ã€‚
2. ğŸ‘ï¸ **å…¨æ™¯æ”¶ç›Š**ï¼šè¯¦æƒ…è¡¨ç°åœ¨ä¼šå®Œæ•´æ˜¾ç¤º D1 / D3 / D5 æ”¶ç›Šç‡ã€‚
""")

# ---------------------------
# è¾…åŠ©å‡½æ•°
# ---------------------------
@st.cache_data(ttl=3600*12) 
def safe_get(func_name, **kwargs):
    global pro
    if pro is None: return pd.DataFrame(columns=['ts_code']) 
    func = getattr(pro, func_name) 
    try:
        # å¢åŠ æçŸ­çš„éšæœºå»¶æ—¶ï¼Œå‡è½»æœåŠ¡å™¨å‹åŠ›
        if kwargs.get('is_index'): df = pro.index_daily(**kwargs)
        else: df = func(**kwargs)
        if df is None or df.empty: return pd.DataFrame(columns=['ts_code']) 
        return df
    except Exception as e: return pd.DataFrame(columns=['ts_code'])

def get_trade_days(end_date_str, num_days):
    # --- ä¿®å¤é€»è¾‘ï¼šå¼ºåˆ¶æ‹‰å–è‡³å°‘ä¸€å¹´çš„æ—¥å†ï¼Œç¡®ä¿ä¸ç®¡å›æµ‹å¤šå°‘å¤©éƒ½æœ‰æ•°æ® ---
    lookback_days = max(num_days * 3, 365) 
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=lookback_days)).strftime("%Y%m%d")
    
    cal = safe_get('trade_cal', start_date=start_date, end_date=end_date_str)
    if cal.empty: return []
    
    trade_days_df = cal[cal['is_open'] == 1].sort_values('cal_date', ascending=False)
    # å†æ¬¡ç¡®ä¿åªå– end_date ä¹‹å‰çš„
    trade_days_df = trade_days_df[trade_days_df['cal_date'] <= end_date_str]
    
    # è¿”å›æŒ‡å®šæ•°é‡çš„äº¤æ˜“æ—¥
    return trade_days_df['cal_date'].head(num_days).tolist()

@st.cache_data(ttl=3600*24)
def fetch_and_cache_daily_data(date):
    adj_df = safe_get('adj_factor', trade_date=date)
    daily_df = safe_get('daily', trade_date=date)
    return {'adj': adj_df, 'daily': daily_df}

def get_all_historical_data(trade_days_list):
    global GLOBAL_ADJ_FACTOR, GLOBAL_DAILY_RAW, GLOBAL_QFQ_BASE_FACTORS
    if not trade_days_list: return False
    
    latest_trade_date = max(trade_days_list) 
    earliest_trade_date = min(trade_days_list)
    
    # æ‰©å¤§ç¼“å†²åŒº
    start_date_dt = datetime.strptime(earliest_trade_date, "%Y%m%d") - timedelta(days=200)
    end_date_dt = datetime.strptime(latest_trade_date, "%Y%m%d") + timedelta(days=30)
    start_date = start_date_dt.strftime("%Y%m%d")
    end_date = end_date_dt.strftime("%Y%m%d")
    
    all_trade_dates_df = safe_get('trade_cal', start_date=start_date, end_date=end_date, is_open='1')
    all_dates = all_trade_dates_df['cal_date'].tolist()
    
    st.info(f"â³ æ­£åœ¨é¢„åŠ è½½ {start_date} åˆ° {end_date} çš„å…¨å¸‚åœºæ•°æ® (ä¸ºäº†è®¡ç®—æŒ‡æ ‡ï¼Œéœ€ä¸‹è½½æ›´å¤šå†å²)...")

    adj_factor_data_list = [] 
    daily_data_list = []
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_text = "æ•°æ®ä¸‹è½½ä¸­ï¼Œè¯·ç¨å€™..."
    my_bar = st.progress(0, text=progress_text)
    
    total_steps = len(all_dates)
    
    for i, date in enumerate(all_dates):
        try:
            cached_data = fetch_and_cache_daily_data(date)
            if not cached_data['adj'].empty: adj_factor_data_list.append(cached_data['adj'])
            if not cached_data['daily'].empty: daily_data_list.append(cached_data['daily'])
            
            # --- é™æµä¿æŠ¤ï¼šæ¯å¤„ç† 20 å¤©ä¼‘æ¯ä¸€ä¸‹ï¼Œé˜²æ­¢æ‰¹é‡ä¸‹è½½è¢«å° ---
            if i % 20 == 0: time.sleep(0.05)
            
            # æ›´æ–°è¿›åº¦æ¡
            if i % 5 == 0:
                my_bar.progress((i + 1) / total_steps, text=f"æ­£åœ¨ä¸‹è½½: {date}")
                
        except Exception: continue 
            
    my_bar.empty()

    if not adj_factor_data_list or not daily_data_list: return False
     
    # åˆå¹¶å¤„ç†
    adj_factor_data = pd.concat(adj_factor_data_list)
    adj_factor_data['adj_factor'] = pd.to_numeric(adj_factor_data['adj_factor'], errors='coerce').fillna(0)
    # å»é‡å¹¶å»ºç«‹ç´¢å¼•
    GLOBAL_ADJ_FACTOR = adj_factor_data.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1]) 
    
    daily_raw_data = pd.concat(daily_data_list)
    GLOBAL_DAILY_RAW = daily_raw_data.drop_duplicates(subset=['ts_code', 'trade_date']).set_index(['ts_code', 'trade_date']).sort_index(level=[0, 1])

    # ç¼“å­˜æœ€æ–°çš„å¤æƒå› å­åŸºå‡†
    latest_global_date = GLOBAL_ADJ_FACTOR.index.get_level_values('trade_date').max()
    if latest_global_date:
        # è·å–æœ€æ–°ä¸€å¤©çš„æ‰€æœ‰è‚¡ç¥¨å¤æƒå› å­
        try:
            latest_adj_df = GLOBAL_ADJ_FACTOR.loc[(slice(None), latest_global_date), 'adj_factor']
            GLOBAL_QFQ_BASE_FACTORS = latest_adj_df.droplevel(1).to_dict()
        except:
            GLOBAL_QFQ_BASE_FACTORS = {}
    
    return True

def get_qfq_data_v4_optimized_final(ts_code, start_date, end_date):
    global GLOBAL_DAILY_RAW, GLOBAL_ADJ_FACTOR, GLOBAL_QFQ_BASE_FACTORS
    
    if GLOBAL_DAILY_RAW.empty: return pd.DataFrame()
    
    # å¿«é€Ÿè·å–åŸºå‡†å› å­
    latest_adj_factor = GLOBAL_QFQ_BASE_FACTORS.get(ts_code, np.nan)
    if pd.isna(latest_adj_factor): return pd.DataFrame() 

    try:
        # åˆ‡ç‰‡è·å–ä¸ªè‚¡æ•°æ® (åˆ©ç”¨ MultiIndex ä¼˜åŠ¿)
        daily_df = GLOBAL_DAILY_RAW.loc[ts_code]
        daily_df = daily_df.loc[(daily_df.index >= start_date) & (daily_df.index <= end_date)]
        
        adj_series = GLOBAL_ADJ_FACTOR.loc[ts_code]['adj_factor']
        adj_series = adj_series.loc[(adj_series.index >= start_date) & (adj_series.index <= end_date)]
    except KeyError: return pd.DataFrame()
    
    if daily_df.empty or adj_series.empty: return pd.DataFrame()
    
    # åˆå¹¶
    df = daily_df.merge(adj_series.rename('adj_factor'), left_index=True, right_index=True, how='left').dropna(subset=['adj_factor'])
    
    # å‰å¤æƒè®¡ç®—
    for col in ['open', 'high', 'low', 'close', 'pre_close']:
        if col in df.columns:
            df[col + '_qfq'] = df[col] * df['adj_factor'] / latest_adj_factor
    
    df = df.reset_index().rename(columns={'trade_date': 'trade_date_str'})
    df = df.sort_values('trade_date_str').set_index('trade_date_str')
    
    # è¦†ç›–åŸåˆ—
    for col in ['open', 'high', 'low', 'close']: df[col] = df[col + '_qfq']
    
    return df[['open', 'high', 'low', 'close', 'vol']].copy() 

def get_future_prices(ts_code, selection_date, d0_qfq_close, days_ahead=[1, 3, 5]):
    d0 = datetime.strptime(selection_date, "%Y%m%d")
    start_future = (d0 + timedelta(days=1)).strftime("%Y%m%d")
    end_future = (d0 + timedelta(days=15)).strftime("%Y%m%d") # å¾€åæ‰¾15å¤©å¤Ÿäº†
    
    hist = get_qfq_data_v4_optimized_final(ts_code, start_date=start_future, end_date=end_future)
    results = {}
    
    if hist.empty: return results
    
    hist['close'] = pd.to_numeric(hist['close'], errors='coerce')
    
    for n in days_ahead:
        col = f'Return_D{n}'
        if len(hist) >= n and d0_qfq_close > 0:
            results[col] = (hist.iloc[n-1]['close'] / d0_qfq_close - 1) * 100
        else:
            results[col] = np.nan
    return results

def calculate_rsi(series, period=12):
    delta = series.diff()
    gain = (delta.where(delta > 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    loss = (-delta.where(delta < 0, 0)).ewm(alpha=1/period, adjust=False).mean()
    rs = gain / loss
    return 100 - (100 / (1 + rs))

@st.cache_data(ttl=3600*12) 
def compute_indicators(ts_code, end_date):
    start_date = (datetime.strptime(end_date, "%Y%m%d") - timedelta(days=150)).strftime("%Y%m%d")
    df = get_qfq_data_v4_optimized_final(ts_code, start_date=start_date, end_date=end_date)
    res = {}
  
    if df.empty or len(df) < 26: return res 
    
    df['pct_chg'] = df['close'].pct_change().fillna(0) * 100 
    close = df['close']
    res['last_close'] = close.iloc[-1]
    res['last_open'] = df['open'].iloc[-1]
    res['last_high'] = df['high'].iloc[-1]
    res['last_low'] = df['low'].iloc[-1]
    
    # MACD
    ema12 = close.ewm(span=12, adjust=False).mean()
    ema26 = close.ewm(span=26, adjust=False).mean()
    diff = ema12 - ema26
    dea = diff.ewm(span=9, adjust=False).mean()
    res['macd_val'] = ((diff - dea) * 2).iloc[-1]
        
    # MA & Bias
    res['ma20'] = close.tail(20).mean()
    res['ma60'] = close.tail(60).mean()
    
    if pd.notna(res['ma20']) and res['ma20'] > 0:
        res['bias_20'] = (res['last_close'] - res['ma20']) / res['ma20'] * 100
    else: res['bias_20'] = 0

    # Position
    hist_60 = df.tail(60)
    res['position_60d'] = (close.iloc[-1] - hist_60['low'].min()) / (hist_60['high'].max() - hist_60['low'].min() + 1e-9) * 100
        
    # RSI (12)
    rsi_series = calculate_rsi(close, period=12)
    res['rsi_12'] = rsi_series.iloc[-1]
    
    res['volatility'] = df['pct_chg'].tail(10).std() if len(df)>=10 else 0
    
    return res

@st.cache_data(ttl=3600*12)
def get_market_state(trade_date):
    start_date = (datetime.strptime(trade_date, "%Y%m%d") - timedelta(days=40)).strftime("%Y%m%d")
    index_data = safe_get('daily', ts_code='000300.SH', start_date=start_date, end_date=trade_date, is_index=True)
    if index_data.empty or len(index_data) < 20: return 'Weak'
    
    index_data = index_data.sort_values('trade_date')
    latest_close = index_data.iloc[-1]['close']
    ma20 = index_data['close'].tail(20).mean()
    
    return 'Strong' if latest_close > ma20 else 'Weak'
       
# ----------------------------------------------------
# ä¾§è¾¹æ å‚æ•° 
# ----------------------------------------------------
with st.sidebar:
    st.header("æ¨¡å¼ä¸æ—¥æœŸé€‰æ‹©")
    backtest_date_end = st.date_input("å›æµ‹ç»“æŸæ—¥æœŸ", value=datetime.now().date())
    BACKTEST_DAYS = int(st.number_input("è‡ªåŠ¨å›æµ‹å¤©æ•° (N)", value=50, step=1))
    
    st.markdown("---")
    st.header("æ ¸å¿ƒå‚æ•°")
    FINAL_POOL = int(st.number_input("å…¥å›´è¯„åˆ†æ•°é‡", value=100)) 
    TOP_BACKTEST = int(st.number_input("å›æµ‹åˆ†æ Top K", value=5)) 
    
    st.markdown("---")
    st.header("ğŸ›¡ï¸ V30.11 æ ¸å¿ƒ Alpha å‚æ•°")
    MAX_UPPER_SHADOW = st.number_input("æœ€å¤§ä¸Šå½±çº¿æ¯”ä¾‹ (%)", value=4.0)
    MIN_BODY_POS = st.number_input("æœ€ä½å®ä½“ä½ç½® (0-1)", value=0.7)
    MAX_TURNOVER_RATE = st.number_input("æœ€å¤§æ¢æ‰‹ç‡ (%)", value=20.0)
    
    # éšè—å‚æ•°
    MIN_PRICE, MAX_PRICE = 10.0, 300.0
    MIN_TURNOVER = 5.0 
    MIN_CIRC_MV_BILLIONS, MAX_CIRC_MV_BILLIONS = 20.0, 200.0
    MIN_AMOUNT = 100000000

# ---------------------------
# Token 
# ---------------------------
TS_TOKEN = st.text_input("Tushare Token", type="password")
if not TS_TOKEN: st.stop()
ts.set_token(TS_TOKEN)
pro = ts.pro_api() 

# ----------------------------------------------------------------------
# æ ¸å¿ƒå›æµ‹é€»è¾‘å‡½æ•° 
# ----------------------------------------------------------------------
def run_backtest_for_a_day(last_trade, TOP_BACKTEST, FINAL_POOL, MAX_UPPER_SHADOW, MAX_TURNOVER_RATE, MIN_BODY_POS): 
    market_state = get_market_state(last_trade)
    
    # 1. åŸºç¡€æ•°æ®
    daily_all = safe_get('daily', trade_date=last_trade) 
    if daily_all.empty: return pd.DataFrame(), f"æ•°æ®ç¼ºå¤± {last_trade}"

    daily_basic = safe_get('daily_basic', trade_date=last_trade, fields='ts_code,turnover_rate,circ_mv,total_mv,amount')
    mf_raw = safe_get('moneyflow', trade_date=last_trade) 
    stock_basic = safe_get('stock_basic', list_status='L', fields='ts_code,name,list_date')
    
    # åˆå¹¶
    df = daily_all.merge(stock_basic, on='ts_code', how='left')
    if not daily_basic.empty: df = df.merge(daily_basic, on='ts_code', how='left')
    else: df['turnover_rate'] = 0; df['circ_mv'] = 0; df['amount'] = 0
    
    if not mf_raw.empty:
        mf = mf_raw[['ts_code','net_mf_amount']].rename(columns={'net_mf_amount':'net_mf'})
        df = df.merge(mf, on='ts_code', how='left')
    df['net_mf'] = df['net_mf'].fillna(0)
    
    # æ¸…æ´—
    df['close'] = pd.to_numeric(df['close'], errors='coerce')
    df['open'] = pd.to_numeric(df['open'], errors='coerce')
    df['high'] = pd.to_numeric(df['high'], errors='coerce')
    df['low'] = pd.to_numeric(df['low'], errors='coerce')
    df['circ_mv_billion'] = pd.to_numeric(df['circ_mv'], errors='coerce').fillna(0) / 10000
    df['amount'] = pd.to_numeric(df['amount'], errors='coerce').fillna(0) * 1000
    df = df[~df['name'].str.contains('ST|é€€', na=False)]
    df = df[~df['ts_code'].str.startswith('92')]
    df['list_date'] = pd.to_datetime(df['list_date'], errors='coerce')
    df = df[(datetime.strptime(last_trade, "%Y%m%d") - df['list_date']).dt.days > 120]
    
    # è¿‡æ»¤
    df = df[(df['close'] >= MIN_PRICE) & (df['close'] <= MAX_PRICE)]
    df = df[(df['circ_mv_billion'] >= MIN_CIRC_MV_BILLIONS) & (df['circ_mv_billion'] <= MAX_CIRC_MV_BILLIONS)]
    df = df[df['turnover_rate'] >= MIN_TURNOVER]
    df = df[df['amount'] >= MIN_AMOUNT]
    df = df[df['turnover_rate'] <= MAX_TURNOVER_RATE] 

    if len(df) == 0: return pd.DataFrame(), "è¿‡æ»¤åæ— æ ‡çš„"

    # åˆç­›
    limit_mf = int(FINAL_POOL * 0.5)
    df_mf = df.sort_values('net_mf', ascending=False).head(limit_mf)
    limit_pct = FINAL_POOL - len(df_mf)
    df_pct = df[~df['ts_code'].isin(df_mf['ts_code'])].sort_values('pct_chg', ascending=False).head(limit_pct)
    final_candidates = pd.concat([df_mf, df_pct]).reset_index(drop=True)
    
    # æ·±åº¦è®¡ç®—
    records = []
    for row in final_candidates.itertuples():
        ts_code = row.ts_code
        ind = compute_indicators(ts_code, last_trade)
        d0_close = ind.get('last_close', np.nan)
        d0_high = ind.get('last_high', np.nan)
        d0_low = ind.get('last_low', np.nan)
        d0_ma60 = ind.get('ma60', np.nan)
        d0_ma20 = ind.get('ma20', np.nan)
        d0_pos60 = ind.get('position_60d', np.nan)
        d0_rsi = ind.get('rsi_12', 50)
        d0_bias = ind.get('bias_20', 0)
        
        # è¿‡æ»¤å™¨
        if pd.isna(d0_ma60) or d0_close < d0_ma60: continue
            
        if pd.notna(d0_high) and pd.notna(d0_close) and d0_close > 0:
            upper_shadow = (d0_high - d0_close) / d0_close * 100
            if upper_shadow > MAX_UPPER_SHADOW: continue 
        
        if pd.notna(d0_high) and pd.notna(d0_low) and pd.notna(d0_close):
            range_len = d0_high - d0_low
            if range_len > 0:
                body_pos = (d0_close - d0_low) / range_len
                if body_pos < MIN_BODY_POS: continue 

        if market_state == 'Weak':
            if pd.isna(d0_ma20) or d0_close < d0_ma20: continue 
            if pd.notna(d0_pos60) and d0_pos60 > 20.0: continue

        # è®°å½•æ”¶ç›Š
        if pd.notna(d0_close):
            future = get_future_prices(ts_code, last_trade, d0_close)
            rec = {
                'ts_code': ts_code, 'name': row.name,
                'Close': row.close, 'Pct_Chg': row.pct_chg,
                'Turnover': row.turnover_rate,
                'macd': ind.get('macd_val', 0),
                'rsi': d0_rsi, 
                'bias': d0_bias, 
                'net_mf': row.net_mf,
                'Return_D1 (%)': future.get('Return_D1', np.nan),
                'Return_D3 (%)': future.get('Return_D3', np.nan),
                'Return_D5 (%)': future.get('Return_D5', np.nan),
            }
            records.append(rec)
            
    fdf = pd.DataFrame(records)
    if fdf.empty: return pd.DataFrame(), "æ·±åº¦ç­›é€‰åæ— æ ‡çš„"
    
    # è¯„åˆ†
    def normalize(s): 
        if s.max() == s.min(): return pd.Series([0.5] * len(s), index=s.index) 
        return (s - s.min()) / (s.max() - s.min() + 1e-9)
    
    fdf['s_mf'] = normalize(fdf['net_mf'])
    fdf['s_rsi_safety'] = 1 - normalize(fdf['rsi']) 
    fdf['s_bias_safety'] = 1 - normalize(fdf['bias']) 
    fdf['s_safety'] = (fdf['s_rsi_safety'] * 0.5 + fdf['s_bias_safety'] * 0.5) 

    if market_state == 'Strong':
        fdf['ç­–ç•¥'] = 'V30.11 Alpha å¼ºå¸‚'
        fdf_strong = fdf[fdf['macd'] > 0].copy()
        if fdf_strong.empty: fdf['Score'] = 0
        else:
            fdf_strong['s_alpha'] = fdf_strong['macd'] * 10000 + fdf_strong['s_mf'] * 50
            fdf_strong['Score'] = fdf_strong['s_alpha'] * 0.8 + fdf_strong['s_safety'] * 0.2
            fdf = fdf_strong.sort_values('Score', ascending=False)
    else:
        fdf['ç­–ç•¥'] = 'V30.11 Alpha å¼±å¸‚'
        fdf['s_macd'] = normalize(fdf['macd'])
        fdf['s_alpha'] = fdf['s_macd'] * 0.6 + fdf['s_mf'] * 0.4
        fdf['Score'] = fdf['s_alpha'] * 0.8 + fdf['s_safety'] * 0.2
        fdf = fdf.sort_values('Score', ascending=False)
        
    return fdf.head(TOP_BACKTEST), None

# ---------------------------
# ä¸»è¿è¡Œå—
# ---------------------------
if st.button(f"ğŸš€ è¿è¡Œ V30.11 ç¨³å®šå›æµ‹ç‰ˆ ({BACKTEST_DAYS}å¤©)"):
    
    try:
        trade_days = get_trade_days(backtest_date_end.strftime("%Y%m%d"), BACKTEST_DAYS)
        st.info(f"ğŸ“… è®¡åˆ’å›æµ‹äº¤æ˜“æ—¥æ•°é‡: {len(trade_days)} å¤©")
        if len(trade_days) < BACKTEST_DAYS:
            st.warning("âš ï¸ è·å–çš„äº¤æ˜“æ—¥å°‘äºé¢„æœŸï¼Œå¯èƒ½æ˜¯å› ä¸ºæ—¥å†æ•°æ®æ›´æ–°å»¶è¿Ÿæˆ–å‡æœŸã€‚")
    except Exception:
        st.error("æ— æ³•æ‰¾åˆ° Tushare äº¤æ˜“æ—¥æ•°æ®ï¼Œè¯·æ£€æŸ¥ Tushare Tokenã€‚")
        st.stop()

    if not get_all_historical_data(trade_days): 
        st.error("æ•°æ®ä¸‹è½½å¤±è´¥æˆ–ç¼ºå¤±ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        st.stop()
    
    results = []
    bar = st.progress(0, text="å¼€å§‹å›æµ‹...")
    
    for i, date in enumerate(trade_days):
        res, err = run_backtest_for_a_day(date, TOP_BACKTEST, FINAL_POOL, MAX_UPPER_SHADOW, MAX_TURNOVER_RATE, MIN_BODY_POS)
        if not res.empty:
            res['Trade_Date'] = date
            results.append(res)
        
        # --- æ ¸å¿ƒä¿®å¤ï¼šé˜²æ­¢ Tushare é¢‘æ§çš„å…³é”® ---
        # æ¯æ¬¡å›æµ‹å®Œä¸€å¤©ï¼Œæš‚åœ 0.2 ç§’ã€‚è¿™ä¼šä½¿å›æµ‹å˜æ…¢ï¼Œä½†èƒ½ç¡®ä¿æ•°æ®ä¸æ–­æµã€‚
        time.sleep(0.2) 
        
        bar.progress((i+1)/len(trade_days), text=f"æ­£åœ¨åˆ†æ: {date}")
        
    bar.empty()
    
    if results:
        all_res = pd.concat(results)
        
        st.header("ğŸ“Š V30.11 å›æµ‹ç»“æœç»Ÿè®¡")
        cols = st.columns(3)
        for idx, n in enumerate([1, 3, 5]):
            col_name = f'Return_D{n} (%)'
            valid = all_res.dropna(subset=[col_name])
            if not valid.empty:
                avg = valid[col_name].mean()
                win = (valid[col_name] > 0).mean() * 100
                cols[idx].metric(f"D+{n} å¹³å‡æ”¶ç›Š/èƒœç‡", f"{avg:.2f}% / {win:.1f}%")
        
        st.subheader("ğŸ“‹ è¯¦ç»†å›æµ‹æ¸…å• (å« D1/D3/D5)")
        
        # --- ä¿®å¤æ˜¾ç¤ºï¼šæ˜ç¡®æŒ‡å®šæ˜¾ç¤ºçš„åˆ—ï¼ŒåŒ…å«æ‰€æœ‰æ”¶ç›Šç‡ ---
        display_cols = ['Trade_Date','name','ts_code','Close','Pct_Chg',
                        'Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)',
                        'rsi','bias','ç­–ç•¥']
        
        # ç¡®ä¿åˆ—å­˜åœ¨æ‰æ˜¾ç¤º
        final_cols = [c for c in display_cols if c in all_res.columns]
        st.dataframe(all_res[final_cols], use_container_width=True)
        
        # æä¾›ä¸‹è½½
        csv = all_res.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´å›æµ‹ç»“æœ CSV", csv, "backtest_results.csv", "text/csv")
        
    else:
        st.info("å›æµ‹å®Œæˆï¼Œä½†æ²¡æœ‰é€‰å‡ºç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ã€‚")
import pandas as pd

# 1. è¯»å–ä½ çš„å›æµ‹ç»“æœæ–‡ä»¶
# ç¡®ä¿æ–‡ä»¶åå’Œä½ å¯¼å‡ºçš„ä¸€è‡´
df = pd.read_csv('backtest_results.csv')

# 2. æ•°æ®æ¸…æ´—ï¼šå»é™¤ D1, D3, D5 ä»»æ„ä¸€ä¸ªä¸ºç©ºçš„æ•°æ®ï¼Œä¿è¯æ ·æœ¬ä¸€è‡´
df_clean = df.dropna(subset=['Return_D1 (%)', 'Return_D3 (%)', 'Return_D5 (%)']).copy()

print(f"å‚ä¸ç»Ÿè®¡çš„æœ‰æ•ˆäº¤æ˜“ç¬”æ•°: {len(df_clean)} ç¬”")

# ==========================================
# åœºæ™¯ A: D1 ä¸Šæ¶¨æ‰ä¹°å…¥ (å³ä¾§äº¤æ˜“)
# ==========================================
# ç­›é€‰ D1 æ”¶ç›Š > 0 çš„è¡Œ
df_buy = df_clean[df_clean['Return_D1 (%)'] > 0].copy()

# è®¡ç®—â€œçœŸå®æŒæœ‰æ”¶ç›Šâ€ï¼šå› ä¸ºä½ æ˜¯D1æ¶¨äº†æ‰ä¹°(å‡è®¾D1æ”¶ç›˜ä»·ä¹°å…¥)ï¼Œæ‰€ä»¥ä½ çš„æˆæœ¬æ˜¯D1çš„ä»·æ ¼
# çœŸå®æ”¶ç›Šå…¬å¼ = (1+D5æ”¶ç›Š) / (1+D1æ”¶ç›Š) - 1
df_buy['Real_Yield_D3'] = ((1 + df_buy['Return_D3 (%)']/100) / (1 + df_buy['Return_D1 (%)']/100) - 1) * 100
df_buy['Real_Yield_D5'] = ((1 + df_buy['Return_D5 (%)']/100) / (1 + df_buy['Return_D1 (%)']/100) - 1) * 100

# ç»Ÿè®¡æ•°æ®
print("\n=== ç­–ç•¥ A: D0é€‰å‡ºï¼ŒD1ä¸Šæ¶¨ç¡®è®¤å(æ”¶ç›˜)ä¹°å…¥ ===")
print(f"è§¦å‘ä¹°å…¥æ¬¡æ•°: {len(df_buy)} ({len(df_buy)/len(df_clean):.1%} çš„é€‰è‚¡è¢«æ‰§è¡Œ)")
print(f"D3 (æŒæœ‰2å¤©) èƒœç‡: {(df_buy['Return_D3 (%)'] > 0).mean():.2%}")  # è¿™é‡Œçš„èƒœç‡é€šå¸¸æŒ‡ç›¸å¯¹äºD0ä¹Ÿæ˜¯èµšçš„
print(f"D3 çœŸå®å¹³å‡æ”¶ç›Š: {df_buy['Real_Yield_D3'].mean():.2f}%")
print(f"D5 (æŒæœ‰4å¤©) èƒœç‡: {(df_buy['Return_D5 (%)'] > 0).mean():.2%}")
print(f"D5 çœŸå®å¹³å‡æ”¶ç›Š: {df_buy['Real_Yield_D5'].mean():.2f}%")

# ==========================================
# åœºæ™¯ B: è¶‹åŠ¿å»¶ç»­æ¦‚ç‡ (æ¡ä»¶æ¦‚ç‡)
# é—®é¢˜ï¼šå¦‚æœ D1ä¸Šæ¶¨ ä¸” D3ä¸Šæ¶¨ï¼ŒD5 ç»§ç»­ä¸Šæ¶¨çš„æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
# ==========================================
# ç­›é€‰ D1 > 0 ä¸” D3 > 0 çš„è¡Œ (å³å‰3å¤©è¶‹åŠ¿å®Œå¥½)
df_trend = df_buy[df_buy['Return_D3 (%)'] > 0].copy()

# åœ¨è¿™éƒ¨åˆ†æ ·æœ¬ä¸­ï¼Œè®¡ç®— D5 > 0 çš„æ¯”ä¾‹
prob_d5_continuation = (df_trend['Return_D5 (%)'] > 0).mean()

print("\n=== åœºæ™¯ B: è¶‹åŠ¿å»¶ç»­æ¦‚ç‡ ===")
print(f"å‡ºç° [D1æ¶¨ + D3æ¶¨] çš„å½¢æ€æ¬¡æ•°: {len(df_trend)}")
print(f"ğŸ‘‰ å¦‚æœ D1æ¶¨ä¸”D3æ¶¨ï¼ŒD5ç»§ç»­ä¸Šæ¶¨çš„æ¦‚ç‡: {prob_d5_continuation:.2%}")
