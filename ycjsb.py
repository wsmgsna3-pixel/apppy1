# -*- coding: utf-8 -*-
"""
ç¬¬ä¸€å 5.0 é«˜ä¿çœŸÂ·ç‹¬äº«ç‰ˆ (High Fidelity)
-------------------------------------------------
ã€æ ¸å¿ƒè®¾è®¡ç†å¿µã€‘
1. æ•°æ®å®Œæ•´æ€§ç¬¬ä¸€ï¼šæ‹’ç»ä¸ºäº†é€Ÿåº¦é˜‰å‰²æ•°æ®ï¼Œå…¨ç¨‹åŠ è½½ OHLCV å®Œæ•´å­—æ®µã€‚
2. ç²¾åº¦æ— æŸï¼šæ”¾å¼ƒ Float32 å‹ç¼©ï¼Œå…¨ç¨‹ä½¿ç”¨ Float64 åŒç²¾åº¦è®¡ç®—ï¼Œå¯¹æ ‡åˆ¸å•†è½¯ä»¶ç²¾åº¦ã€‚
3. ç¨³å¥æ»‘çª—ï¼šé‡‡ç”¨â€œ20å¤©æ­¥è¿› + å®Œæ•´å†å²é‡è½½â€æ¨¡å¼ï¼Œå®å¯æ…¢ï¼Œä¸å¯å´©ã€‚
4. åˆšæ€§é£æ§ï¼šå†…ç½® -4% æ­¢æŸä¸ T+1 é«˜å¼€é€»è¾‘ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import gc
import time
import os
import warnings

# ---------------------------
# 1. å…¨å±€é…ç½®
# ---------------------------
st.set_page_config(page_title="ç¬¬ä¸€å 5.0 é«˜ä¿çœŸç‰ˆ", layout="wide")
warnings.filterwarnings("ignore")

if 'pro' not in st.session_state:
    st.session_state.pro = None
if 'ts_token' not in st.session_state:
    st.session_state.ts_token = ""

# ---------------------------
# 2. UI ç•Œé¢
# ---------------------------
st.title("ğŸ† ç¬¬ä¸€å 5.0 é«˜ä¿çœŸÂ·ç‹¬äº«ç‰ˆ")
st.markdown("""
> **âš ï¸ éƒ‘é‡æç¤ºï¼š** > æœ¬ç‰ˆæœ¬ä¸º**å…¨æ•°æ®ç²¾åº¦ç‰ˆ**ï¼Œä¸å†è¿½æ±‚æè‡´é€Ÿåº¦ï¼Œè€Œæ˜¯è¿½æ±‚**æ•°æ®çš„ç»å¯¹å®Œæ•´æ€§**ã€‚  
> 500å¤©å›æµ‹é¢„è®¡è€—æ—¶ **40-90åˆ†é’Ÿ**ï¼ˆå–å†³äºç½‘ç»œï¼‰ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚ç³»ç»Ÿä¼šå®æ—¶ä¿å­˜ç»“æœï¼Œéšæ—¶å¯æ–­ç‚¹ç»­ä¼ ã€‚
""")

with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        new_token = st.text_input("ğŸ’ Tushare Token (è¯·è¾“å…¥æ‚¨çš„Token)", value=st.session_state.ts_token, type="password")
        if new_token:
            st.session_state.ts_token = new_token
            ts.set_token(new_token)
            st.session_state.pro = ts.pro_api()
    with col2:
        st.write("") 
        st.write("") 
        start_btn = st.button("ğŸ¢ å¯åŠ¨é«˜ä¿çœŸå›æµ‹", type="primary", use_container_width=True)

with st.expander("âš™ï¸ ç­–ç•¥å‚æ•° (å·²è°ƒä¼˜)", expanded=True):
    c1, c2, c3 = st.columns(3)
    with c1:
        backtest_days = st.number_input("å›æµ‹å¤©æ•°", value=500, step=50, help="å»ºè®®500å¤©ä»¥è¦†ç›–2024å¹´åˆçš„è‚¡ç¾")
        stop_loss_pct = st.number_input("æ­¢æŸé˜ˆå€¼ (%)", value=-4.0, step=0.5, help="ç›˜ä¸­è§¦åŠå³æ­¢æŸ")
    with c2:
        min_price = st.number_input("æœ€ä½è‚¡ä»·", value=40.0)
        max_price = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0)
    with c3:
        buy_threshold = st.number_input("ä¹°å…¥é˜ˆå€¼ (%)", value=1.5)
        top_k = st.number_input("æ¯æ—¥æŒä»“ (Top K)", value=3, min_value=1, help="è‡ªç”±è®¾ç½®ï¼Œæ¨è 3 æˆ– 5")

# ---------------------------
# 3. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ---------------------------
def get_trade_days(end_date_str, num_days):
    """è·å–ç›®æ ‡å›æµ‹çš„äº¤æ˜“æ—¥å†"""
    # è¿™é‡Œåªè·å–æˆ‘ä»¬è¦å›æµ‹çš„é‚£500å¤©ï¼Œä¸åŒ…å«ç¼“å†²æœŸ
    # ç¼“å†²æœŸåœ¨ batch å†…éƒ¨åŠ¨æ€è®¡ç®—ï¼Œä¿è¯æ•°æ®æ–°é²œ
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 2 + 365)).strftime("%Y%m%d")
    if st.session_state.pro:
        try:
            cal = st.session_state.pro.trade_cal(start_date=start_date, end_date=end_date_str, is_open='1')
            # å–æœ€è¿‘çš„ num_days å¤©
            return cal.sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()
        except: return []
    return []

def load_processed_dates(filepath):
    """æ–­ç‚¹ç»­ä¼ ï¼šè¯»å–å·²å®Œæˆæ—¥æœŸ"""
    if not os.path.exists(filepath): return set()
    try:
        df = pd.read_csv(filepath, usecols=['trade_date'], dtype={'trade_date': str})
        return set(df['trade_date'].unique().tolist())
    except: return set()

# ---------------------------
# 4. é«˜ä¿çœŸæ•°æ®åŠ è½½å¼•æ“
# ---------------------------
def fetch_full_precision_data(target_days):
    """
    ã€é«˜ä¿çœŸåŠ è½½ã€‘
    é’ˆå¯¹ç»™å®šçš„ target_days (æ¯”å¦‚20å¤©)ï¼Œ
    1. è‡ªåŠ¨å‘å‰æ¨ 180 å¤© (History Buffer)
    2. è‡ªåŠ¨å‘åæ¨ 30 å¤© (Future Buffer)
    3. å®Œæ•´æ‹‰å– OHLCVï¼Œä¸åšåˆ—è£å‰ªï¼Œä¸åš float32 å‹ç¼©ã€‚
    """
    if not target_days: return None
    
    # 1. è®¡ç®—æ—¶é—´çª—å£
    start_date = min(target_days)
    end_date = max(target_days)
    
    # å†å²ç¼“å†² (MACDéœ€è¦)
    buffer_start = (datetime.strptime(start_date, "%Y%m%d") - timedelta(days=180)).strftime("%Y%m%d")
    # æœªæ¥ç¼“å†² (è®¡ç®—æ”¶ç›Šéœ€è¦)
    future_end = (datetime.strptime(end_date, "%Y%m%d") + timedelta(days=30)).strftime("%Y%m%d")
    
    st.info(f"ğŸ“¥ [å®Œæ•´æ•°æ®åŠ è½½] æ­£åœ¨æ‹‰å–åŒºé—´: {buffer_start} ~ {future_end}")
    
    # 2. è·å–è¯¥åŒºé—´æ‰€æœ‰äº¤æ˜“æ—¥
    try:
        cal = st.session_state.pro.trade_cal(start_date=buffer_start, end_date=future_end, is_open='1')
        all_cal_dates = cal['cal_date'].tolist()
    except: return None
    
    # 3. åˆ†å—æ‹‰å–å®Œæ•´è¡Œæƒ… (Batch Fetching)
    # Tushare å•æ¬¡æ‹‰å–æœ‰é™åˆ¶ï¼Œæˆ‘ä»¬æŒ‰ 50 å¤©ä¸€å—æ‹‰å–
    full_dfs = []
    chunk_size = 50
    
    # è¿›åº¦æ¡
    fetch_bar = st.progress(0)
    
    for i in range(0, len(all_cal_dates), chunk_size):
        chunk = all_cal_dates[i:i+chunk_size]
        s_chunk, e_chunk = chunk[0], chunk[-1]
        
        try:
            # [å…³é”®] æ‹‰å–å®Œæ•´å­—æ®µï¼Œä¸è¿›è¡Œé˜‰å‰²
            df = st.session_state.pro.daily(
                start_date=s_chunk, 
                end_date=e_chunk, 
                fields='ts_code,trade_date,open,high,low,close,pre_close,vol,amount'
            )
            if not df.empty:
                # [å…³é”®] ä¿æŒ float64 ç²¾åº¦ (Pandas é»˜è®¤)ï¼Œä¸å¼ºè½¬ float32
                full_dfs.append(df)
        except Exception as e:
            st.warning(f"æ•°æ®æ‹‰å–é‡è¯•ä¸­: {e}")
            time.sleep(1)
            continue
            
        fetch_bar.progress(min((i + chunk_size) / len(all_cal_dates), 1.0))
        time.sleep(0.05) # ä¸»åŠ¨ä¼‘çœ ï¼Œé˜²æ­¢è§¦å‘ Tushare æµæ§
        
    fetch_bar.empty()
    
    if not full_dfs: return None
    
    # åˆå¹¶
    df_big = pd.concat(full_dfs).sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    
    # 4. æ‹‰å–å¤æƒå› å­ (å¿…é¡»)
    st.caption("ğŸ”§ æ­£åœ¨æ‹‰å–å¤æƒå› å­...")
    adj_dfs = []
    for i in range(0, len(all_cal_dates), chunk_size):
        chunk = all_cal_dates[i:i+chunk_size]
        s_chunk, e_chunk = chunk[0], chunk[-1]
        try:
            adj = st.session_state.pro.adj_factor(start_date=s_chunk, end_date=e_chunk, fields='ts_code,trade_date,adj_factor')
            if not adj.empty:
                adj_dfs.append(adj)
        except: pass
        
    if adj_dfs:
        adj_all = pd.concat(adj_dfs)
        df_big = pd.merge(df_big, adj_all, on=['ts_code', 'trade_date'], how='left')
        df_big['adj_factor'] = df_big['adj_factor'].fillna(method='ffill').fillna(1.0)
        # è®¡ç®—åå¤æƒä»·æ ¼ (High Precision)
        df_big['hfq_close'] = df_big['close'] * df_big['adj_factor']
    else:
        df_big['hfq_close'] = df_big['close']
        
    return df_big

def calculate_indicators_safe(df_big):
    """
    è®¡ç®—æŒ‡æ ‡ï¼Œå…¨ç¨‹ä½¿ç”¨ GroupBy + Transformï¼Œä¸ä½¿ç”¨å‹ç¼©
    """
    st.caption("ğŸ§® æ­£åœ¨è¿›è¡Œé«˜ç²¾åº¦æŒ‡æ ‡è®¡ç®—...")
    
    # ç¡®ä¿æ’åº
    df_big = df_big.sort_values(['ts_code', 'trade_date']).reset_index(drop=True)
    grouped = df_big.groupby('ts_code')['hfq_close']
    
    # MACD (8, 17, 5) - ä½¿ç”¨åå¤æƒä»·æ ¼
    ema8 = grouped.ewm(span=8, adjust=False).mean().reset_index(level=0, drop=True)
    ema17 = grouped.ewm(span=17, adjust=False).mean().reset_index(level=0, drop=True)
    
    df_big['diff'] = ema8 - ema17
    # DEA éœ€è¦åŸºäº diff å†æ¬¡ group
    df_big['dea'] = df_big.groupby('ts_code')['diff'].ewm(span=5, adjust=False).mean().reset_index(level=0, drop=True)
    df_big['macd'] = (df_big['diff'] - df_big['dea']) * 2
    
    # MA20
    df_big['ma20'] = grouped.rolling(20).mean().reset_index(level=0, drop=True)
    
    # MA5_Vol
    df_big['ma5_vol'] = df_big.groupby('ts_code')['vol'].rolling(5).mean().reset_index(level=0, drop=True)
    
    return df_big

def simulate_trade(ts_code, buy_date, buy_price, stop_loss_pct, df_future):
    """
    åœ¨å†…å­˜ä¸­åˆ‡ç‰‡æŸ¥æ‰¾æœªæ¥æ•°æ®ï¼Œè¿›è¡Œæ¨¡æ‹Ÿäº¤æ˜“
    df_future: åŒ…å«è¯¥è‚¡ç¥¨æœªæ¥æ•°æ®çš„ DataFrame åˆ‡ç‰‡
    """
    try:
        # ç­›é€‰æœªæ¥æ—¥æœŸ
        # å‡è®¾ df_future å·²ç»æ˜¯è¯¥è‚¡ç¥¨ä¸”æŒ‰æ—¥æœŸæ’åºçš„æ•°æ®
        # æ‰¾åˆ° buy_date ä¹‹åçš„è¡Œ
        df_after = df_future[df_future['trade_date'] > buy_date].copy()
        
        if df_after.empty: return {}
        
        d1 = df_after.iloc[0]
        
        # 1. ä¹°å…¥æ¡ä»¶æ ¡éªŒ
        # å¿…é¡»é«˜å¼€
        if d1['open'] <= d1['pre_close']: return {'status': 'ä½å¼€æ”¾å¼ƒ'}
        # å‰”é™¤ä¸€å­—æ¿ (å¼€ç›˜ä»· >= æ¶¨åœä»· ä¸” Low >= Open)
        limit_up = d1['pre_close'] * 1.095
        if d1['open'] >= limit_up and d1['low'] >= d1['open']: return {'status': 'ä¸€å­—æ¿æ”¾å¼ƒ'}
        # å¿…é¡»çªç ´ä¹°å…¥ä»·
        if d1['high'] < buy_price: return {'status': 'æœªçªç ´'}
        
        # 2. æ”¶ç›Šè®¡ç®— (å«æ­¢æŸ)
        res = {'status': 'æˆäº¤'}
        stop_price = buy_price * (1 + stop_loss_pct/100)
        
        for n in [1, 3, 5]:
            if len(df_after) >= n:
                triggered_stop = False
                # éå†æŒæœ‰æœŸï¼Œæ£€æŸ¥æ˜¯å¦è§¦åŠæ­¢æŸ
                for i in range(n):
                    current_day = df_after.iloc[i]
                    if current_day['low'] <= stop_price:
                        # è§¦å‘æ­¢æŸ
                        exit_price = min(stop_price, current_day['open'])
                        res[f'Return_D{n} (%)'] = (exit_price / buy_price - 1) * 100
                        res[f'Stop_D{n}'] = True
                        triggered_stop = True
                        break
                
                if not triggered_stop:
                    # æ­£å¸¸æŒæœ‰åˆ°æœŸ
                    close_price = df_after.iloc[n-1]['close']
                    res[f'Return_D{n} (%)'] = (close_price / buy_price - 1) * 100
                    res[f'Stop_D{n}'] = False
        return res
    except: return {}

# ---------------------------
# 5. ä¸»ç¨‹åºé€»è¾‘
# ---------------------------
if start_btn:
    if not st.session_state.ts_token:
        st.error("âŒ è¯·å…ˆè¾“å…¥ Token")
        st.stop()
        
    # 1. è·å–æ‰€æœ‰å›æµ‹æ—¥æœŸ
    end_date_str = datetime.now().strftime("%Y%m%d")
    all_target_days = get_trade_days(end_date_str, backtest_days)
    all_target_days = sorted(all_target_days)
    
    # 2. æ–­ç‚¹ç»­ä¼ 
    results_file = "rank_high_fidelity.csv"
    finished_dates = load_processed_dates(results_file)
    days_to_run = [d for d in all_target_days if d not in finished_dates]
    
    if not days_to_run:
        st.success("ğŸ‰ æ‰€æœ‰æ—¥æœŸå·²å®Œæˆï¼")
        # ä¹Ÿè¦æ˜¾ç¤ºç»“æœ
    else:
        st.info(f"ğŸ“… æœ¬æ¬¡éœ€å›æµ‹ {len(days_to_run)} å¤©ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æ‰¹æ‰§è¡Œ...")

        # 3. ç¨³å¥åˆ†æ‰¹ (Batch Processing)
        # æ—¢ç„¶ç”¨æˆ·æ¥å—æ…¢ï¼Œæˆ‘ä»¬ç”¨ 20 å¤©ä¸€ä¸ª Batchï¼Œä¿è¯å†…å­˜ç»å¯¹å®‰å…¨
        # å¹¶ä¸”æ¯ä¸ª Batch éƒ½é‡æ–°æ‹‰å– History Bufferï¼Œè™½ç„¶æµªè´¹æµé‡ï¼Œä½†é€»è¾‘æœ€ç®€å•æœ€ç¨³
        BATCH_SIZE = 20
        batches = [days_to_run[i:i + BATCH_SIZE] for i in range(0, len(days_to_run), BATCH_SIZE)]
        
        main_progress = st.progress(0)
        status_text = st.empty()
        total_trades = 0
        
        for b_i, batch_days in enumerate(batches):
            status_text.markdown(f"### ğŸ”„ æ­£åœ¨å¤„ç†æ‰¹æ¬¡ {b_i+1}/{len(batches)} ({batch_days[0]} ~ {batch_days[-1]})")
            
            # A. æ‹‰å–å…¨é‡æ•°æ® (History + Batch + Future)
            df_big = fetch_full_precision_data(batch_days)
            
            if df_big is None or df_big.empty:
                st.warning(f"æ‰¹æ¬¡ {b_i+1} æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡")
                continue
                
            # B. è®¡ç®—æŒ‡æ ‡
            df_big = calculate_indicators_safe(df_big)
            
            # C. é€æ—¥å›æµ‹ (Looping)
            batch_results = []
            
            # æ‰¹é‡æ‹‰å– daily_basic (ä¼˜åŒ–ç‚¹)
            basic_map = {} # Key: date, Value: DataFrame
            try:
                b_start, b_end = batch_days[0], batch_days[-1]
                daily_basics = st.session_state.pro.daily_basic(start_date=b_start, end_date=b_end, fields='ts_code,trade_date,turnover_rate,volume_ratio,circ_mv')
                if not daily_basics.empty:
                    for date, group in daily_basics.groupby('trade_date'):
                        basic_map[date] = group
            except: pass

            # æ¯æ—¥å¾ªç¯
            for current_date in batch_days:
                try:
                    # 1. è·å–å½“æ—¥åˆ‡ç‰‡
                    today_data = df_big[df_big['trade_date'] == current_date].copy()
                    if today_data.empty: continue
                    
                    # 2. è·å–å½“æ—¥ Basic
                    if current_date in basic_map:
                        basic = basic_map[current_date]
                        # åˆå¹¶
                        merged = pd.merge(today_data, basic, on='ts_code', how='inner')
                    else:
                        continue
                    
                    # 3. ç­›é€‰ (V30.22 é€»è¾‘)
                    mask = (
                        (merged['hfq_close'] > merged['ma20']) &
                        (merged['vol'] > merged['ma5_vol'] * 1.2) &
                        (merged['macd'] > 0) &
                        (merged['close'] >= min_price) & 
                        (merged['close'] <= max_price) &
                        (merged['turnover_rate'] > 3.0) &
                        (merged['circ_mv'] > 200000) 
                    )
                    candidates = merged[mask].copy()
                    
                    if candidates.empty: continue
                    
                    # 4. è¯„åˆ†
                    candidates['base_score'] = (candidates['macd'] / candidates['hfq_close']) * 1000000
                    candidates['pct_chg'] = (candidates['close'] / candidates['pre_close'] - 1) * 100
                    
                    candidates['bonus'] = 1.0
                    candidates.loc[(candidates['volume_ratio'] > 1.5) & (candidates['volume_ratio'] < 5.0), 'bonus'] += 0.1
                    candidates.loc[(candidates['turnover_rate'] > 5.0) & (candidates['turnover_rate'] < 15.0), 'bonus'] += 0.1
                    candidates.loc[candidates['pct_chg'] > 9.5, 'bonus'] += 0.1
                    
                    candidates['final_score'] = candidates['base_score'] * candidates['bonus']
                    
                    # 5. Top K
                    top_selection = candidates.sort_values('final_score', ascending=False).head(top_k)
                    
                    # 6. æ¨¡æ‹Ÿäº¤æ˜“
                    for row in top_selection.itertuples():
                        buy_price = row.open * (1 + buy_threshold/100)
                        
                        # ä»å†…å­˜ä¸­çš„ df_big æˆªå–è¯¥è‚¡ç¥¨çš„æœªæ¥æ•°æ®
                        stock_future = df_big[df_big['ts_code'] == row.ts_code]
                        
                        res = simulate_trade(row.ts_code, current_date, buy_price, stop_loss_pct, stock_future)
                        
                        if res.get('status') == 'æˆäº¤':
                            rec = {
                                'trade_date': current_date,
                                'ts_code': row.ts_code,
                                'name': 'Unknown',
                                'close': row.close,
                                'score': row.final_score
                            }
                            rec.update(res)
                            batch_results.append(rec)
                            
                except Exception as e:
                    pass
            
            # D. å­˜ç›˜ä¸æ¸…ç†
            if batch_results:
                df_res = pd.DataFrame(batch_results)
                header = not os.path.exists(results_file)
                df_res.to_csv(results_file, mode='a', header=header, index=False, encoding='utf-8-sig')
                total_trades += len(df_res)
                st.toast(f"âœ… ä¿å­˜ {len(df_res)} æ¡è®°å½• | ç´¯è®¡: {total_trades}")
            
            # E. å½»åº•å†…å­˜æ¸…ç†
            del df_big, batch_results
            gc.collect()
            
            # F. ä¸»åŠ¨ä¼‘çœ  (é˜²æ­¢ API è¿‡è½½)
            time.sleep(1)
            main_progress.progress((b_i + 1) / len(batches))

        st.success("ğŸ‰ é«˜ä¿çœŸå›æµ‹å…¨éƒ¨å®Œæˆï¼")
    
    # ---------------------------
    # 6. ç»“æœå±•ç¤º
    # ---------------------------
    st.markdown("---")
    if os.path.exists(results_file):
        try:
            res_df = pd.read_csv(results_file)
            st.subheader("ğŸ“Š å›æµ‹æŠ¥å‘Š (High Fidelity)")
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("æ€»äº¤æ˜“æ¬¡æ•°", len(res_df))
            
            if 'Return_D1 (%)' in res_df.columns:
                avg_d1 = res_df['Return_D1 (%)'].mean()
                win_d1 = (res_df['Return_D1 (%)'] > 0).mean() * 100
                col2.metric("D+1 å‡æ”¶", f"{avg_d1:.2f}%")
                col3.metric("D+1 èƒœç‡", f"{win_d1:.1f}%")
                
                res_df = res_df.sort_values('trade_date')
                # ç®€å•èµ„é‡‘æ›²çº¿ (å‡è®¾å•åˆ©ç´¯åŠ )
                daily_ret = res_df.groupby('trade_date')['Return_D1 (%)'].mean()
                equity = daily_ret.cumsum()
                dd = equity.cummax() - equity
                col4.metric("æœ€å¤§å›æ’¤", f"{dd.max():.2f}")
            
            st.dataframe(res_df, use_container_width=True)
            with open(results_file, "rb") as f:
                st.download_button("ğŸ“¥ ä¸‹è½½ CSV", f, "high_fidelity_result.csv")
        except:
            st.error("ç»“æœè¯»å–å¤±è´¥")
