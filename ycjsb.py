# -*- coding: utf-8 -*-
"""
ç¬¬ä¸€å 4.0 ç»ˆæå®æˆ˜ç‰ˆ (é˜²å´©æºƒ + è‡ªç”±TopK + æ­¢æŸé£æ§)
-------------------------------------------------
æ ¸å¿ƒç‰¹æ€§ï¼š
1. [å†…å­˜æ ¸æ­¦] é‡‡ç”¨åŒè½¨åŠ è½½(Split Loading)æŠ€æœ¯ï¼Œå†å²æ•°æ®åªåŠ è½½Close/Volï¼Œå†…å­˜å ç”¨é™ä½80%ã€‚
2. [é•¿è·‘å† å†›] æ‰¹æ¬¡å¤§å°(Batch Size)é”å®š15å¤©ï¼Œé…åˆFloat32å‹ç¼©ï¼Œè½»æ¾è·‘å®Œ500å¤©+ã€‚
3. [è‡ªç”±ç­–ç•¥] æ”¯æŒè‡ªå®šä¹‰ Top K (å¦‚Top 3)ï¼Œä¸å†å¼ºåˆ¶Top 1ã€‚
4. [æ™ºèƒ½ç»­ä¼ ] è‡ªåŠ¨è·³è¿‡å·²å›æµ‹æ—¥æœŸï¼Œå´©æºƒé‡å¯æ— ç¼è¡”æ¥ã€‚
"""

import streamlit as st
import pandas as pd
import numpy as np
import tushare as ts
from datetime import datetime, timedelta
import gc
import time
import os
import warnings

# è¿‡æ»¤è­¦å‘Š
warnings.filterwarnings("ignore")

# ---------------------------
# 1. å…¨å±€é…ç½®ä¸çŠ¶æ€
# ---------------------------
st.set_page_config(page_title="ç¬¬ä¸€å 4.0 ç»ˆæç‰ˆ", layout="wide")

if 'pro' not in st.session_state:
    st.session_state.pro = None
if 'ts_token' not in st.session_state:
    st.session_state.ts_token = ""

# ---------------------------
# 2. UI ç•Œé¢å¸ƒå±€
# ---------------------------
st.title("ğŸ† ç¬¬ä¸€å 4.0 ç»ˆæå®æˆ˜ç‰ˆ")
st.caption("ğŸš€ 500å¤©å›æµ‹ä¸“ç”¨ | åŒè½¨åŠ è½½å†…æ ¸ | æ­¢æŸé£æ§ | è‡ªç”±æŒä»“")

# é¡¶éƒ¨æ§åˆ¶åŒº
with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        new_token = st.text_input("ğŸ’ Tushare Token (éœ€2000ç§¯åˆ†ä»¥ä¸Š)", value=st.session_state.ts_token, type="password")
        if new_token:
            st.session_state.ts_token = new_token
            ts.set_token(new_token)
            st.session_state.pro = ts.pro_api()
    with col2:
        st.write("") # å ä½
        st.write("") 
        start_btn = st.button("ğŸš€ å¯åŠ¨å›æµ‹", type="primary", use_container_width=True)

# å‚æ•°è®¾ç½®åŒº (é»˜è®¤å±•å¼€)
with st.expander("âš™ï¸ ç­–ç•¥å‚æ•°è®¾ç½® (å¯è‡ªç”±è°ƒæ•´)", expanded=True):
    c1, c2, c3 = st.columns(3)
    with c1:
        # å»ºè®®è·‘ 500 å¤©çœ‹ç©¿è¶Šç‰›ç†Šæ•ˆæœ
        backtest_days = st.number_input("å›æµ‹å¤©æ•°", value=500, step=50, help="å»ºè®®500å¤©")
        stop_loss_pct = st.number_input("æ­¢æŸé˜ˆå€¼ (%)", value=-4.0, step=0.5, help="ç›˜ä¸­è§¦åŠå³æ­¢æŸï¼Œå»ºè®®è®¾ä¸º -4.0")
    with c2:
        # ä»·æ ¼åŒºé—´
        min_price = st.number_input("æœ€ä½è‚¡ä»·", value=40.0)
        max_price = st.number_input("æœ€é«˜è‚¡ä»·", value=300.0)
    with c3:
        buy_threshold = st.number_input("ä¹°å…¥é˜ˆå€¼ (%)", value=1.5, help="é«˜å¼€åä¸Šæ¶¨å¤šå°‘æ‰ä¹°å…¥")
        # [è‡ªç”± Top K] é»˜è®¤è®¾ä¸º 3
        top_k = st.number_input("æ¯æ—¥æŒä»“ (Top K)", value=3, min_value=1, max_value=20, help="è®¾ç½®ä¸º3è¡¨ç¤ºä¹°å‰ä¸‰å")

# ---------------------------
# 3. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ---------------------------
def get_trade_days(end_date_str, num_days):
    """è·å–äº¤æ˜“æ—¥å†"""
    # å¤šå–ä¸€äº›å†—ä½™æ—¥æœŸä»¥é˜²å‡æœŸ
    start_date = (datetime.strptime(end_date_str, "%Y%m%d") - timedelta(days=num_days * 3 + 365)).strftime("%Y%m%d")
    if st.session_state.pro:
        try:
            cal = st.session_state.pro.trade_cal(start_date=start_date, end_date=end_date_str, is_open='1')
            return cal.sort_values('cal_date', ascending=False)['cal_date'].head(num_days).tolist()
        except: return []
    return []

def load_processed_dates(filepath):
    """æ–­ç‚¹ç»­ä¼ ï¼šè¯»å–å·²å®Œæˆæ—¥æœŸ"""
    if not os.path.exists(filepath): return set()
    try:
        df = pd.read_csv(filepath, usecols=['trade_date'], dtype={'trade_date': str})
        return set(df['trade_date'].unique().tolist())
    except: return set()

# ---------------------------
# 4. åŒè½¨åŠ è½½å¼•æ“ (è§£å†³å´©æºƒçš„æ ¸å¿ƒ)
# ---------------------------
def load_data_and_compute_safe(date_list):
    """
    [å†…å­˜æ ¸æ­¦] åŒè½¨åŠ è½½æœºåˆ¶
    è½¨é“1ï¼šå†å²ç¼“å†²æœŸ (150å¤©)ï¼ŒåªåŠ è½½ Close/Volï¼Œè®¡ç®—å®ŒæŒ‡æ ‡ç«‹å³é‡Šæ”¾ã€‚
    è½¨é“2ï¼šå›æµ‹æœŸ (15å¤©)ï¼ŒåŠ è½½ Open/High/Low/Close ç”¨äºäº¤æ˜“åˆ¤æ–­ã€‚
    """
    if not date_list: return None
    
    start_date = min(date_list)
    end_date = max(date_list)
    # å¾€å‰æ¨ 150 å¤©ç”¨äºè®¡ç®— MACD
    buffer_start = (datetime.strptime(start_date, "%Y%m%d") - timedelta(days=160)).strftime("%Y%m%d")
    
    st.info(f"ğŸ“¥ [åŒè½¨åŠ è½½] æ­£åœ¨å‡†å¤‡æ•°æ®: {buffer_start} ~ {end_date} ...")
    
    # === è½¨é“ 1ï¼šè½»é‡åŒ–åŠ è½½å†å²æ•°æ® (è®¡ç®—æŒ‡æ ‡ä¸“ç”¨) ===
    # è¿™ä¸€æ­¥åªæ‹‰å– trade_date, ts_code, close, volã€‚ä¸æ‹‰å– open/high/low/pre_close
    # å†…å­˜å ç”¨ç›´æ¥å‡å°‘ 60%-80%
    
    # è·å–æ‰€æœ‰æ—¥æœŸ
    try:
        cal = st.session_state.pro.trade_cal(start_date=buffer_start, end_date=end_date, is_open='1')
        all_cal_dates = cal['cal_date'].tolist()
    except: return None

    # åˆ†å—æ‹‰å– Close/Vol (é˜²æ­¢ Tushare å•æ¬¡é™åˆ¶)
    dfs_thin = []
    chunk_size = 50
    for i in range(0, len(all_cal_dates), chunk_size):
        chunk = all_cal_dates[i:i+chunk_size]
        start_chunk, end_chunk = chunk[0], chunk[-1]
        try:
            daily = st.session_state.pro.daily(start_date=start_chunk, end_date=end_chunk, fields='ts_code,trade_date,close,vol')
            if not daily.empty:
                # [å†…å­˜å‹ç¼©] å¼ºåˆ¶è½¬ float32
                daily['close'] = daily['close'].astype('float32')
                daily['vol'] = daily['vol'].astype('float32')
                dfs_thin.append(daily)
        except: pass
        time.sleep(0.1) # é˜²å°åœ

    if not dfs_thin: return None
    df_thin = pd.concat(dfs_thin).sort_values(['ts_code', 'trade_date']).reset_index(drop=True)

    # æ‹‰å–å¤æƒå› å­ (å¿…éœ€)
    adj_dfs = []
    for i in range(0, len(all_cal_dates), chunk_size):
        chunk = all_cal_dates[i:i+chunk_size]
        start_chunk, end_chunk = chunk[0], chunk[-1]
        try:
            adj = st.session_state.pro.adj_factor(start_date=start_chunk, end_date=end_chunk, fields='ts_code,trade_date,adj_factor')
            if not adj.empty:
                adj['adj_factor'] = adj['adj_factor'].astype('float32')
                adj_dfs.append(adj)
        except: pass
    
    if adj_dfs:
        adj_all = pd.concat(adj_dfs)
        df_thin = pd.merge(df_thin, adj_all, on=['ts_code', 'trade_date'], how='left')
        df_thin['adj_factor'] = df_thin['adj_factor'].fillna(method='ffill').fillna(1.0)
        # è®¡ç®—åå¤æƒ Close ç”¨äº MACD
        df_thin['hfq_close'] = df_thin['close'] * df_thin['adj_factor']
    else:
        df_thin['hfq_close'] = df_thin['close']

    # === å‘é‡åŒ–è®¡ç®—æŒ‡æ ‡ ===
    # ä½¿ç”¨ Pandas GroupBy + Transform æé€Ÿè®¡ç®—
    grouped = df_thin.groupby('ts_code')['hfq_close']
    
    # MACD (8, 17, 5)
    ema8 = grouped.ewm(span=8, adjust=False).mean().reset_index(level=0, drop=True)
    ema17 = grouped.ewm(span=17, adjust=False).mean().reset_index(level=0, drop=True)
    df_thin['diff'] = ema8 - ema17
    df_thin['dea'] = df_thin.groupby('ts_code')['diff'].ewm(span=5, adjust=False).mean().reset_index(level=0, drop=True)
    df_thin['macd'] = (df_thin['diff'] - df_thin['dea']) * 2
    
    # MA20
    df_thin['ma20'] = grouped.rolling(20).mean().reset_index(level=0, drop=True)
    
    # MA5_Vol
    df_thin['ma5_vol'] = df_thin.groupby('ts_code')['vol'].rolling(5).mean().reset_index(level=0, drop=True)

    # === å…³é”®æ­¥éª¤ï¼šåªä¿ç•™éœ€è¦çš„æŒ‡æ ‡ï¼Œä¸¢å¼ƒå†å²æ•°æ® ===
    # ç­›é€‰å‡ºå±äºæœ¬æ¬¡ date_list çš„è¡Œ
    df_indicators = df_thin[df_thin['trade_date'].isin(date_list)].copy()
    # åªä¿ç•™ key å’ŒæŒ‡æ ‡
    df_indicators = df_indicators[['ts_code', 'trade_date', 'close', 'macd', 'ma20', 'ma5_vol', 'vol', 'hfq_close']]
    
    # ğŸ—‘ï¸ åƒåœ¾å›æ”¶ (é‡Šæ”¾å‡ ç™¾ä¸‡è¡Œæ•°æ®çš„å†…å­˜)
    del df_thin, dfs_thin, ema8, ema17, adj_dfs
    gc.collect()

    # === è½¨é“ 2ï¼šåŠ è½½å›æµ‹æœŸå…¨é‡æ•°æ® ===
    # åªåŠ è½½è¿™ 15 å¤©çš„ Open/High/Low/Pre_close ç”¨äºäº¤æ˜“åˆ¤å®š
    st.caption("ğŸ”§ åŠ è½½äº¤æ˜“ç»†èŠ‚æ•°æ®...")
    full_prices = st.session_state.pro.daily(start_date=start_date, end_date=end_date, fields='ts_code,trade_date,open,high,low,pre_close')
    if full_prices.empty: return None
    
    for c in ['open', 'high', 'low', 'pre_close']:
        full_prices[c] = full_prices[c].astype('float32')

    # === åˆå¹¶è½¨é“ ===
    df_final = pd.merge(df_indicators, full_prices, on=['ts_code', 'trade_date'], how='inner')
    
    return df_final

def check_trade_result(ts_code, buy_date, buy_price, stop_loss_pct):
    """
    [é£æ§å¼•æ“] æ£€æŸ¥æœªæ¥æ”¶ç›Šï¼ŒåŒ…å« T+1 å¿…é¡»é«˜å¼€ + åˆšæ€§æ­¢æŸ
    """
    try:
        d0 = datetime.strptime(buy_date, "%Y%m%d")
        f_start = (d0 + timedelta(days=1)).strftime("%Y%m%d")
        f_end = (d0 + timedelta(days=15)).strftime("%Y%m%d") # å–æœªæ¥15å¤©æ•°æ®ç”¨äºåˆ¤æ–­
        
        # æ‹‰å–å•åªè‚¡ç¥¨æœªæ¥æ•°æ® (æå¿«)
        df = st.session_state.pro.daily(ts_code=ts_code, start_date=f_start, end_date=f_end, fields='trade_date,open,high,low,close,pre_close')
        if df.empty: return {}
        
        df = df.sort_values('trade_date').reset_index(drop=True)
        d1 = df.iloc[0]
        
        # 1. ä¸¥æ ¼ä¹°å…¥æ¡ä»¶
        if d1['open'] <= d1['pre_close']: return {'status': 'ä½å¼€æ”¾å¼ƒ'}
        limit_up = d1['pre_close'] * 1.095
        if d1['open'] >= limit_up and d1['low'] >= d1['open']: return {'status': 'ä¸€å­—æ¿æ”¾å¼ƒ'}
        if d1['high'] < buy_price: return {'status': 'æœªçªç ´'}
        
        # 2. æ¨¡æ‹ŸæŒä»“ (åŒ…å«æ­¢æŸ)
        res = {'status': 'æˆäº¤'}
        stop_price = buy_price * (1 + stop_loss_pct/100)
        
        for n in [1, 3, 5]:
            if len(df) >= n:
                triggered_stop = False
                # æ£€æŸ¥ D1 åˆ° Dn æœŸé—´æ˜¯å¦è§¦åŠæ­¢æŸ
                for i in range(n):
                    if df.iloc[i]['low'] <= stop_price:
                        # è§¦å‘æ­¢æŸï¼šæŒ‰æ­¢æŸä»·ç¦»åœº (å¦‚æœå¼€ç›˜æ›´ä½ï¼ŒæŒ‰å¼€ç›˜ä»·)
                        exit_price = min(stop_price, df.iloc[i]['open'])
                        res[f'Return_D{n} (%)'] = (exit_price / buy_price - 1) * 100
                        res[f'Stop_D{n}'] = True
                        triggered_stop = True
                        break 
                
                if not triggered_stop:
                    # æœªè§¦å‘æ­¢æŸï¼ŒæŒ‰æ”¶ç›˜ä»·
                    close_price = df.iloc[n-1]['close']
                    res[f'Return_D{n} (%)'] = (close_price / buy_price - 1) * 100
                    res[f'Stop_D{n}'] = False
        return res
    except: return {}

# ---------------------------
# 5. ä¸»ç¨‹åºé€»è¾‘
# ---------------------------
if start_btn:
    if not st.session_state.ts_token:
        st.error("âŒ è¯·å…ˆè¾“å…¥ Token")
        st.stop()
        
    st.info("â³ åˆå§‹åŒ–å›æµ‹ç¯å¢ƒ...")
    
    # 1. è·å–æ‰€æœ‰æ—¥æœŸ
    end_date_str = datetime.now().strftime("%Y%m%d")
    all_target_days = get_trade_days(end_date_str, backtest_days)
    all_target_days = sorted(all_target_days) # æŒ‰æ—¶é—´æ­£åº
    
    # 2. æ–­ç‚¹ç»­ä¼ æ£€æµ‹
    results_file = "final_result.csv"
    finished_dates = load_processed_dates(results_file)
    days_to_run = [d for d in all_target_days if d not in finished_dates]
    
    if len(finished_dates) > 0:
        st.warning(f"æ£€æµ‹åˆ°å†å²å­˜æ¡£ï¼šå·²è·‘ {len(finished_dates)} å¤©ï¼Œè‡ªåŠ¨è·³è¿‡ã€‚æœ¬æ¬¡éœ€è·‘ {len(days_to_run)} å¤©ã€‚")
    
    if not days_to_run:
        st.success("ğŸ‰ æ‰€æœ‰æ—¥æœŸå·²å…¨éƒ¨å®Œæˆï¼")
    else:
        # 3. æ™ºèƒ½åˆ†æ®µ (é”å®š 15 å¤©ï¼Œé˜²å´©æºƒçš„å…³é”®)
        BATCH_SIZE = 15 
        batches = [days_to_run[i:i + BATCH_SIZE] for i in range(0, len(days_to_run), BATCH_SIZE)]
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        total_trades = 0
        
        for b_i, batch_days in enumerate(batches):
            status_text.markdown(f"### âš¡ æ­£åœ¨è®¡ç®—æ‰¹æ¬¡ {b_i+1}/{len(batches)} ({batch_days[0]} ~ {batch_days[-1]})")
            
            # A. å‡†å¤‡æ•°æ® (åŒè½¨åŠ è½½)
            try:
                df_batch = load_data_and_compute_safe(batch_days)
            except Exception as e:
                st.error(f"æ•°æ®åŠ è½½å¼‚å¸¸: {e}")
                continue

            if df_batch is None or df_batch.empty: continue
            
            # B. æ¯æ—¥é€‰è‚¡å¾ªç¯ (å†…å­˜æ“ä½œ)
            batch_results = []
            
            for day in batch_days:
                try:
                    # ç­›é€‰å½“æ—¥æ•°æ®
                    day_data = df_batch[df_batch['trade_date'] == day]
                    if day_data.empty: continue
                    
                    # è·å–å¸‚å€¼/æ¢æ‰‹ (Basicæ•°æ®æå°ï¼Œå®æ—¶æ‹‰å–å³å¯)
                    basic = st.session_state.pro.daily_basic(trade_date=day, fields='ts_code,turnover_rate,volume_ratio,circ_mv')
                    if basic is None or basic.empty: continue
                    
                    merged = pd.merge(day_data, basic, on='ts_code', how='inner')
                    
                    # === ç­–ç•¥ç­›é€‰æ ‡å‡† ===
                    mask = (
                        (merged['hfq_close'] > merged['ma20']) &       # è¶‹åŠ¿å‘ä¸Š
                        (merged['vol'] > merged['ma5_vol'] * 1.2) &    # æ”¾é‡
                        (merged['macd'] > 0) &                         # MACDé‡‘å‰åŒº
                        (merged['close'] >= min_price) &               # ä»·æ ¼ä¸‹é™
                        (merged['close'] <= max_price) &               # ä»·æ ¼ä¸Šé™
                        (merged['turnover_rate'] > 3.0) &              # æ´»è·ƒåº¦
                        (merged['circ_mv'] > 200000)                   # å¸‚å€¼ > 2äº¿
                    )
                    candidates = merged[mask].copy()
                    
                    if candidates.empty: continue
                    
                    # === è¯„åˆ†ç³»ç»Ÿ ===
                    # MACD/Price å› å­
                    candidates['base_score'] = (candidates['macd'] / candidates['hfq_close']) * 1000000
                    
                    # åŠ åˆ†é¡¹
                    candidates['pct_chg'] = (candidates['close'] / candidates['pre_close'] - 1) * 100
                    candidates['bonus'] = 1.0
                    candidates.loc[(candidates['volume_ratio'] > 1.5) & (candidates['volume_ratio'] < 5.0), 'bonus'] += 0.1
                    candidates.loc[(candidates['turnover_rate'] > 5.0) & (candidates['turnover_rate'] < 15.0), 'bonus'] += 0.1
                    candidates.loc[candidates['pct_chg'] > 9.5, 'bonus'] += 0.1
                    
                    candidates['final_score'] = candidates['base_score'] * candidates['bonus']
                    
                    # === å– Top K ===
                    # [è‡ªç”± Top K]
                    top_selection = candidates.sort_values('final_score', ascending=False).head(top_k)
                    
                    # === æ¨¡æ‹Ÿäº¤æ˜“ ===
                    for row in top_selection.itertuples():
                        buy_price = row.open * (1 + buy_threshold/100)
                        # ä¼ å…¥æ­¢æŸå‚æ•°
                        res = check_trade_result(row.ts_code, day, buy_price, stop_loss_pct)
                        
                        if res.get('status') == 'æˆäº¤':
                            rec = {
                                'trade_date': day,
                                'ts_code': row.ts_code,
                                'name': 'Unknown', 
                                'close': row.close,
                                'score': row.final_score
                            }
                            rec.update(res)
                            batch_results.append(rec)
                
                except Exception: pass
            
            # C. å®æ—¶å­˜ç›˜ (è¿½åŠ æ¨¡å¼)
            if batch_results:
                df_res = pd.DataFrame(batch_results)
                header = not os.path.exists(results_file)
                df_res.to_csv(results_file, mode='a', header=header, index=False, encoding='utf-8-sig')
                total_trades += len(df_res)
                st.toast(f"âœ… ä¿å­˜ {len(df_res)} æ¡è®°å½• (ç´¯è®¡: {total_trades})")
            
            # æ›´æ–°è¿›åº¦
            progress_bar.progress((b_i + 1) / len(batches))
            
            # D. å¼ºåˆ¶å†…å­˜æ¸…ç†
            del df_batch
            gc.collect()
            
        st.success("ğŸ‰ å›æµ‹å…¨éƒ¨å®Œæˆï¼")

    # ---------------------------
    # 6. ç»“æœå±•ç¤º
    # ---------------------------
    st.markdown("---")
    if os.path.exists(results_file):
        try:
            res_df = pd.read_csv(results_file)
            st.subheader("ğŸ“Š å›æµ‹æŠ¥å‘Š")
            
            col1, col2, col3, col4 = st.columns(4)
            col1.metric("æ€»äº¤æ˜“æ¬¡æ•°", len(res_df))
            
            if 'Return_D1 (%)' in res_df.columns:
                avg_d1 = res_df['Return_D1 (%)'].mean()
                win_d1 = (res_df['Return_D1 (%)'] > 0).mean() * 100
                col2.metric("D+1 å¹³å‡æ”¶ç›Š", f"{avg_d1:.2f}%")
                col3.metric("D+1 èƒœç‡", f"{win_d1:.1f}%")
                
                # ç®€å•èµ„é‡‘æ›²çº¿å›æ’¤
                res_df = res_df.sort_values('trade_date')
                # å‡è®¾æ¯æ—¥å‡ä»“
                daily_ret = res_df.groupby('trade_date')['Return_D1 (%)'].mean()
                equity = daily_ret.cumsum()
                dd = equity.cummax() - equity
                max_dd = dd.max()
                col4.metric("æœ€å¤§å›æ’¤ (ç‚¹æ•°)", f"{max_dd:.2f}")

            st.dataframe(res_df, use_container_width=True)
            
            with open(results_file, "rb") as f:
                st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´å›æµ‹æ•°æ® (CSV)", f, "final_backtest.csv", type="primary")
        except:
            st.info("è¯»å–ç»“æœæ–‡ä»¶å¤±è´¥æˆ–æ–‡ä»¶ä¸ºç©º")
